[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Workshop: Power Analysis for Experimental Designs in R with the PowerUpR Package",
    "section": "",
    "text": "Welcome to the introductory workshop on power analysis for single- and multilevel randomized trials (RTs) in R at the “Nachwuchstagung” of the GEBF 2024 at the University of Potsdam, taking place on March 21, 2024!\nThis online tutorial illustrates diverse application scenarios and offers corresponding exercises to perform power analysis with the PowerUpR package (Bulus et al., 2021). In this two-part workshop, you learn the basic steps to follow when designing…"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "single-level.html",
    "href": "single-level.html",
    "title": "Single-Level Designs",
    "section": "",
    "text": "In an individually randomized trial (IRT), individual students are sampled independently of each other and are randomly assigned to the experimental groups, disregarding any potential classroom or school affiliation; likewise, the treatment and control protocols are delivered at a completely individual basis."
  },
  {
    "objectID": "single-level.html#worked-example",
    "href": "single-level.html#worked-example",
    "title": "Single-Level Designs",
    "section": "Worked Example",
    "text": "Worked Example\nA research team has programmed a comprehensive learning app. It is meant to function as a multidisciplinary digital learning environment for students in various grade levels in the German school system. Therefore, it can be used to support teaching and learning in manifold achievement domains throughout the entire school career.\nAs a first step, the researchers aim to test the general efficacy of the underlying didactic approach. They plan a small-scale pilot IRT involving exclusively mathematical topics from Grade 4.\n\nScenario 1: Finding the Minimum Required Sample Size\nHow many students are required to adequately power an IRT to detect a certain hypothesized effect?\nThe research team considers a standardized treatment effect of d = .25 as meaningful, because it represents around one quarter of the expected annual growth in mathematics from Grade 3 to Grade 4 in the German student population (Brunner et al., 2023, Table 1). The team’s objective, therefore, is to sample enough 4th graders to detect MDES = .25 at significance level α = .05 in a two-tailed test with power 1−β = .80. For simplicity, the researchers assume a balanced design where students are allocated to the treatment and control conditions in equal shares (i.e., n[TG] = n[CG]), that is PT = .50.\n\nmrss.ira(es=.25, power=.80, alpha=.05, two.tailed=TRUE, n0=10, tol=.10, p=.50)\n\nn = 504 \n\n\nThe minimum required sample size (MRSS) for this design is N = 504 students.\n\n\nScenario 2: Computing the Minimum Detectable Effect Size\nWhich MDES is attainable in an adequately powered IRT?\nA standardized treatment effect of d = .25 is considered meaningful, representing around one quarter of the expected annual growth in mathematics for Grade 3–4 in the German student population (Brunner et al., 2023, Table 1). The team’s objective, therefore, is to sample enough 4th graders to detect MDES = .25 at significance level α = .05 in a two-tailed test with power 1−β = .80, where PT = .50.\n\nmdes.ira(power=.80, alpha=.05, two.tailed=TRUE, p=.50, n=250)\n\n\nMinimum detectable effect size: \n--------------------------------------- \n 0.356 95% CI [0.107,0.605]\n---------------------------------------\nDegrees of freedom: 248\nStandardized standard error: 0.126\nType I error rate: 0.05\nType II error rate: 0.2\nTwo-tailed test: TRUE\n\n\nThe minimum required sample size (MRSS) to achieve this in an unconditional IRT design (i.e., without covariates) is N = 504 students.\n\n\nScenario 3: Determining Power for a Given Design\nHow much power is achieved in an IRT?\nA standardized treatment effect of d = .25 is considered meaningful, representing around one quarter of the expected annual growth in mathematics for Grade 3–4 in the German student population (Brunner et al., 2023, Table 1). The team’s objective, therefore, is to sample enough 4th graders to detect MDES = .25 at significance level α = .05 in a two-tailed test with power 1−β = .80, where PT = .50.\n\npower.ira(es=.25, alpha=.05, two.tailed=TRUE, p=.50, n=250)\n\n\nStatistical power: \n--------------------------------------- \n 0.504\n--------------------------------------- \nDegrees of freedom: 248\nStandardized standard error: 0.126\nType I error rate: 0.05\nType II error rate: 0.496\nTwo-tailed test: TRUE\n\n\nThe minimum required sample size (MRSS) to achieve this in an unconditional IRT design (i.e., without covariates) is N = 504 students."
  },
  {
    "objectID": "single-level.html#using-the-powerupr-package-to-design-irts",
    "href": "single-level.html#using-the-powerupr-package-to-design-irts",
    "title": "Single-Level Designs",
    "section": "Using the PowerUpR Package to Design IRTs",
    "text": "Using the PowerUpR Package to Design IRTs\nIf not yet done, load the package.\n\nlibrary(PowerUpR)\n\n\n\n\nOutput\nFunction\n\n\n\n\nMinimum required sample size (MRSS)\nmrss.ira()\n\n\nMinimum detectable effect size (MDES)\nmdes.ira()\n\n\nPower\npower.ira()\n\n\n\nGo to the PowerUpR Documentation to see arguments etc."
  },
  {
    "objectID": "single-level.html#your-turn",
    "href": "single-level.html#your-turn",
    "title": "Single-Level Designs",
    "section": "Your turn!",
    "text": "Your turn!\n\nScenario 2: Finding the Minimum Required Sample Size\nHow many students are required to adequately power an IRT to detect a certain hypothesized effect?\nTo find the MRSS, use the mrss.ira() function.\n\n\n\n\n\n\nNote\n\n\n\nIn the PowerUpR Documentation you will find the following default code:\nmrss.ira(es=.25, power=.80, alpha=.05, two.tailed=TRUE, n0=10, tol=.10, p=.50, g1=0, r21=0)\nNote that the arguments n0 and tol are used to set the starting value and the tolerance in the iterative process to determine the MRSS. Here, you can keep the default values. Note further that, for the moment, you can ignore the covariate arguments g1 and r21.\n\n\n\nExercisesR Code Solutions\n\n\n\nCalculate the number of students needed for an IRT to detect MDES = .22 in a two-tailed test with 5% Type I error rate and 80% power, when the design is balanced (i.e., the exact MRSS for our worked example).\n\nAll else being constant, what happens when…\n\nincreasing power from 80% to 90%?\ndecreasing the Type I error rate to 1%?\n75% of the sample is assigned to the treatment group and 25% is assigned to the control group?\n\n\n\n\nCalculate the number of students needed for an IRT to detect MDES = .22 in a two-tailed test with 5% Type I error rate and 80% power, when the design is balanced (i.e., the exact MRSS for our worked example).\n\n\nmrss.ira(es=.22)\n\nThe MRSS is N = 651 students.\nAll else being constant, what happens when…\n\nincreasing power from 80% to 90%?\n\n\nmrss.ira(power=.90, es=.22)\n\nThe MRSS increases to N = 870 students.\n\ndecreasing the Type I error rate to 1%?\n\n\nmrss.ira(alpha=.01, es=.22)\n\nThe MRSS increases to N = 968 students.\n\n75% of the sample is assigned to the treatment group and 25% is assigned to the control group?\n\n\nmrss.ira(p=.75, es=.22)\n\nThe MRSS increases to N = 867 students.\n\n\n\n\n\nScenario 3: Computing the Minimum Detectable Effect Size\nWhich MDES* is attainable in an adequately powered IRT, given a specified sample size?*\nTo compute the MDES, use the mdes.ira() function.\n\n\n\n\n\n\nNote\n\n\n\nIn the PowerUpR Documentation you will find the following default code:\nmdes.ira(power=.80, alpha=.05, two.tailed=TRUE, p=.50, g1=0, r21=0, n)\nAgain, ignore the covariate arguments g1 and r21 for the moment.\n\n\n\nExercisesR Code Solutions\n\n\nCalculate the smallest size of effect that can be uncovered with confidence (i.e., α = .05, two-tailed, 1-β = .80) in an IRT…\n\nwhere 125 students receive the treatment, and 375 do “business as usual”.\nwhere 375 students receive the treatment, and 125 do “business as usual”.\n\nPlot the MDES as a function of the sample size…\n\nfor the unbalanced design in 1.\nfor a balanced design and compare with the plot from 3.\n\n\n\nCalculate the smallest size of effect that can be uncovered with confidence (i.e., α = .05, two-tailed, 1-β = .80) in an IRT…\n\nwhere 125 students receive the treatment, and 375 do “business as usual”.\n\n\nmdes.ira(p=.25, n=500)\n\n\nMinimum detectable effect size: \n--------------------------------------- \n 0.29 95% CI [0.087,0.493]\n---------------------------------------\nDegrees of freedom: 498\nStandardized standard error: 0.103\nType I error rate: 0.05\nType II error rate: 0.2\nTwo-tailed test: TRUE\n\n\nThe MDES equals 0.29, with 95% CI [0.09, 0.49].\n\nwhere 375 students receive the treatment, and 125 do “business as usual”.\n\n\nmdes.ira(p=.75, n=500)\n\n\nMinimum detectable effect size: \n--------------------------------------- \n 0.29 95% CI [0.087,0.493]\n---------------------------------------\nDegrees of freedom: 498\nStandardized standard error: 0.103\nType I error rate: 0.05\nType II error rate: 0.2\nTwo-tailed test: TRUE\n\n\nThe results are exactly the same: The MDES equals 0.29, with 95% CI [0.09, 0.49].\nPlot the MDES as a function of the sample size…\n\nfor the unbalanced design in 1.\n\n\ns3.1 &lt;- mdes.ira(p=.25, n=500)\nplot(s3.1, ypar=\"mdes\")\n\n\n\n\n\n\n\nfor a balanced design and compare with the plot from 3.\n\n\ns3.2 &lt;- mdes.ira(n=500)\n\n\nMinimum detectable effect size: \n--------------------------------------- \n 0.251 95% CI [0.075,0.427]\n---------------------------------------\nDegrees of freedom: 498\nStandardized standard error: 0.089\nType I error rate: 0.05\nType II error rate: 0.2\nTwo-tailed test: TRUE\n\nplot(s3.2, ypar=\"mdes\")\n\n\n\n\nThe balanced design is more efficient than the unbalanced design, because the treatment effect can be estimated with greater precision."
  },
  {
    "objectID": "multilevel.html",
    "href": "multilevel.html",
    "title": "Multilevel Designs",
    "section": "",
    "text": "In a cluster randomized trial (CRT), entire groups of students (e.g., whole schools) are randomly assigned to the experimental groups; likewise, the treatment and control protocols are delivered at the cluster level.\nIn this tutorial, you will learn how to perform power analysis for 2L- and 3L-CRT designs. In the 2L-CRT, students at L1 are nested within schools at L2 and entire schools are randomly assigned to the experimental conditions. In the 3L-CRT, students at L1 are nested within classrooms at L2 which are, in turn, nested within schools at L3. Here, randomization/treatment assignment occurs, again, at the top hierarchical school level."
  },
  {
    "objectID": "multilevel.html#scenario-1-how-many-schools-are-required-for-a-2l-crt",
    "href": "multilevel.html#scenario-1-how-many-schools-are-required-for-a-2l-crt",
    "title": "Multilevel Designs",
    "section": "Scenario 1: How Many Schools are Required for a 2L-CRT?",
    "text": "Scenario 1: How Many Schools are Required for a 2L-CRT?\nResearch Team 1 would like to conduct a 2L-CRT on the effectiveness of a school-wide intervention to improve 4th graders’ mathematical achievement in Germany. Team 1 plans to sample 40 students from each school. A standardized treatment effect of d = .25 is considered meaningful, because it represents around one quarter of the expected annual growth in mathematics from Grade 3 to Grade 4 in the German student population (Brunner et al., 2023, Table 1). How many schools are required to detect MDES = .25?\n\nStep 1: Choose the Design Parameters\nWhich data frame contains the appropriate design parameters?\n\n\n# -- choose data frame B9 \ndp_s1 &lt;- multides1[[\"B9_General-2l\"]] |&gt; \n  # filter mathematics in grade 4\n  filter(domain == \"Mathematics\", grade == 4)\n\nLet’s have a look at the relevant design parameters.\ndp_s1 |&gt; \n  # select the ICC and its standard error\n  select(contains(\"icc\")) |&gt; \n  round(2) |&gt; \n  pivot_longer(everything(), names_to = \"Variable\", values_to = \"Value\") |&gt; \n  kable()\n\n\n\n\nVariable\nValue\n\n\n\n\nicc_l3.est\n0.12\n\n\nicc_l3.se\n0.01\n\n\n\n\n\n\nStep 2: Define the Assumptions\n\nDesign AssumptionsFormula\n\n\n\n\n\n\n\n\n\nParameter\nPowerUpR Conversion\n\n\n\n\nTarget output\n\n\n\nMinimum required sample size of a 2L-CRT: Number of schools J\nmrss.cra2()\n\n\nStatistical test\n\n\n\nPower 1-β = .80\npower=.80 (default)\n\n\nSignificance level α = .05\nalpha=.05 (default)\n\n\nTwo-tailed test\ntwo.tailed=TRUE (default)\n\n\nSample sizes\n\n\n\nHarmonic mean number of L1 units per L2 unit n = 40\nn=40\n\n\nProportion of sample assigned to treatment P = .50 (balanced)\np=.50 (default)\n\n\nDesign parameters\n\n\n\nICC at L2 ρL2 = .12\nrho2=dp_s1$icc_l3.est\n\n\nFurther parameters\n\n\n\nMinimum detectable effect size MDES = .25\nes=.25\n\n\n\n\n\nBased on the expression for the MDES of a 2L-CRT with randomization/treatment assignment at L2 as given in (dong_maynard2013?), the number of schools \\(J\\) is computed as \\[\nJ = \\left(\\frac{M_{J-2}}{MDES}\\right)^2\\left(\\frac{\\rho_{L2}}{P(1-P)}+\\frac{(1-\\rho_{L2})}{P(1-P)n} \\right)\n\\] with\n\n\\(n\\) = harmonic mean number of L1 units per L2 unit\n\\(J\\) = number of L2 units\n\\(P\\) = \\(J_{TG}/J\\) = proportion of sample assigned to treatment\n\\(MDES\\) = minimum detectable effect size\n\\(M_{J-2}\\) = \\(t_{\\alpha/2}+t_{1-\\beta}\\) = multiplier for two-tailed test with \\(J-2\\) degrees of freedom\n\\(\\rho_{L2}\\) = achievement differences at L2 (ICC at L2)\n\n\n\n\n\n\nStep 3: Power Analysis with PowerUpR\n\nSimple Design with Default Assumptions\n\nd.0 &lt;- mrss.cra2(power=.80, alpha=.05, two.tailed=TRUE,\n                 n=40, p=.50,\n                 rho2=dp_s1$icc_l3.est, \n                 es=.25)\n\nJ = 73 \n\n\nGiven this design, at least 73 schools are necessary to detect an MDES of .25.\nOf course, it is also possible to directly insert the numeric values for the design parameters, but using the variables instead is safer, more precise, and prevents typos. Note that the results can differ due to rounding.\n\n# Note: Here, we are omitting all default parameters...\nd.01 &lt;- mrss.cra2(n=40, rho2=.12, es=.25)\n\nJ = 73 \n\n\n\n\nChanging the Default Assumptions\nEverything else being equal, what happens, when…\n\n(a) … power increases from 80% to 90%?\n\n# adjust the `power` argument to .90\nd.a &lt;- mrss.cra2(power=.90, \n                 n=40, rho2=dp_s1$icc_l3.est, es=.25)\n\nJ = 97 \n\n\nIncreasing power requires a larger number of schools.\nTip: We could also update the respective parameter in the list $parms stored in the mrss object and then call the function again with the modified argument.\n\n# save design 0 as a new design\nd.a &lt;- d.0\n# update `power` argument to .90\nd.a$parms$power=.90\n# call the function\nd.a &lt;- exec(\"mrss.cra2\", !!!d.a$parms)\n\nJ = 97 \n\n\n\n\n(b) … Type I error rate is set to 1%?\n\n# adjust the `alpha` argument to .01\nd.b &lt;- mrss.cra2(alpha=.01, \n                 n=40, rho2=dp_s1$icc_l3.est, es=.25)\n\nJ = 109 \n\n\nDecreasing the Type I error rate requires a larger number of schools.\n\n\n(c) … applying a one-tailed test?\n\n# adjust the `two.tailed` argument to FALSE\nd.c &lt;- mrss.cra2(two.tailed=FALSE, \n                 n=40, rho2=dp_s1$icc_l3.est, es=.25)\n\nJ = 57 \n\n\nTesting one-tailed requires a smaller number of schools.\n\n\n(d) … sampling 20/40/60/80/100 students per school?\n\n# adjust the `n` argument to 20/40/60/80/100\nd.d1 &lt;- mrss.cra2(n=20, rho2=dp_s1$icc_l3.est, es=.25)\nd.d2 &lt;- mrss.cra2(n=40, rho2=dp_s1$icc_l3.est, es=.25)\nd.d3 &lt;- mrss.cra2(n=60, rho2=dp_s1$icc_l3.est, es=.25)\nd.d4 &lt;- mrss.cra2(n=80, rho2=dp_s1$icc_l3.est, es=.25)\nd.d5 &lt;- mrss.cra2(n=100, rho2=dp_s1$icc_l3.est, es=.25)\n\nTip: Performing power analysis over a range of possible input parameters can be more easily done via vectorization. To vectorize the functions of PowerUpR over a range of possible input parameters (here: n = 20/40/60/80/100), we need to write a custom function similar to what is suggested by the package authors in their vignette on vectorization).\n\ncustom_mrss.cra2 &lt;- function(n) {\n  parms &lt;- list(n=n, rho2 = dp_s1$icc_l3.est, es=.25)\n  design &lt;- exec(\"mrss.cra2\", !!!parms)\n  design$J\n}\n\nNow we simply have to map the function across the various sample sizes.\n\n# number of students per school n = 20/40/60/80/100 \nn &lt;- seq(20, 100, 20)\nd.d &lt;- map_dbl(n, custom_mrss.cra2)\n\nJ = 84 \nJ = 73 \nJ = 69 \nJ = 67 \nJ = 66 \n\n\nSampling fewer/more students per school requires a larger/smaller number of schools. However, it becomes clear that increasing the number of students per school quickly reaches a point of diminishing returns.\n\n\n(e) … using an unbalanced design with 75% of the sample assigned to the treatment condition?\n\n# adjust the `p` argument to .75\nd.e &lt;- mrss.cra2(n=20, p=.75, rho2=dp_s1$icc_l3.est, es=.25)\n\nJ = 111 \n\n\nThe more pronounced the imbalance between experimental conditions, the larger the required number of schools.\n\n\n(f) … larger achievement differences of \\(\\rho\\) = .20 are assumed?\n\n# adjust `rho2` to .20\nd.f &lt;-mrss.cra2(n=40, rho2=.20, es=.25)\n\nJ = 112 \n\n\nLarger ICCs increase the required number of schools.\n\n\n\nIncorporating Statistical Uncertainty\nThe design parameters are estimates of population quantities, and thus, associated with statistical uncertainty. The uncertainty can be incorporated by using the standard errors for each design parameter. Assuming large-sample properties, research Team 1 uses the standard normal distribution to compute the limits for 95% confidence intervals by means of the standard errors for the design parameters. This approach has been labeled the the “safeguard” approach (Perugini et al., 2014). A conservative approach for planning the sample size is to use the upper bound estimate of the 95% CI for \\(\\rho\\).\n\n# lower bound\nd.g_lb &lt;- mrss.cra2(n=40, \n                    rho2 = dp_s1$icc_l3.est-1.96*dp_s1$icc_l3.se, \n                    es=.25)\n\nJ = 61 \n\n# upper bound\nd.g_ub &lt;- mrss.cra2(n=40, \n                    rho2 = dp_s1$icc_l3.est+1.96*dp_s1$icc_l3.se, \n                    es=.25)\n\nJ = 85 \n\n\nTaking statistical uncertainty into account, the required number of schools likely ranges between 61 and 85.\nNote that there are also other approaches to tackle uncertainties and/or heterogeneities in the input parameters. For instance, (Bayesian) simulation-based approaches to power analysis have been proposed that implicitly take into account uncertainty(see e.g., Moerbeek & Teerenstra, 2015; Pek & Park, 2019; Spiegelhalter et al., 2003; Turner et al., 2004).\n\n\n\nStep 4: Plotting\nLet’s plot the results. Move your cursor across the bars to learn about the required number schools for each design and how large the difference in % is compared to the baseline design.\n\n\nshow code\n\n\npackages &lt;- c(\"plotly\", \"htmlwidgets\")\n\ninvisible(\n  lapply(packages,\n         function(x) {\n           if (!require(x, character.only = TRUE)) {\n             install.packages(x, dependencies = TRUE); require(x, character.only = TRUE)}\n         }\n  )\n)\n\n\ndesign &lt;- list(d.0, d.a, d.b, d.c, d.d1, d.d3, d.d5, d.e, d.f, d.g_lb, d.g_ub) |&gt; \n  set_names(\"d.0\", \"d.a\", \"d.b\", \"d.c\", \"d.d1\", \"d.d3\", \"d.d5\", \"d.e\", \"d.f\", \"d.g_lb\", \"d.g_ub\")\n\ndelta &lt;- function(design) (design[[\"J\"]]-d.0[[\"J\"]])/d.0[[\"J\"]]*100\n\n\np &lt;- data.frame(design = factor(names(design)), \n                schools = map_dbl(design, ~.[[\"J\"]]), \n                delta = map_dbl(design, delta)) |&gt; \n  ggplot(aes(design, schools, text = paste(\n    factor(design, \n           levels = c(\"d.0\", \"d.a\", \"d.b\", \"d.c\", \"d.d1\", \"d.d3\", \"d.d5\", \"d.e\", \"d.f\", \"d.g_lb\", \"d.g_ub\"), \n           labels = c(\"The baseline design\", \n                      \"... increasing power to 90%\", \n                      \" ... setting Type I error rate to 1%\", \n                      \" ... applying a one-tailed test\", \n                      \"... sampling 20 students per school\", \n                      \"... sampling 60 students per school\", \n                      \"... sampling 100 students per school\", \n                      \"... assigning 75% of the schools to the treatment condition\", \n                      \"... assuming increased achievement differences at L2 of 20%\", \n                      \"... applying a liberal approach\",\n                      \"... applying a conservative approach\")),\n    \" requires J = \", schools, \" schools.\",\"\\n\",\n    ifelse(design == \"d.0\", \"\", \n           ifelse(design != \"d.0\" & delta &gt; 0, \n           paste0(\"This amounts to \", round(delta, 0), \n                  \"% more schools compared to the baseline design.\"),\n           ifelse(design != \"d.0\" & delta == 0, \n           \"The required number of schools does not change compared to the baseline design.\",\n           paste0(\"This amounts to \", round(delta, 0)*-1, \n                  \"% fewer schools compared to the baseline design.\")))),\n    sep = \"\"\n    ))) +\n  geom_bar(stat=\"identity\", width=0.9) + \n  scale_x_discrete(\"Design\") + \n  scale_y_continuous(\"Number of schools\") + \n  theme_minimal() + \n  theme(axis.ticks = element_blank(), \n        plot.title = element_text(hjust = 0.5)) + \n  ggtitle(\"Number of Schools Required for an MDES of .25 by Design\")\n\nggplotly(p, tooltip = \"text\")\n\n\n\n\n\n\n\n\n\nBuilt-in Functionality for Plotting in PowerUpR\nPowerUpR also comes with a built-in plotting function. We will quickly check out PowerUpR::plot() with the baseline design.\nIt is not possible to plot the required sample size. Instead, we can either plot the statistical power as a function of the sample size (which is the default)…\n\nplot(d.0, main = \"Power as a Function of the Number of Schools\")\n\n\n\n\n… or we can plot the MDES along with its (1-α)*100% CI as a function of the required number of schools.\n\n# include `ypar = \"mdes\"` to plot the MDES\n# include `locate=TRUE` to locate parameter values for the applied design\nplot(d.0, ypar = \"mdes\", \n     main = \"MDES as a Function of Number of Schools\", locate = TRUE)"
  },
  {
    "objectID": "exercises.html",
    "href": "exercises.html",
    "title": "Exercises",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.0     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(kableExtra)\n\n\nAttache Paket: 'kableExtra'\n\nDas folgende Objekt ist maskiert 'package:dplyr':\n\n    group_rows\n\n\n\niris %&gt;% \n  kable(table.attr = 'data-quarto-disable-processing=\"true\"') %&gt;% \n  kableExtra::kable_styling(bootstrap_options = c(\"basic\", \"hover\"), full_width = FALSE)\n\n\n\n\nSepal.Length\nSepal.Width\nPetal.Length\nPetal.Width\nSpecies\n\n\n\n\n5.1\n3.5\n1.4\n0.2\nsetosa\n\n\n4.9\n3.0\n1.4\n0.2\nsetosa\n\n\n4.7\n3.2\n1.3\n0.2\nsetosa\n\n\n4.6\n3.1\n1.5\n0.2\nsetosa\n\n\n5.0\n3.6\n1.4\n0.2\nsetosa\n\n\n5.4\n3.9\n1.7\n0.4\nsetosa\n\n\n4.6\n3.4\n1.4\n0.3\nsetosa\n\n\n5.0\n3.4\n1.5\n0.2\nsetosa\n\n\n4.4\n2.9\n1.4\n0.2\nsetosa\n\n\n4.9\n3.1\n1.5\n0.1\nsetosa\n\n\n5.4\n3.7\n1.5\n0.2\nsetosa\n\n\n4.8\n3.4\n1.6\n0.2\nsetosa\n\n\n4.8\n3.0\n1.4\n0.1\nsetosa\n\n\n4.3\n3.0\n1.1\n0.1\nsetosa\n\n\n5.8\n4.0\n1.2\n0.2\nsetosa\n\n\n5.7\n4.4\n1.5\n0.4\nsetosa\n\n\n5.4\n3.9\n1.3\n0.4\nsetosa\n\n\n5.1\n3.5\n1.4\n0.3\nsetosa\n\n\n5.7\n3.8\n1.7\n0.3\nsetosa\n\n\n5.1\n3.8\n1.5\n0.3\nsetosa\n\n\n5.4\n3.4\n1.7\n0.2\nsetosa\n\n\n5.1\n3.7\n1.5\n0.4\nsetosa\n\n\n4.6\n3.6\n1.0\n0.2\nsetosa\n\n\n5.1\n3.3\n1.7\n0.5\nsetosa\n\n\n4.8\n3.4\n1.9\n0.2\nsetosa\n\n\n5.0\n3.0\n1.6\n0.2\nsetosa\n\n\n5.0\n3.4\n1.6\n0.4\nsetosa\n\n\n5.2\n3.5\n1.5\n0.2\nsetosa\n\n\n5.2\n3.4\n1.4\n0.2\nsetosa\n\n\n4.7\n3.2\n1.6\n0.2\nsetosa\n\n\n4.8\n3.1\n1.6\n0.2\nsetosa\n\n\n5.4\n3.4\n1.5\n0.4\nsetosa\n\n\n5.2\n4.1\n1.5\n0.1\nsetosa\n\n\n5.5\n4.2\n1.4\n0.2\nsetosa\n\n\n4.9\n3.1\n1.5\n0.2\nsetosa\n\n\n5.0\n3.2\n1.2\n0.2\nsetosa\n\n\n5.5\n3.5\n1.3\n0.2\nsetosa\n\n\n4.9\n3.6\n1.4\n0.1\nsetosa\n\n\n4.4\n3.0\n1.3\n0.2\nsetosa\n\n\n5.1\n3.4\n1.5\n0.2\nsetosa\n\n\n5.0\n3.5\n1.3\n0.3\nsetosa\n\n\n4.5\n2.3\n1.3\n0.3\nsetosa\n\n\n4.4\n3.2\n1.3\n0.2\nsetosa\n\n\n5.0\n3.5\n1.6\n0.6\nsetosa\n\n\n5.1\n3.8\n1.9\n0.4\nsetosa\n\n\n4.8\n3.0\n1.4\n0.3\nsetosa\n\n\n5.1\n3.8\n1.6\n0.2\nsetosa\n\n\n4.6\n3.2\n1.4\n0.2\nsetosa\n\n\n5.3\n3.7\n1.5\n0.2\nsetosa\n\n\n5.0\n3.3\n1.4\n0.2\nsetosa\n\n\n7.0\n3.2\n4.7\n1.4\nversicolor\n\n\n6.4\n3.2\n4.5\n1.5\nversicolor\n\n\n6.9\n3.1\n4.9\n1.5\nversicolor\n\n\n5.5\n2.3\n4.0\n1.3\nversicolor\n\n\n6.5\n2.8\n4.6\n1.5\nversicolor\n\n\n5.7\n2.8\n4.5\n1.3\nversicolor\n\n\n6.3\n3.3\n4.7\n1.6\nversicolor\n\n\n4.9\n2.4\n3.3\n1.0\nversicolor\n\n\n6.6\n2.9\n4.6\n1.3\nversicolor\n\n\n5.2\n2.7\n3.9\n1.4\nversicolor\n\n\n5.0\n2.0\n3.5\n1.0\nversicolor\n\n\n5.9\n3.0\n4.2\n1.5\nversicolor\n\n\n6.0\n2.2\n4.0\n1.0\nversicolor\n\n\n6.1\n2.9\n4.7\n1.4\nversicolor\n\n\n5.6\n2.9\n3.6\n1.3\nversicolor\n\n\n6.7\n3.1\n4.4\n1.4\nversicolor\n\n\n5.6\n3.0\n4.5\n1.5\nversicolor\n\n\n5.8\n2.7\n4.1\n1.0\nversicolor\n\n\n6.2\n2.2\n4.5\n1.5\nversicolor\n\n\n5.6\n2.5\n3.9\n1.1\nversicolor\n\n\n5.9\n3.2\n4.8\n1.8\nversicolor\n\n\n6.1\n2.8\n4.0\n1.3\nversicolor\n\n\n6.3\n2.5\n4.9\n1.5\nversicolor\n\n\n6.1\n2.8\n4.7\n1.2\nversicolor\n\n\n6.4\n2.9\n4.3\n1.3\nversicolor\n\n\n6.6\n3.0\n4.4\n1.4\nversicolor\n\n\n6.8\n2.8\n4.8\n1.4\nversicolor\n\n\n6.7\n3.0\n5.0\n1.7\nversicolor\n\n\n6.0\n2.9\n4.5\n1.5\nversicolor\n\n\n5.7\n2.6\n3.5\n1.0\nversicolor\n\n\n5.5\n2.4\n3.8\n1.1\nversicolor\n\n\n5.5\n2.4\n3.7\n1.0\nversicolor\n\n\n5.8\n2.7\n3.9\n1.2\nversicolor\n\n\n6.0\n2.7\n5.1\n1.6\nversicolor\n\n\n5.4\n3.0\n4.5\n1.5\nversicolor\n\n\n6.0\n3.4\n4.5\n1.6\nversicolor\n\n\n6.7\n3.1\n4.7\n1.5\nversicolor\n\n\n6.3\n2.3\n4.4\n1.3\nversicolor\n\n\n5.6\n3.0\n4.1\n1.3\nversicolor\n\n\n5.5\n2.5\n4.0\n1.3\nversicolor\n\n\n5.5\n2.6\n4.4\n1.2\nversicolor\n\n\n6.1\n3.0\n4.6\n1.4\nversicolor\n\n\n5.8\n2.6\n4.0\n1.2\nversicolor\n\n\n5.0\n2.3\n3.3\n1.0\nversicolor\n\n\n5.6\n2.7\n4.2\n1.3\nversicolor\n\n\n5.7\n3.0\n4.2\n1.2\nversicolor\n\n\n5.7\n2.9\n4.2\n1.3\nversicolor\n\n\n6.2\n2.9\n4.3\n1.3\nversicolor\n\n\n5.1\n2.5\n3.0\n1.1\nversicolor\n\n\n5.7\n2.8\n4.1\n1.3\nversicolor\n\n\n6.3\n3.3\n6.0\n2.5\nvirginica\n\n\n5.8\n2.7\n5.1\n1.9\nvirginica\n\n\n7.1\n3.0\n5.9\n2.1\nvirginica\n\n\n6.3\n2.9\n5.6\n1.8\nvirginica\n\n\n6.5\n3.0\n5.8\n2.2\nvirginica\n\n\n7.6\n3.0\n6.6\n2.1\nvirginica\n\n\n4.9\n2.5\n4.5\n1.7\nvirginica\n\n\n7.3\n2.9\n6.3\n1.8\nvirginica\n\n\n6.7\n2.5\n5.8\n1.8\nvirginica\n\n\n7.2\n3.6\n6.1\n2.5\nvirginica\n\n\n6.5\n3.2\n5.1\n2.0\nvirginica\n\n\n6.4\n2.7\n5.3\n1.9\nvirginica\n\n\n6.8\n3.0\n5.5\n2.1\nvirginica\n\n\n5.7\n2.5\n5.0\n2.0\nvirginica\n\n\n5.8\n2.8\n5.1\n2.4\nvirginica\n\n\n6.4\n3.2\n5.3\n2.3\nvirginica\n\n\n6.5\n3.0\n5.5\n1.8\nvirginica\n\n\n7.7\n3.8\n6.7\n2.2\nvirginica\n\n\n7.7\n2.6\n6.9\n2.3\nvirginica\n\n\n6.0\n2.2\n5.0\n1.5\nvirginica\n\n\n6.9\n3.2\n5.7\n2.3\nvirginica\n\n\n5.6\n2.8\n4.9\n2.0\nvirginica\n\n\n7.7\n2.8\n6.7\n2.0\nvirginica\n\n\n6.3\n2.7\n4.9\n1.8\nvirginica\n\n\n6.7\n3.3\n5.7\n2.1\nvirginica\n\n\n7.2\n3.2\n6.0\n1.8\nvirginica\n\n\n6.2\n2.8\n4.8\n1.8\nvirginica\n\n\n6.1\n3.0\n4.9\n1.8\nvirginica\n\n\n6.4\n2.8\n5.6\n2.1\nvirginica\n\n\n7.2\n3.0\n5.8\n1.6\nvirginica\n\n\n7.4\n2.8\n6.1\n1.9\nvirginica\n\n\n7.9\n3.8\n6.4\n2.0\nvirginica\n\n\n6.4\n2.8\n5.6\n2.2\nvirginica\n\n\n6.3\n2.8\n5.1\n1.5\nvirginica\n\n\n6.1\n2.6\n5.6\n1.4\nvirginica\n\n\n7.7\n3.0\n6.1\n2.3\nvirginica\n\n\n6.3\n3.4\n5.6\n2.4\nvirginica\n\n\n6.4\n3.1\n5.5\n1.8\nvirginica\n\n\n6.0\n3.0\n4.8\n1.8\nvirginica\n\n\n6.9\n3.1\n5.4\n2.1\nvirginica\n\n\n6.7\n3.1\n5.6\n2.4\nvirginica\n\n\n6.9\n3.1\n5.1\n2.3\nvirginica\n\n\n5.8\n2.7\n5.1\n1.9\nvirginica\n\n\n6.8\n3.2\n5.9\n2.3\nvirginica\n\n\n6.7\n3.3\n5.7\n2.5\nvirginica\n\n\n6.7\n3.0\n5.2\n2.3\nvirginica\n\n\n6.3\n2.5\n5.0\n1.9\nvirginica\n\n\n6.5\n3.0\n5.2\n2.0\nvirginica\n\n\n6.2\n3.4\n5.4\n2.3\nvirginica\n\n\n5.9\n3.0\n5.1\n1.8\nvirginica"
  },
  {
    "objectID": "multilevel2.html",
    "href": "multilevel2.html",
    "title": "Multilevel Designs",
    "section": "",
    "text": "The following exercises cover power analysis for cluster randomized trials (CRTs) with one treatment and one control condition (i.e., a two-arm study). We will walk through the process of planning two CRT designs:"
  },
  {
    "objectID": "multilevel2.html#scenario-1-how-many-schools-are-required-for-a-2l-crt",
    "href": "multilevel2.html#scenario-1-how-many-schools-are-required-for-a-2l-crt",
    "title": "Multilevel Designs",
    "section": "Scenario 1: How Many Schools are Required for a 2L-CRT?",
    "text": "Scenario 1: How Many Schools are Required for a 2L-CRT?\nResearch Team 1 would like to conduct a 2L-CRT on the effectiveness of a school-wide intervention to improve 4th graders’ mathematical achievement in Germany. Team 1 plans to sample 40 students from each school. A standardized treatment effect of d = .25 is considered meaningful, because it represents around one quarter of the expected annual growth in mathematics from Grade 3 to Grade 4 in the German student population (Brunner et al., 2023, Table 1). How many schools are required to detect MDES = .25?\n\nStep 1: Choose the Design Parameters\nWhich data frame contains the appropriate design parameters?\n\n\n# -- choose data frame B9 \ndp_s1 &lt;- multides1[[\"B9_General-2l\"]] |&gt; \n  # filter mathematics in grade 4\n  filter(domain == \"Mathematics\", grade == 4)\n\nLet’s have a look at the relevant design parameters.\n\ndp_s1 |&gt; \n  # select the ICC and its standard error\n  select(contains(\"icc\")) |&gt; \n  round(2) |&gt; \n  pivot_longer(everything(), names_to = \"Variable\", values_to = \"Value\") |&gt; \n  kable(table.attr = 'data-quarto-disable-processing=\"true\"') |&gt; \n  kable_styling(full_width=FALSE, position = \"left\", \n                  bootstrap_options = c(\"condensed\", \"responsive\"))\n\n\n\n\n\nVariable\nValue\n\n\n\n\nicc_l3.est\n0.12\n\n\nicc_l3.se\n0.01\n\n\n\n\n\n\n\n\n\n\nStep 2: Define the Assumptions\n\nDesign AssumptionsFormula\n\n\n\n\n\n\n\n\n\nParameter\nPowerUpR Conversion\n\n\n\n\nTarget output\n\n\n\nMinimum required sample size of a 2L-CRT: Number of schools J\nmrss.cra2()\n\n\nStatistical test\n\n\n\nPower 1-β = .80\npower=.80 (default)\n\n\nSignificance level α = .05\nalpha=.05 (default)\n\n\nTwo-tailed test\ntwo.tailed=TRUE (default)\n\n\nSample sizes\n\n\n\nHarmonic mean number of L1 units per L2 unit n = 40\nn=40\n\n\nProportion of sample assigned to treatment P = .50 (balanced)\np=.50 (default)\n\n\nDesign parameters\n\n\n\nICC at L2 ρL2 = .12\nrho2=dp_s1$icc_l3.est\n\n\nFurther parameters\n\n\n\nMinimum detectable effect size MDES = .25\nes=.25\n\n\n\n\n\nBased on the expression for the MDES of a 2L-CRT with randomization/treatment assignment at L2 as given in (dong_maynard2013?), the number of schools \\(J\\) is computed as \\[\nJ = \\left(\\frac{M_{J-2}}{MDES}\\right)^2\\left(\\frac{\\rho_{L2}}{P(1-P)}+\\frac{(1-\\rho_{L2})}{P(1-P)n} \\right)\n\\] with\n\n\\(n\\) = harmonic mean number of L1 units per L2 unit\n\\(J\\) = number of L2 units\n\\(P\\) = \\(J_{TG}/J\\) = proportion of sample assigned to treatment\n\\(MDES\\) = minimum detectable effect size\n\\(M_{J-2}\\) = \\(t_{\\alpha/2}+t_{1-\\beta}\\) = multiplier for two-tailed test with \\(J-2\\) degrees of freedom\n\\(\\rho_{L2}\\) = achievement differences at L2 (ICC at L2)\n\n\n\n\n\n\nStep 3: Power Analysis with PowerUpR\n\nSimple design with default assumptions\n\nd.0 &lt;- mrss.cra2(power=.80, alpha=.05, two.tailed=TRUE,\n                 n=40, J0=10, tol=.10, p=.50,\n                 rho2=dp_s1$icc_l3.est, \n                 es=.25)\n\nJ = 73 \n\n\nGiven this design, at least 73 schools are necessary to detect an MDES of .25.\nOf course, it is also possible to directly insert the numeric values for the design parameters, but using the variables instead is safer, more precise, and prevents typos. Note that the results can differ due to rounding.\n\n# Note: Here, we are omitting all default parameters...\nd.01 &lt;- mrss.cra2(n=40, rho2=.12, es=.25)\n\nJ = 73 \n\n\n\n\nChanging the default assumptions\nEverything else being equal, what happens, when…\n\n(a) … power increases from 80% to 90%?\n\n# adjust the power argument to .90\nd.a &lt;- mrss.cra2(power=.90, \n                 n=40, rho2=dp_s1$icc_l3.est, es=.25)\n\nJ = 97 \n\n\nIncreasing power requires a larger number of schools.\nTip: We could also update the respective parameter in the list $parms stored in the mrss object and then call the function again with the modified argument.\n\n# save design 0 as a new design\nd.a &lt;- d.0\n# update power argument to .90\nd.a$parms$power=.90\n# call the function\nd.a &lt;- exec(\"mrss.cra2\", !!!d.a$parms)\n\nJ = 97 \n\n\n\n\n(b) … Type I error rate is set to 1%?\n\n# adjust the alpha argument to .01\nd.b &lt;- mrss.cra2(alpha=.01, \n                 n=40, rho2=dp_s1$icc_l3.est, es=.25)\n\nJ = 109 \n\n\nDecreasing the Type I error rate requires a larger number of schools.\n\n\n(c) … applying a one-tailed test?\n\n# adjust the two.tailed argument to FALSE\nd.c &lt;- mrss.cra2(two.tailed=FALSE, \n                 n=40, rho2=dp_s1$icc_l3.est, es=.25)\n\nJ = 57 \n\n\nTesting one-tailed requires a smaller number of schools.\n\n\n(d) … sampling 20/40/60/80/100 students per school?\n\n# adjust the n argument to 20/40/60/80/100\nd.d1 &lt;- mrss.cra2(n=20, rho2=dp_s1$icc_l3.est, es=.25)\nd.d2 &lt;- mrss.cra2(n=40, rho2=dp_s1$icc_l3.est, es=.25)\nd.d3 &lt;- mrss.cra2(n=60, rho2=dp_s1$icc_l3.est, es=.25)\nd.d4 &lt;- mrss.cra2(n=80, rho2=dp_s1$icc_l3.est, es=.25)\nd.d5 &lt;- mrss.cra2(n=100, rho2=dp_s1$icc_l3.est, es=.25)\n\nTip: Performing power analysis over a range of possible input parameters can be more easily done via vectorization.\nTo vectorize the functions of PowerUpR over a range of possible input parameters (here: n = 20/40/60/80/100), we need to write a custom function similar to what is suggested by the package authors in their vignette on vectorization).\n\ncustom_mrss.cra2 &lt;- function(n) {\n  parms &lt;- list(n=n, rho2 = dp_s1$icc_l3.est, es=.25)\n  design &lt;- exec(\"mrss.cra2\", !!!parms)\n  design$J\n}\n\nNow we simply have to map the function across the various sample sizes.\n\n# number of students per school n = 20/40/60/80/100 \nn &lt;- seq(20, 100, 20)\nd.d &lt;- map_dbl(n, custom_mrss.cra2)\n\nJ = 84 \nJ = 73 \nJ = 69 \nJ = 67 \nJ = 66 \n\n\nSampling fewer/more students per school requires a larger/smaller number of schools. However, it becomes clear that increasing the number of students per school quickly reaches a point of diminishing returns.\n\n\n(e) … using an unbalanced design with 60/70/80% of the sample assigned to the treatment condition?\n\n# -- adjust the `p` argument to .60/.70/.80\n\n# write a function to vectorize over a range of allocation proportions P\ncustom_mrss.cra2 &lt;- function(p) {\n  parms &lt;- list(n=40, p=p, rho2 = dp_s1$icc_l3.est, es=.25)\n  design &lt;- exec(\"mrss.cra2\", !!!parms)\n  design$J\n}\n\n# allocation proportion P = .60/.70/.80\np &lt;- seq(.60, .80, .10)\nd.e &lt;- map_dbl(p, custom_mrss.cra2)\n\nJ = 76 \nJ = 86 \nJ = 113 \n\n\n\n\n(f) … larger achievement differences of \\(\\rho\\) = .20 are assumed?\n\n# adjust `rho2` to .20\nd.f &lt;-mrss.cra2(n=40, rho2=.20, es=.25)\n\nJ = 112 \n\n\nLarger \\(\\rho\\) values increase the required number of schools.\n\n\n(g) … taking statistical uncertainty in into account?\nThe design parameters are estimates of population quantities, and thus, associated with statistical uncertainty. The uncertainty can be incorporated by using the standard errors for each design parameter. Assuming large-sample properties, research Team 1 uses the standard normal distribution to compute the limits for 95% confidence intervals by means of the standard errors for the design parameters. A conservative approach for planning the sample size is to use the upper bound estimate of the 95% CI for \\(\\rho\\).\n\n# lower bound\nd.g_lb &lt;- mrss.cra2(n=40, \n                    rho2 = dp_s1$icc_l3.est-1.96*dp_s1$icc_l3.se, \n                    es=.25)\n\nJ = 61 \n\n# upper bound\nd.g_ub &lt;- mrss.cra2(n=40, \n                    rho2 = dp_s1$icc_l3.est+1.96*dp_s1$icc_l3.se, \n                    es=.25)\n\nJ = 85 \n\n\nTaking statistical uncertainty into account, Team 1 learns that the required number of schools likely ranges between 61 and 85.\n\n\n\n\nPlotting\nLet’s have a look at the results. Move your cursor across the bars to learn about the required number schools for each design and how large the difference in % is compared to the baseline design with a single math pretest as covariate at L1 and L2.\n\n\nshow code\n\n\n#| warning: false\n#| message: false\n#| eval: false\n#| output: false\n\n#packages &lt;- c(\"plotly\", \"htmlwidgets\")\n#\n#invisible(\n#  lapply(packages,\n#         function(x) {\n#           if (!require(x, character.only = TRUE)) {\n#             install.packages(x, dependencies = TRUE); require(x, character.only = TRUE)}\n#         }\n#  )\n#)\n#\n#\n#design &lt;- list(d.a, d.b, d.c1, d.c2, d.d, d.e, d.f) |&gt; \n#  set_names(\"d.a\", \"d.b\", \"d.c1\", \"d.c2\", \"d.d\", \"d.e\", \"d.f\")\n#\n#delta &lt;- function(design) (design[[\"J\"]]-d.a[[\"J\"]])/d.a[[\"J\"]]*100\n#\n#\n#p &lt;- data.frame(design = factor(names(design)), \n#                schools = map_dbl(design, ~.[[\"J\"]]), \n#                delta = map_dbl(design, delta)) |&gt; \n#  ggplot(aes(design, schools, text = paste(\n#    factor(design, \n#           levels = c(\"d.a\", \"d.b\", \"d.c1\", \"d.c2\", \"d.d\", \"d.e\", \"d.f\"), \n#           labels = c(\"The baseline design with a math pretest as covariate\", \n#                      \"... increasing power to 90%\", \n#                      \" ... adding sociodemographics at L1\", \n#                      \" ... adding sociodemographics at both L1 and L2\", \n#                      \"... using no covariates\", \n#                      \"... assuming increased achievement differences at L2 of 20%\", \n#                      \"... applying a conservative approach\")),\n#    \" requires J = \", schools, \" schools.\",\"\\n\",\n#    ifelse(design == \"d.a\", \"\", \n#           ifelse(design != \"d.a\" & delta &gt; 0, \n#           paste0(\"This amounts to \", round(delta, 0), \n#                  \"% more schools compared to the baseline design.\"),\n#           ifelse(design != \"d.a\" & delta == 0, \n#           \"The required number of schools does not change compared to the baseline design.\",\n#           paste0(\"This amounts to \", round(delta, 0)*-1, \n#                  \"% fewer schools compared to the baseline design.\")))),\n#    sep = \"\"\n#    ))) +\n#  geom_bar(stat=\"identity\", width=0.9, fill = \"#2c3e50\") + \n#  scale_x_discrete(\"Design\") + \n#  scale_y_continuous(\"Number of schools\") + \n#  theme_minimal() + \n#  theme(axis.ticks = element_blank(), \n#        plot.title = element_text(hjust = 0.5)) + \n#  ggtitle(\"Number of Schools Required for an MDES of .15 by Design\")\n#\n#ggplotly(p, tooltip = \"text\")\n\n\nPowerUpR also has built-in functionality for plotting. We will quickly check out the plot() function with design (a). We can either plot statistical power as a function of the required number of schools (which is the default in plot())…\n\n#plot(d.a, main = \"MDES as a Function of Number of Schools\")\n\n\n \n\n… or we can plot the MDES along with its (1-α)*100% CI as a function of the required number of schools.\n\n# include `ypar = \"mdes\"` to plot the MDES\n# include `locate=TRUE` to locate parameter values for the applied design\n#plot(d.a, ypar = \"mdes\", \n#     main = \"MDES as a Function of Number of Schools\", locate = TRUE)"
  },
  {
    "objectID": "multilevel.html#scenario-2-how-many-schools-are-required-for-a-2l-crt",
    "href": "multilevel.html#scenario-2-how-many-schools-are-required-for-a-2l-crt",
    "title": "Multilevel Designs",
    "section": "Scenario 2: How Many Schools are Required for a 2L-CRT?",
    "text": "Scenario 2: How Many Schools are Required for a 2L-CRT?\nResearch Team 1 would like to conduct a 2L-CRT on the effectiveness of a school-wide intervention to improve 4th graders’ mathematical achievement in Germany. Team 1 plans to sample 40 students from each school. A standardized treatment effect of d = .25 is considered meaningful, because it represents around one quarter of the expected annual growth in mathematics from Grade 3 to Grade 4 in the German student population (Brunner et al., 2023, Table 1). How many schools are required to detect MDES = .25?\n\nStep 1: Choose the Design Parameters\nWhich data frame contains the appropriate design parameters?\n\n\n# -- choose data frame B9 \ndp_s1 &lt;- multides1[[\"B9_General-2l\"]] |&gt; \n  # filter mathematics in grade 4\n  filter(domain == \"Mathematics\", grade == 4)\n\nLet’s have a look at the relevant design parameters.\ndp_s1 |&gt; \n  # select the ICC and its standard error\n  select(contains(\"icc\")) |&gt; \n  round(2) |&gt; \n  pivot_longer(everything(), names_to = \"Variable\", values_to = \"Value\") |&gt; \n  kable()\n\n\n\n\nVariable\nValue\n\n\n\n\nicc_l3.est\n0.12\n\n\nicc_l3.se\n0.01\n\n\n\n\n\n\nStep 2: Define the Assumptions\n\nDesign AssumptionsFormula\n\n\n\n\n\n\n\n\n\nParameter\nPowerUpR Conversion\n\n\n\n\nTarget output\n\n\n\nMinimum required sample size of a 2L-CRT: Number of schools J\nmrss.cra2()\n\n\nStatistical test\n\n\n\nPower 1-β = .80\npower=.80 (default)\n\n\nSignificance level α = .05\nalpha=.05 (default)\n\n\nTwo-tailed test\ntwo.tailed=TRUE (default)\n\n\nSample sizes\n\n\n\nHarmonic mean number of L1 units per L2 unit n = 40\nn=40\n\n\nProportion of sample assigned to treatment P = .50 (balanced)\np=.50 (default)\n\n\nDesign parameters\n\n\n\nICC at L2 ρL2 = .12\nrho2=dp_s1$icc_l3.est\n\n\nFurther parameters\n\n\n\nMinimum detectable effect size MDES = .25\nes=.25\n\n\n\n\n\nBased on the expression for the MDES of a 2L-CRT with randomization/treatment assignment at L2 as given in (dong_maynard2013?), the number of schools \\(J\\) is computed as \\[\nJ = \\left(\\frac{M_{J-2}}{MDES}\\right)^2\\left(\\frac{\\rho_{L2}}{P(1-P)}+\\frac{(1-\\rho_{L2})}{P(1-P)n} \\right)\n\\] with\n\n\\(n\\) = harmonic mean number of L1 units per L2 unit\n\\(J\\) = number of L2 units\n\\(P\\) = \\(J_{TG}/J\\) = proportion of sample assigned to treatment\n\\(MDES\\) = minimum detectable effect size\n\\(M_{J-2}\\) = \\(t_{\\alpha/2}+t_{1-\\beta}\\) = multiplier for two-tailed test with \\(J-2\\) degrees of freedom\n\\(\\rho_{L2}\\) = achievement differences at L2 (ICC at L2)\n\n\n\n\n\n\nStep 3: Power Analysis with PowerUpR\n\nSimple Design with Default Assumptions\n\nd.0 &lt;- mrss.cra2(power=.80, alpha=.05, two.tailed=TRUE,\n                 n=40, p=.50,\n                 rho2=dp_s1$icc_l3.est, \n                 es=.25)\n\nJ = 73 \n\n\nGiven this design, at least 73 schools are necessary to detect an MDES of .25.\nOf course, it is also possible to directly insert the numeric values for the design parameters, but using the variables instead is safer, more precise, and prevents typos. Note that the results can differ due to rounding.\n\n# Note: Here, we are omitting all default parameters...\nd.01 &lt;- mrss.cra2(n=40, rho2=.12, es=.25)\n\nJ = 73 \n\n\n\n\nChanging the Default Assumptions\nEverything else being equal, what happens, when…\n\n(a) … power increases from 80% to 90%?\n\n# adjust the `power` argument to .90\nd.a &lt;- mrss.cra2(power=.90, \n                 n=40, rho2=dp_s1$icc_l3.est, es=.25)\n\nJ = 97 \n\n\nIncreasing power requires a larger number of schools.\nTip: We could also update the respective parameter in the list $parms stored in the mrss object and then call the function again with the modified argument.\n\n# save design 0 as a new design\nd.a &lt;- d.0\n# update `power` argument to .90\nd.a$parms$power=.90\n# call the function\nd.a &lt;- exec(\"mrss.cra2\", !!!d.a$parms)\n\nJ = 97 \n\n\n\n\n(b) … Type I error rate is set to 1%?\n\n# adjust the `alpha` argument to .01\nd.b &lt;- mrss.cra2(alpha=.01, \n                 n=40, rho2=dp_s1$icc_l3.est, es=.25)\n\nJ = 109 \n\n\nDecreasing the Type I error rate requires a larger number of schools.\n\n\n(c) … applying a one-tailed test?\n\n# adjust the `two.tailed` argument to FALSE\nd.c &lt;- mrss.cra2(two.tailed=FALSE, \n                 n=40, rho2=dp_s1$icc_l3.est, es=.25)\n\nJ = 57 \n\n\nTesting one-tailed requires a smaller number of schools.\n\n\n(d) … sampling 20/40/60/80/100 students per school?\n\n# adjust the `n` argument to 20/40/60/80/100\nd.d1 &lt;- mrss.cra2(n=20, rho2=dp_s1$icc_l3.est, es=.25)\nd.d2 &lt;- mrss.cra2(n=40, rho2=dp_s1$icc_l3.est, es=.25)\nd.d3 &lt;- mrss.cra2(n=60, rho2=dp_s1$icc_l3.est, es=.25)\nd.d4 &lt;- mrss.cra2(n=80, rho2=dp_s1$icc_l3.est, es=.25)\nd.d5 &lt;- mrss.cra2(n=100, rho2=dp_s1$icc_l3.est, es=.25)\n\nTip: Performing power analysis over a range of possible input parameters can be more easily done via vectorization. To vectorize the functions of PowerUpR over a range of possible input parameters (here: n = 20/40/60/80/100), we need to write a custom function similar to what is suggested by the package authors in their vignette on vectorization).\n\ncustom_mrss.cra2 &lt;- function(n) {\n  parms &lt;- list(n=n, rho2 = dp_s1$icc_l3.est, es=.25)\n  design &lt;- exec(\"mrss.cra2\", !!!parms)\n  design$J\n}\n\nNow we simply have to map the function across the various sample sizes.\n\n# number of students per school n = 20/40/60/80/100 \nn &lt;- seq(20, 100, 20)\nd.d &lt;- map_dbl(n, custom_mrss.cra2)\n\nJ = 84 \nJ = 73 \nJ = 69 \nJ = 67 \nJ = 66 \n\n\nSampling fewer/more students per school requires a larger/smaller number of schools. However, it becomes clear that increasing the number of students per school quickly reaches a point of diminishing returns.\n\n\n(e) … using an unbalanced design with 75% of the sample assigned to the treatment condition?\n\n# adjust the `p` argument to .75\nd.e &lt;- mrss.cra2(n=20, p=.75, rho2=dp_s1$icc_l3.est, es=.25)\n\nJ = 111 \n\n\nThe more pronounced the imbalance between experimental conditions, the larger the required number of schools.\n\n\n(f) … larger achievement differences of \\(\\rho\\) = .20 are assumed?\n\n# adjust `rho2` to .20\nd.f &lt;-mrss.cra2(n=40, rho2=.20, es=.25)\n\nJ = 112 \n\n\nLarger ICCs increase the required number of schools.\n\n\n\nIncorporating Statistical Uncertainty\nThe design parameters are estimates of population quantities, and thus, associated with statistical uncertainty. The uncertainty can be incorporated by using the standard errors for each design parameter. Assuming large-sample properties, research Team 1 uses the standard normal distribution to compute the limits for 95% confidence intervals by means of the standard errors for the design parameters. This approach has been labeled the the “safeguard” approach (Perugini et al., 2014). A conservative approach for planning the sample size is to use the upper bound estimate of the 95% CI for \\(\\rho\\).\n\n# lower bound\nd.g_lb &lt;- mrss.cra2(n=40, \n                    rho2 = dp_s1$icc_l3.est-1.96*dp_s1$icc_l3.se, \n                    es=.25)\n\nJ = 61 \n\n# upper bound\nd.g_ub &lt;- mrss.cra2(n=40, \n                    rho2 = dp_s1$icc_l3.est+1.96*dp_s1$icc_l3.se, \n                    es=.25)\n\nJ = 85 \n\n\nTaking statistical uncertainty into account, the required number of schools likely ranges between 61 and 85.\nNote that there are also other approaches to tackle uncertainties and/or heterogeneities in the input parameters. For instance, (Bayesian) simulation-based approaches to power analysis have been proposed that implicitly take into account uncertainty(see e.g., Moerbeek & Teerenstra, 2015; Pek & Park, 2019; Spiegelhalter et al., 2003; Turner et al., 2004).\n\n\n\nStep 4: Plotting\nLet’s plot the results. Move your cursor across the bars to learn about the required number schools for each design and how large the difference in % is compared to the baseline design.\n\n\nshow code\n\n\npackages &lt;- c(\"plotly\", \"htmlwidgets\")\n\ninvisible(\n  lapply(packages,\n         function(x) {\n           if (!require(x, character.only = TRUE)) {\n             install.packages(x, dependencies = TRUE); require(x, character.only = TRUE)}\n         }\n  )\n)\n\n\ndesign &lt;- list(d.0, d.a, d.b, d.c, d.d1, d.d3, d.d5, d.e, d.f, d.g_lb, d.g_ub) |&gt; \n  set_names(\"d.0\", \"d.a\", \"d.b\", \"d.c\", \"d.d1\", \"d.d3\", \"d.d5\", \"d.e\", \"d.f\", \"d.g_lb\", \"d.g_ub\")\n\ndelta &lt;- function(design) (design[[\"J\"]]-d.0[[\"J\"]])/d.0[[\"J\"]]*100\n\n\np &lt;- data.frame(design = factor(names(design)), \n                schools = map_dbl(design, ~.[[\"J\"]]), \n                delta = map_dbl(design, delta)) |&gt; \n  ggplot(aes(design, schools, text = paste(\n    factor(design, \n           levels = c(\"d.0\", \"d.a\", \"d.b\", \"d.c\", \"d.d1\", \"d.d3\", \"d.d5\", \"d.e\", \"d.f\", \"d.g_lb\", \"d.g_ub\"), \n           labels = c(\"The baseline design\", \n                      \"... increasing power to 90%\", \n                      \" ... setting Type I error rate to 1%\", \n                      \" ... applying a one-tailed test\", \n                      \"... sampling 20 students per school\", \n                      \"... sampling 60 students per school\", \n                      \"... sampling 100 students per school\", \n                      \"... assigning 75% of the schools to the treatment condition\", \n                      \"... assuming increased achievement differences at L2 of 20%\", \n                      \"... applying a liberal approach\",\n                      \"... applying a conservative approach\")),\n    \" requires J = \", schools, \" schools.\",\"\\n\",\n    ifelse(design == \"d.0\", \"\", \n           ifelse(design != \"d.0\" & delta &gt; 0, \n           paste0(\"This amounts to \", round(delta, 0), \n                  \"% more schools compared to the baseline design.\"),\n           ifelse(design != \"d.0\" & delta == 0, \n           \"The required number of schools does not change compared to the baseline design.\",\n           paste0(\"This amounts to \", round(delta, 0)*-1, \n                  \"% fewer schools compared to the baseline design.\")))),\n    sep = \"\"\n    ))) +\n  geom_bar(stat=\"identity\", width=0.9) + \n  scale_x_discrete(\"Design\") + \n  scale_y_continuous(\"Number of schools\") + \n  theme_minimal() + \n  theme(axis.ticks = element_blank(), \n        plot.title = element_text(hjust = 0.5)) + \n  ggtitle(\"Number of Schools Required for an MDES of .25 by Design\")\n\nggplotly(p, tooltip = \"text\")\n\n\n\n\n\n\n\n\n\nBuilt-in Functionality for Plotting in PowerUpR\nPowerUpR also comes with a built-in plotting function. We will quickly check out PowerUpR::plot() with the baseline design.\nIt is not possible to plot the required sample size. Instead, we can either plot the statistical power as a function of the sample size (which is the default)…\n\nplot(d.0, main = \"Power as a Function of the Number of Schools\")\n\n\n\n\n… or we can plot the MDES along with its (1-α)*100% CI as a function of the required number of schools.\n\n# include `ypar = \"mdes\"` to plot the MDES\n# include `locate=TRUE` to locate parameter values for the applied design\nplot(d.0, ypar = \"mdes\", \n     main = \"MDES as a Function of Number of Schools\", locate = TRUE)"
  },
  {
    "objectID": "two-level.html",
    "href": "two-level.html",
    "title": "Two-Level Designs",
    "section": "",
    "text": "The following exercises cover power analysis for cluster randomized trials (CRTs) with one treatment and one control condition (i.e., a two-arm study). We will walk through the process of planning two CRT designs:"
  },
  {
    "objectID": "two-level.html#scenario-1-how-many-schools-are-required-for-a-2l-crt",
    "href": "two-level.html#scenario-1-how-many-schools-are-required-for-a-2l-crt",
    "title": "Two-Level Designs",
    "section": "Scenario 1: How Many Schools are Required for a 2L-CRT?",
    "text": "Scenario 1: How Many Schools are Required for a 2L-CRT?\nResearch Team 1 would like to conduct a 2L-CRT on the effectiveness of a school-wide intervention to improve 4th graders’ mathematical achievement in Germany. Team 1 plans to sample 40 students from each school. A standardized treatment effect of d = .25 is considered meaningful, because it represents around one quarter of the expected annual growth in mathematics from Grade 3 to Grade 4 in the German student population (Brunner et al., 2023, Table 1). How many schools are required to detect MDES = .25?\n\nStep 1: Choose the Design Parameters\nWhich data frame contains the appropriate design parameters?\n\n\n# -- choose data frame B9 \ndp_s1 &lt;- multides1[[\"B9_General-2l\"]] |&gt; \n  # filter mathematics in grade 4\n  filter(domain == \"Mathematics\", grade == 4)\n\nLet’s have a look at the relevant design parameters.\ndp_s1 |&gt; \n  # select the ICC and its standard error\n  select(contains(\"icc\")) |&gt; \n  round(2) |&gt; \n  pivot_longer(everything(), names_to = \"Variable\", values_to = \"Value\") |&gt; \n  kable()\n\n\n\n\nVariable\nValue\n\n\n\n\nicc_l3.est\n0.12\n\n\nicc_l3.se\n0.01\n\n\n\n\n\n\nStep 2: Define the Assumptions\n\nDesign AssumptionsFormula\n\n\n\n\n\n\n\n\n\nParameter\nPowerUpR Conversion\n\n\n\n\nTarget output\n\n\n\nMinimum required sample size of a 2L-CRT: Number of schools J\nmrss.cra2()\n\n\nStatistical test\n\n\n\nPower 1-β = .80\npower=.80 (default)\n\n\nSignificance level α = .05\nalpha=.05 (default)\n\n\nTwo-tailed test\ntwo.tailed=TRUE (default)\n\n\nSample sizes\n\n\n\nHarmonic mean number of L1 units per L2 unit n = 40\nn=40\n\n\nProportion of sample assigned to treatment P = .50 (balanced)\np=.50 (default)\n\n\nDesign parameters\n\n\n\nICC at L2 ρL2 = .12\nrho2=dp_s1$icc_l3.est\n\n\nFurther parameters\n\n\n\nMinimum detectable effect size MDES = .25\nes=.25\n\n\n\n\n\nBased on the expression for the MDES of a 2L-CRT with randomization/treatment assignment at L2 as given in (dong_maynard2013?), the number of schools \\(J\\) is computed as \\[\nJ = \\left(\\frac{M_{J-2}}{MDES}\\right)^2\\left(\\frac{\\rho_{L2}}{P(1-P)}+\\frac{(1-\\rho_{L2})}{P(1-P)n} \\right)\n\\] with\n\n\\(n\\) = harmonic mean number of L1 units per L2 unit\n\\(J\\) = number of L2 units\n\\(P\\) = \\(J_{TG}/J\\) = proportion of sample assigned to treatment\n\\(MDES\\) = minimum detectable effect size\n\\(M_{J-2}\\) = \\(t_{\\alpha/2}+t_{1-\\beta}\\) = multiplier for two-tailed test with \\(J-2\\) degrees of freedom\n\\(\\rho_{L2}\\) = achievement differences at L2 (ICC at L2)\n\n\n\n\n\n\nStep 3: Power Analysis with PowerUpR\n\nSimple Design with Default Assumptions\n\nd.0 &lt;- mrss.cra2(power=.80, alpha=.05, two.tailed=TRUE,\n                 n=40, p=.50,\n                 rho2=dp_s1$icc_l3.est, \n                 es=.25)\n\nJ = 73 \n\n\nGiven this design, at least 73 schools are necessary to detect an MDES of .25.\nOf course, it is also possible to directly insert the numeric values for the design parameters, but using the variables instead is safer, more precise, and prevents typos. Note that the results can differ due to rounding.\n\n# Note: Here, we are omitting all default parameters...\nd.01 &lt;- mrss.cra2(n=40, rho2=.12, es=.25)\n\nJ = 73 \n\n\n\n\nChanging the Default Assumptions\nEverything else being equal, what happens, when…\n\n(a) … power increases from 80% to 90%?\n\n# adjust the `power` argument to .90\nd.a &lt;- mrss.cra2(power=.90, \n                 n=40, rho2=dp_s1$icc_l3.est, es=.25)\n\nJ = 97 \n\n\nIncreasing power requires a larger number of schools.\nTip: We could also update the respective parameter in the list $parms stored in the mrss object and then call the function again with the modified argument.\n\n# save design 0 as a new design\nd.a &lt;- d.0\n# update `power` argument to .90\nd.a$parms$power=.90\n# call the function\nd.a &lt;- exec(\"mrss.cra2\", !!!d.a$parms)\n\nJ = 97 \n\n\n\n\n(b) … Type I error rate is set to 1%?\n\n# adjust the `alpha` argument to .01\nd.b &lt;- mrss.cra2(alpha=.01, \n                 n=40, rho2=dp_s1$icc_l3.est, es=.25)\n\nJ = 109 \n\n\nDecreasing the Type I error rate requires a larger number of schools.\n\n\n(c) … applying a one-tailed test?\n\n# adjust the `two.tailed` argument to FALSE\nd.c &lt;- mrss.cra2(two.tailed=FALSE, \n                 n=40, rho2=dp_s1$icc_l3.est, es=.25)\n\nJ = 57 \n\n\nTesting one-tailed requires a smaller number of schools.\n\n\n(d) … sampling 20/40/60/80/100 students per school?\n\n# adjust the `n` argument to 20/40/60/80/100\nd.d1 &lt;- mrss.cra2(n=20, rho2=dp_s1$icc_l3.est, es=.25)\nd.d2 &lt;- mrss.cra2(n=40, rho2=dp_s1$icc_l3.est, es=.25)\nd.d3 &lt;- mrss.cra2(n=60, rho2=dp_s1$icc_l3.est, es=.25)\nd.d4 &lt;- mrss.cra2(n=80, rho2=dp_s1$icc_l3.est, es=.25)\nd.d5 &lt;- mrss.cra2(n=100, rho2=dp_s1$icc_l3.est, es=.25)\n\nTip: Performing power analysis over a range of possible input parameters can be more easily done via vectorization. To vectorize the functions of PowerUpR over a range of possible input parameters (here: n = 20/40/60/80/100), we need to write a custom function similar to what is suggested by the package authors in their vignette on vectorization).\n\ncustom_mrss.cra2 &lt;- function(n) {\n  parms &lt;- list(n=n, rho2 = dp_s1$icc_l3.est, es=.25)\n  design &lt;- exec(\"mrss.cra2\", !!!parms)\n  design$J\n}\n\nNow we simply have to map the function across the various sample sizes.\n\n# number of students per school n = 20/40/60/80/100 \nn &lt;- seq(20, 100, 20)\nd.d &lt;- map_dbl(n, custom_mrss.cra2)\n\nJ = 84 \nJ = 73 \nJ = 69 \nJ = 67 \nJ = 66 \n\n\nSampling fewer/more students per school requires a larger/smaller number of schools. However, it becomes clear that increasing the number of students per school quickly reaches a point of diminishing returns.\n\n\n(e) … using an unbalanced design with 75% of the sample assigned to the treatment condition?\n\n# adjust the `p` argument to .75\nd.e &lt;- mrss.cra2(n=20, p=.75, rho2=dp_s1$icc_l3.est, es=.25)\n\nJ = 111 \n\n\nThe more pronounced the imbalance between experimental conditions, the larger the required number of schools.\n\n\n(f) … larger achievement differences of \\(\\rho\\) = .20 are assumed?\n\n# adjust `rho2` to .20\nd.f &lt;-mrss.cra2(n=40, rho2=.20, es=.25)\n\nJ = 112 \n\n\nLarger ICCs increase the required number of schools.\n\n\n\nIncorporating Statistical Uncertainty\nThe design parameters are estimates of population quantities, and thus, associated with statistical uncertainty. The uncertainty can be incorporated by using the standard errors for each design parameter. Assuming large-sample properties, research Team 1 uses the standard normal distribution to compute the limits for 95% confidence intervals by means of the standard errors for the design parameters. This approach has been labeled the the “safeguard” approach (Perugini et al., 2014). A conservative approach for planning the sample size is to use the upper bound estimate of the 95% CI for \\(\\rho\\).\n\n# lower bound\nd.g_lb &lt;- mrss.cra2(n=40, \n                    rho2 = dp_s1$icc_l3.est-1.96*dp_s1$icc_l3.se, \n                    es=.25)\n\nJ = 61 \n\n# upper bound\nd.g_ub &lt;- mrss.cra2(n=40, \n                    rho2 = dp_s1$icc_l3.est+1.96*dp_s1$icc_l3.se, \n                    es=.25)\n\nJ = 85 \n\n\nTaking statistical uncertainty into account, the required number of schools likely ranges between 61 and 85.\nNote that there are also other approaches to tackle uncertainties and/or heterogeneities in the input parameters. For instance, (Bayesian) simulation-based approaches to power analysis have been proposed that implicitly take into account uncertainty(see e.g., Moerbeek & Teerenstra, 2015; Pek & Park, 2019; Spiegelhalter et al., 2003; Turner et al., 2004).\n\n\n\nStep 4: Plotting\nLet’s plot the results. Move your cursor across the bars to learn about the required number schools for each design and how large the difference in % is compared to the baseline design.\n\n\nshow code\n\n\npackages &lt;- c(\"plotly\", \"htmlwidgets\")\n\ninvisible(\n  lapply(packages,\n         function(x) {\n           if (!require(x, character.only = TRUE)) {\n             install.packages(x, dependencies = TRUE); require(x, character.only = TRUE)}\n         }\n  )\n)\n\n\ndesign &lt;- list(d.0, d.a, d.b, d.c, d.d1, d.d3, d.d5, d.e, d.f, d.g_lb, d.g_ub) |&gt; \n  set_names(\"d.0\", \"d.a\", \"d.b\", \"d.c\", \"d.d1\", \"d.d3\", \"d.d5\", \"d.e\", \"d.f\", \"d.g_lb\", \"d.g_ub\")\n\ndelta &lt;- function(design) (design[[\"J\"]]-d.0[[\"J\"]])/d.0[[\"J\"]]*100\n\n\np &lt;- data.frame(design = factor(names(design)), \n                schools = map_dbl(design, ~.[[\"J\"]]), \n                delta = map_dbl(design, delta)) |&gt; \n  ggplot(aes(design, schools, text = paste(\n    factor(design, \n           levels = c(\"d.0\", \"d.a\", \"d.b\", \"d.c\", \"d.d1\", \"d.d3\", \"d.d5\", \"d.e\", \"d.f\", \"d.g_lb\", \"d.g_ub\"), \n           labels = c(\"The baseline design\", \n                      \"... increasing power to 90%\", \n                      \" ... setting Type I error rate to 1%\", \n                      \" ... applying a one-tailed test\", \n                      \"... sampling 20 students per school\", \n                      \"... sampling 60 students per school\", \n                      \"... sampling 100 students per school\", \n                      \"... assigning 75% of the schools to the treatment condition\", \n                      \"... assuming increased achievement differences at L2 of 20%\", \n                      \"... applying a liberal approach\",\n                      \"... applying a conservative approach\")),\n    \" requires J = \", schools, \" schools.\",\"\\n\",\n    ifelse(design == \"d.0\", \"\", \n           ifelse(design != \"d.0\" & delta &gt; 0, \n           paste0(\"This amounts to \", round(delta, 0), \n                  \"% more schools compared to the baseline design.\"),\n           ifelse(design != \"d.0\" & delta == 0, \n           \"The required number of schools does not change compared to the baseline design.\",\n           paste0(\"This amounts to \", round(delta, 0)*-1, \n                  \"% fewer schools compared to the baseline design.\")))),\n    sep = \"\"\n    ))) +\n  geom_bar(stat=\"identity\", width=0.9) + \n  scale_x_discrete(\"Design\") + \n  scale_y_continuous(\"Number of schools\") + \n  theme_minimal() + \n  theme(axis.ticks = element_blank(), \n        plot.title = element_text(hjust = 0.5)) + \n  ggtitle(\"Number of Schools Required for an MDES of .25 by Design\")\n\nggplotly(p, tooltip = \"text\")\n\n\n\n\n\n\n\n\n\nBuilt-in Functionality for Plotting in PowerUpR\nPowerUpR also comes with a built-in plotting function. We will quickly check out PowerUpR::plot() with the baseline design.\nIt is not possible to plot the required sample size. Instead, we can either plot the statistical power as a function of the sample size (which is the default)…\n\nplot(d.0, main = \"Power as a Function of the Number of Schools\")\n\n\n\n\n… or we can plot the MDES along with its (1-α)*100% CI as a function of the required number of schools.\n\n# include `ypar = \"mdes\"` to plot the MDES\n# include `locate=TRUE` to locate parameter values for the applied design\nplot(d.0, ypar = \"mdes\", \n     main = \"MDES as a Function of Number of Schools\", locate = TRUE)"
  },
  {
    "objectID": "two-level.html#scenario-2-how-many-schools-are-required-for-a-2l-crt",
    "href": "two-level.html#scenario-2-how-many-schools-are-required-for-a-2l-crt",
    "title": "Two-Level Designs",
    "section": "Scenario 2: How Many Schools are Required for a 2L-CRT?",
    "text": "Scenario 2: How Many Schools are Required for a 2L-CRT?\nResearch Team 1 would like to conduct a 2L-CRT on the effectiveness of a school-wide intervention to improve 4th graders’ mathematical achievement in Germany. Team 1 plans to sample 40 students from each school. A standardized treatment effect of d = .25 is considered meaningful, because it represents around one quarter of the expected annual growth in mathematics from Grade 3 to Grade 4 in the German student population (Brunner et al., 2023, Table 1). How many schools are required to detect MDES = .25?\n\nStep 1: Choose the Design Parameters\nWhich data frame contains the appropriate design parameters?\n\n\n# -- choose data frame B9 \ndp_s1 &lt;- multides1[[\"B9_General-2l\"]] |&gt; \n  # filter mathematics in grade 4\n  filter(domain == \"Mathematics\", grade == 4)\n\nLet’s have a look at the relevant design parameters.\ndp_s1 |&gt; \n  # select the ICC and its standard error\n  select(contains(\"icc\")) |&gt; \n  round(2) |&gt; \n  pivot_longer(everything(), names_to = \"Variable\", values_to = \"Value\") |&gt; \n  kable()\n\n\n\n\nVariable\nValue\n\n\n\n\nicc_l3.est\n0.12\n\n\nicc_l3.se\n0.01\n\n\n\n\n\n\nStep 2: Define the Assumptions\n\nDesign AssumptionsFormula\n\n\n\n\n\n\n\n\n\nParameter\nPowerUpR Conversion\n\n\n\n\nTarget output\n\n\n\nMinimum required sample size of a 2L-CRT: Number of schools J\nmrss.cra2()\n\n\nStatistical test\n\n\n\nPower 1-β = .80\npower=.80 (default)\n\n\nSignificance level α = .05\nalpha=.05 (default)\n\n\nTwo-tailed test\ntwo.tailed=TRUE (default)\n\n\nSample sizes\n\n\n\nHarmonic mean number of L1 units per L2 unit n = 40\nn=40\n\n\nProportion of sample assigned to treatment P = .50 (balanced)\np=.50 (default)\n\n\nDesign parameters\n\n\n\nICC at L2 ρL2 = .12\nrho2=dp_s1$icc_l3.est\n\n\nFurther parameters\n\n\n\nMinimum detectable effect size MDES = .25\nes=.25\n\n\n\n\n\nBased on the expression for the MDES of a 2L-CRT with randomization/treatment assignment at L2 as given in (dong_maynard2013?), the number of schools \\(J\\) is computed as \\[\nJ = \\left(\\frac{M_{J-2}}{MDES}\\right)^2\\left(\\frac{\\rho_{L2}}{P(1-P)}+\\frac{(1-\\rho_{L2})}{P(1-P)n} \\right)\n\\] with\n\n\\(n\\) = harmonic mean number of L1 units per L2 unit\n\\(J\\) = number of L2 units\n\\(P\\) = \\(J_{TG}/J\\) = proportion of sample assigned to treatment\n\\(MDES\\) = minimum detectable effect size\n\\(M_{J-2}\\) = \\(t_{\\alpha/2}+t_{1-\\beta}\\) = multiplier for two-tailed test with \\(J-2\\) degrees of freedom\n\\(\\rho_{L2}\\) = achievement differences at L2 (ICC at L2)\n\n\n\n\n\n\nStep 3: Power Analysis with PowerUpR\n\nSimple Design with Default Assumptions\n\nd.0 &lt;- mrss.cra2(power=.80, alpha=.05, two.tailed=TRUE,\n                 n=40, p=.50,\n                 rho2=dp_s1$icc_l3.est, \n                 es=.25)\n\nJ = 73 \n\n\nGiven this design, at least 73 schools are necessary to detect an MDES of .25.\nOf course, it is also possible to directly insert the numeric values for the design parameters, but using the variables instead is safer, more precise, and prevents typos. Note that the results can differ due to rounding.\n\n# Note: Here, we are omitting all default parameters...\nd.01 &lt;- mrss.cra2(n=40, rho2=.12, es=.25)\n\nJ = 73 \n\n\n\n\nChanging the Default Assumptions\nEverything else being equal, what happens, when…\n\n(a) … power increases from 80% to 90%?\n\n# adjust the `power` argument to .90\nd.a &lt;- mrss.cra2(power=.90, \n                 n=40, rho2=dp_s1$icc_l3.est, es=.25)\n\nJ = 97 \n\n\nIncreasing power requires a larger number of schools.\nTip: We could also update the respective parameter in the list $parms stored in the mrss object and then call the function again with the modified argument.\n\n# save design 0 as a new design\nd.a &lt;- d.0\n# update `power` argument to .90\nd.a$parms$power=.90\n# call the function\nd.a &lt;- exec(\"mrss.cra2\", !!!d.a$parms)\n\nJ = 97 \n\n\n\n\n(b) … Type I error rate is set to 1%?\n\n# adjust the `alpha` argument to .01\nd.b &lt;- mrss.cra2(alpha=.01, \n                 n=40, rho2=dp_s1$icc_l3.est, es=.25)\n\nJ = 109 \n\n\nDecreasing the Type I error rate requires a larger number of schools.\n\n\n(c) … applying a one-tailed test?\n\n# adjust the `two.tailed` argument to FALSE\nd.c &lt;- mrss.cra2(two.tailed=FALSE, \n                 n=40, rho2=dp_s1$icc_l3.est, es=.25)\n\nJ = 57 \n\n\nTesting one-tailed requires a smaller number of schools.\n\n\n(d) … sampling 20/40/60/80/100 students per school?\n\n# adjust the `n` argument to 20/40/60/80/100\nd.d1 &lt;- mrss.cra2(n=20, rho2=dp_s1$icc_l3.est, es=.25)\nd.d2 &lt;- mrss.cra2(n=40, rho2=dp_s1$icc_l3.est, es=.25)\nd.d3 &lt;- mrss.cra2(n=60, rho2=dp_s1$icc_l3.est, es=.25)\nd.d4 &lt;- mrss.cra2(n=80, rho2=dp_s1$icc_l3.est, es=.25)\nd.d5 &lt;- mrss.cra2(n=100, rho2=dp_s1$icc_l3.est, es=.25)\n\nTip: Performing power analysis over a range of possible input parameters can be more easily done via vectorization. To vectorize the functions of PowerUpR over a range of possible input parameters (here: n = 20/40/60/80/100), we need to write a custom function similar to what is suggested by the package authors in their vignette on vectorization).\n\ncustom_mrss.cra2 &lt;- function(n) {\n  parms &lt;- list(n=n, rho2 = dp_s1$icc_l3.est, es=.25)\n  design &lt;- exec(\"mrss.cra2\", !!!parms)\n  design$J\n}\n\nNow we simply have to map the function across the various sample sizes.\n\n# number of students per school n = 20/40/60/80/100 \nn &lt;- seq(20, 100, 20)\nd.d &lt;- map_dbl(n, custom_mrss.cra2)\n\nJ = 84 \nJ = 73 \nJ = 69 \nJ = 67 \nJ = 66 \n\n\nSampling fewer/more students per school requires a larger/smaller number of schools. However, it becomes clear that increasing the number of students per school quickly reaches a point of diminishing returns.\n\n\n(e) … using an unbalanced design with 75% of the sample assigned to the treatment condition?\n\n# adjust the `p` argument to .75\nd.e &lt;- mrss.cra2(n=20, p=.75, rho2=dp_s1$icc_l3.est, es=.25)\n\nJ = 111 \n\n\nThe more pronounced the imbalance between experimental conditions, the larger the required number of schools.\n\n\n(f) … larger achievement differences of \\(\\rho\\) = .20 are assumed?\n\n# adjust `rho2` to .20\nd.f &lt;-mrss.cra2(n=40, rho2=.20, es=.25)\n\nJ = 112 \n\n\nLarger ICCs increase the required number of schools.\n\n\n\nIncorporating Statistical Uncertainty\nThe design parameters are estimates of population quantities, and thus, associated with statistical uncertainty. The uncertainty can be incorporated by using the standard errors for each design parameter. Assuming large-sample properties, research Team 1 uses the standard normal distribution to compute the limits for 95% confidence intervals by means of the standard errors for the design parameters. This approach has been labeled the the “safeguard” approach (Perugini et al., 2014). A conservative approach for planning the sample size is to use the upper bound estimate of the 95% CI for \\(\\rho\\).\n\n# lower bound\nd.g_lb &lt;- mrss.cra2(n=40, \n                    rho2 = dp_s1$icc_l3.est-1.96*dp_s1$icc_l3.se, \n                    es=.25)\n\nJ = 61 \n\n# upper bound\nd.g_ub &lt;- mrss.cra2(n=40, \n                    rho2 = dp_s1$icc_l3.est+1.96*dp_s1$icc_l3.se, \n                    es=.25)\n\nJ = 85 \n\n\nTaking statistical uncertainty into account, the required number of schools likely ranges between 61 and 85.\nNote that there are also other approaches to tackle uncertainties and/or heterogeneities in the input parameters. For instance, (Bayesian) simulation-based approaches to power analysis have been proposed that implicitly take into account uncertainty(see e.g., Moerbeek & Teerenstra, 2015; Pek & Park, 2019; Spiegelhalter et al., 2003; Turner et al., 2004).\n\n\n\nStep 4: Plotting\nLet’s plot the results. Move your cursor across the bars to learn about the required number schools for each design and how large the difference in % is compared to the baseline design.\n\n\nshow code\n\n\npackages &lt;- c(\"plotly\", \"htmlwidgets\")\n\ninvisible(\n  lapply(packages,\n         function(x) {\n           if (!require(x, character.only = TRUE)) {\n             install.packages(x, dependencies = TRUE); require(x, character.only = TRUE)}\n         }\n  )\n)\n\n\ndesign &lt;- list(d.0, d.a, d.b, d.c, d.d1, d.d3, d.d5, d.e, d.f, d.g_lb, d.g_ub) |&gt; \n  set_names(\"d.0\", \"d.a\", \"d.b\", \"d.c\", \"d.d1\", \"d.d3\", \"d.d5\", \"d.e\", \"d.f\", \"d.g_lb\", \"d.g_ub\")\n\ndelta &lt;- function(design) (design[[\"J\"]]-d.0[[\"J\"]])/d.0[[\"J\"]]*100\n\n\np &lt;- data.frame(design = factor(names(design)), \n                schools = map_dbl(design, ~.[[\"J\"]]), \n                delta = map_dbl(design, delta)) |&gt; \n  ggplot(aes(design, schools, text = paste(\n    factor(design, \n           levels = c(\"d.0\", \"d.a\", \"d.b\", \"d.c\", \"d.d1\", \"d.d3\", \"d.d5\", \"d.e\", \"d.f\", \"d.g_lb\", \"d.g_ub\"), \n           labels = c(\"The baseline design\", \n                      \"... increasing power to 90%\", \n                      \" ... setting Type I error rate to 1%\", \n                      \" ... applying a one-tailed test\", \n                      \"... sampling 20 students per school\", \n                      \"... sampling 60 students per school\", \n                      \"... sampling 100 students per school\", \n                      \"... assigning 75% of the schools to the treatment condition\", \n                      \"... assuming increased achievement differences at L2 of 20%\", \n                      \"... applying a liberal approach\",\n                      \"... applying a conservative approach\")),\n    \" requires J = \", schools, \" schools.\",\"\\n\",\n    ifelse(design == \"d.0\", \"\", \n           ifelse(design != \"d.0\" & delta &gt; 0, \n           paste0(\"This amounts to \", round(delta, 0), \n                  \"% more schools compared to the baseline design.\"),\n           ifelse(design != \"d.0\" & delta == 0, \n           \"The required number of schools does not change compared to the baseline design.\",\n           paste0(\"This amounts to \", round(delta, 0)*-1, \n                  \"% fewer schools compared to the baseline design.\")))),\n    sep = \"\"\n    ))) +\n  geom_bar(stat=\"identity\", width=0.9) + \n  scale_x_discrete(\"Design\") + \n  scale_y_continuous(\"Number of schools\") + \n  theme_minimal() + \n  theme(axis.ticks = element_blank(), \n        plot.title = element_text(hjust = 0.5)) + \n  ggtitle(\"Number of Schools Required for an MDES of .25 by Design\")\n\nggplotly(p, tooltip = \"text\")\n\n\n\n\n\n\n\n\n\nBuilt-in Functionality for Plotting in PowerUpR\nPowerUpR also comes with a built-in plotting function. We will quickly check out PowerUpR::plot() with the baseline design.\nIt is not possible to plot the required sample size. Instead, we can either plot the statistical power as a function of the sample size (which is the default)…\n\nplot(d.0, main = \"Power as a Function of the Number of Schools\")\n\n\n\n\n… or we can plot the MDES along with its (1-α)*100% CI as a function of the required number of schools.\n\n# include `ypar = \"mdes\"` to plot the MDES\n# include `locate=TRUE` to locate parameter values for the applied design\nplot(d.0, ypar = \"mdes\", \n     main = \"MDES as a Function of Number of Schools\", locate = TRUE)"
  },
  {
    "objectID": "three-level.html",
    "href": "three-level.html",
    "title": "Multilevel Designs",
    "section": "",
    "text": "The following exercises cover power analysis for cluster randomized trials (CRTs) with one treatment and one control condition (i.e., a two-arm study). We will walk through the process of planning two CRT designs:"
  },
  {
    "objectID": "three-level.html#scenario-1-how-many-schools-are-required-for-a-2l-crt",
    "href": "three-level.html#scenario-1-how-many-schools-are-required-for-a-2l-crt",
    "title": "Multilevel Designs",
    "section": "Scenario 1: How Many Schools are Required for a 2L-CRT?",
    "text": "Scenario 1: How Many Schools are Required for a 2L-CRT?\nResearch Team 1 would like to conduct a 2L-CRT on the effectiveness of a school-wide intervention to improve 4th graders’ mathematical achievement in Germany. Team 1 plans to sample 40 students from each school. A standardized treatment effect of d = .25 is considered meaningful, because it represents around one quarter of the expected annual growth in mathematics from Grade 3 to Grade 4 in the German student population (Brunner et al., 2023, Table 1). How many schools are required to detect MDES = .25?\n\nStep 1: Choose the Design Parameters\nWhich data frame contains the appropriate design parameters?\n\n\n# -- choose data frame B9 \ndp_s1 &lt;- multides1[[\"B9_General-2l\"]] |&gt; \n  # filter mathematics in grade 4\n  filter(domain == \"Mathematics\", grade == 4)\n\nLet’s have a look at the relevant design parameters.\ndp_s1 |&gt; \n  # select the ICC and its standard error\n  select(contains(\"icc\")) |&gt; \n  round(2) |&gt; \n  pivot_longer(everything(), names_to = \"Variable\", values_to = \"Value\") |&gt; \n  kable()\n\n\n\n\nVariable\nValue\n\n\n\n\nicc_l3.est\n0.12\n\n\nicc_l3.se\n0.01\n\n\n\n\n\n\nStep 2: Define the Assumptions\n\nDesign AssumptionsFormula\n\n\n\n\n\n\n\n\n\nParameter\nPowerUpR Conversion\n\n\n\n\nTarget output\n\n\n\nMinimum required sample size of a 2L-CRT: Number of schools J\nmrss.cra2()\n\n\nStatistical test\n\n\n\nPower 1-β = .80\npower=.80 (default)\n\n\nSignificance level α = .05\nalpha=.05 (default)\n\n\nTwo-tailed test\ntwo.tailed=TRUE (default)\n\n\nSample sizes\n\n\n\nHarmonic mean number of L1 units per L2 unit n = 40\nn=40\n\n\nProportion of sample assigned to treatment P = .50 (balanced)\np=.50 (default)\n\n\nDesign parameters\n\n\n\nICC at L2 ρL2 = .12\nrho2=dp_s1$icc_l3.est\n\n\nFurther parameters\n\n\n\nMinimum detectable effect size MDES = .25\nes=.25\n\n\n\n\n\nBased on the expression for the MDES of a 2L-CRT with randomization/treatment assignment at L2 as given in (dong_maynard2013?), the number of schools \\(J\\) is computed as \\[\nJ = \\left(\\frac{M_{J-2}}{MDES}\\right)^2\\left(\\frac{\\rho_{L2}}{P(1-P)}+\\frac{(1-\\rho_{L2})}{P(1-P)n} \\right)\n\\] with\n\n\\(n\\) = harmonic mean number of L1 units per L2 unit\n\\(J\\) = number of L2 units\n\\(P\\) = \\(J_{TG}/J\\) = proportion of sample assigned to treatment\n\\(MDES\\) = minimum detectable effect size\n\\(M_{J-2}\\) = \\(t_{\\alpha/2}+t_{1-\\beta}\\) = multiplier for two-tailed test with \\(J-2\\) degrees of freedom\n\\(\\rho_{L2}\\) = achievement differences at L2 (ICC at L2)\n\n\n\n\n\n\nStep 3: Power Analysis with PowerUpR\n\nSimple Design with Default Assumptions\n\nd.0 &lt;- mrss.cra2(power=.80, alpha=.05, two.tailed=TRUE,\n                 n=40, p=.50,\n                 rho2=dp_s1$icc_l3.est, \n                 es=.25)\n\nJ = 73 \n\n\nGiven this design, at least 73 schools are necessary to detect an MDES of .25.\nOf course, it is also possible to directly insert the numeric values for the design parameters, but using the variables instead is safer, more precise, and prevents typos. Note that the results can differ due to rounding.\n\n# Note: Here, we are omitting all default parameters...\nd.01 &lt;- mrss.cra2(n=40, rho2=.12, es=.25)\n\nJ = 73 \n\n\n\n\nChanging the Default Assumptions\nEverything else being equal, what happens, when…\n\n(a) … power increases from 80% to 90%?\n\n# adjust the `power` argument to .90\nd.a &lt;- mrss.cra2(power=.90, \n                 n=40, rho2=dp_s1$icc_l3.est, es=.25)\n\nJ = 97 \n\n\nIncreasing power requires a larger number of schools.\nTip: We could also update the respective parameter in the list $parms stored in the mrss object and then call the function again with the modified argument.\n\n# save design 0 as a new design\nd.a &lt;- d.0\n# update `power` argument to .90\nd.a$parms$power=.90\n# call the function\nd.a &lt;- exec(\"mrss.cra2\", !!!d.a$parms)\n\nJ = 97 \n\n\n\n\n(b) … Type I error rate is set to 1%?\n\n# adjust the `alpha` argument to .01\nd.b &lt;- mrss.cra2(alpha=.01, \n                 n=40, rho2=dp_s1$icc_l3.est, es=.25)\n\nJ = 109 \n\n\nDecreasing the Type I error rate requires a larger number of schools.\n\n\n(c) … applying a one-tailed test?\n\n# adjust the `two.tailed` argument to FALSE\nd.c &lt;- mrss.cra2(two.tailed=FALSE, \n                 n=40, rho2=dp_s1$icc_l3.est, es=.25)\n\nJ = 57 \n\n\nTesting one-tailed requires a smaller number of schools.\n\n\n(d) … sampling 20/40/60/80/100 students per school?\n\n# adjust the `n` argument to 20/40/60/80/100\nd.d1 &lt;- mrss.cra2(n=20, rho2=dp_s1$icc_l3.est, es=.25)\nd.d2 &lt;- mrss.cra2(n=40, rho2=dp_s1$icc_l3.est, es=.25)\nd.d3 &lt;- mrss.cra2(n=60, rho2=dp_s1$icc_l3.est, es=.25)\nd.d4 &lt;- mrss.cra2(n=80, rho2=dp_s1$icc_l3.est, es=.25)\nd.d5 &lt;- mrss.cra2(n=100, rho2=dp_s1$icc_l3.est, es=.25)\n\nTip: Performing power analysis over a range of possible input parameters can be more easily done via vectorization. To vectorize the functions of PowerUpR over a range of possible input parameters (here: n = 20/40/60/80/100), we need to write a custom function similar to what is suggested by the package authors in their vignette on vectorization).\n\ncustom_mrss.cra2 &lt;- function(n) {\n  parms &lt;- list(n=n, rho2 = dp_s1$icc_l3.est, es=.25)\n  design &lt;- exec(\"mrss.cra2\", !!!parms)\n  design$J\n}\n\nNow we simply have to map the function across the various sample sizes.\n\n# number of students per school n = 20/40/60/80/100 \nn &lt;- seq(20, 100, 20)\nd.d &lt;- map_dbl(n, custom_mrss.cra2)\n\nJ = 84 \nJ = 73 \nJ = 69 \nJ = 67 \nJ = 66 \n\n\nSampling fewer/more students per school requires a larger/smaller number of schools. However, it becomes clear that increasing the number of students per school quickly reaches a point of diminishing returns.\n\n\n(e) … using an unbalanced design with 75% of the sample assigned to the treatment condition?\n\n# adjust the `p` argument to .75\nd.e &lt;- mrss.cra2(n=20, p=.75, rho2=dp_s1$icc_l3.est, es=.25)\n\nJ = 111 \n\n\nThe more pronounced the imbalance between experimental conditions, the larger the required number of schools.\n\n\n(f) … larger achievement differences of \\(\\rho\\) = .20 are assumed?\n\n# adjust `rho2` to .20\nd.f &lt;-mrss.cra2(n=40, rho2=.20, es=.25)\n\nJ = 112 \n\n\nLarger ICCs increase the required number of schools.\n\n\n\nIncorporating Statistical Uncertainty\nThe design parameters are estimates of population quantities, and thus, associated with statistical uncertainty. The uncertainty can be incorporated by using the standard errors for each design parameter. Assuming large-sample properties, research Team 1 uses the standard normal distribution to compute the limits for 95% confidence intervals by means of the standard errors for the design parameters. This approach has been labeled the the “safeguard” approach (Perugini et al., 2014). A conservative approach for planning the sample size is to use the upper bound estimate of the 95% CI for \\(\\rho\\).\n\n# lower bound\nd.g_lb &lt;- mrss.cra2(n=40, \n                    rho2 = dp_s1$icc_l3.est-1.96*dp_s1$icc_l3.se, \n                    es=.25)\n\nJ = 61 \n\n# upper bound\nd.g_ub &lt;- mrss.cra2(n=40, \n                    rho2 = dp_s1$icc_l3.est+1.96*dp_s1$icc_l3.se, \n                    es=.25)\n\nJ = 85 \n\n\nTaking statistical uncertainty into account, the required number of schools likely ranges between 61 and 85.\nNote that there are also other approaches to tackle uncertainties and/or heterogeneities in the input parameters. For instance, (Bayesian) simulation-based approaches to power analysis have been proposed that implicitly take into account uncertainty(see e.g., Moerbeek & Teerenstra, 2015; Pek & Park, 2019; Spiegelhalter et al., 2003; Turner et al., 2004).\n\n\n\nStep 4: Plotting\nLet’s plot the results. Move your cursor across the bars to learn about the required number schools for each design and how large the difference in % is compared to the baseline design.\n\n\nshow code\n\n\npackages &lt;- c(\"plotly\", \"htmlwidgets\")\n\ninvisible(\n  lapply(packages,\n         function(x) {\n           if (!require(x, character.only = TRUE)) {\n             install.packages(x, dependencies = TRUE); require(x, character.only = TRUE)}\n         }\n  )\n)\n\n\ndesign &lt;- list(d.0, d.a, d.b, d.c, d.d1, d.d3, d.d5, d.e, d.f, d.g_lb, d.g_ub) |&gt; \n  set_names(\"d.0\", \"d.a\", \"d.b\", \"d.c\", \"d.d1\", \"d.d3\", \"d.d5\", \"d.e\", \"d.f\", \"d.g_lb\", \"d.g_ub\")\n\ndelta &lt;- function(design) (design[[\"J\"]]-d.0[[\"J\"]])/d.0[[\"J\"]]*100\n\n\np &lt;- data.frame(design = factor(names(design)), \n                schools = map_dbl(design, ~.[[\"J\"]]), \n                delta = map_dbl(design, delta)) |&gt; \n  ggplot(aes(design, schools, text = paste(\n    factor(design, \n           levels = c(\"d.0\", \"d.a\", \"d.b\", \"d.c\", \"d.d1\", \"d.d3\", \"d.d5\", \"d.e\", \"d.f\", \"d.g_lb\", \"d.g_ub\"), \n           labels = c(\"The baseline design\", \n                      \"... increasing power to 90%\", \n                      \" ... setting Type I error rate to 1%\", \n                      \" ... applying a one-tailed test\", \n                      \"... sampling 20 students per school\", \n                      \"... sampling 60 students per school\", \n                      \"... sampling 100 students per school\", \n                      \"... assigning 75% of the schools to the treatment condition\", \n                      \"... assuming increased achievement differences at L2 of 20%\", \n                      \"... applying a liberal approach\",\n                      \"... applying a conservative approach\")),\n    \" requires J = \", schools, \" schools.\",\"\\n\",\n    ifelse(design == \"d.0\", \"\", \n           ifelse(design != \"d.0\" & delta &gt; 0, \n           paste0(\"This amounts to \", round(delta, 0), \n                  \"% more schools compared to the baseline design.\"),\n           ifelse(design != \"d.0\" & delta == 0, \n           \"The required number of schools does not change compared to the baseline design.\",\n           paste0(\"This amounts to \", round(delta, 0)*-1, \n                  \"% fewer schools compared to the baseline design.\")))),\n    sep = \"\"\n    ))) +\n  geom_bar(stat=\"identity\", width=0.9) + \n  scale_x_discrete(\"Design\") + \n  scale_y_continuous(\"Number of schools\") + \n  theme_minimal() + \n  theme(axis.ticks = element_blank(), \n        plot.title = element_text(hjust = 0.5)) + \n  ggtitle(\"Number of Schools Required for an MDES of .25 by Design\")\n\nggplotly(p, tooltip = \"text\")\n\n\n\n\n\n\n\n\n\nBuilt-in Functionality for Plotting in PowerUpR\nPowerUpR also comes with a built-in plotting function. We will quickly check out PowerUpR::plot() with the baseline design.\nIt is not possible to plot the required sample size. Instead, we can either plot the statistical power as a function of the sample size (which is the default)…\n\nplot(d.0, main = \"Power as a Function of the Number of Schools\")\n\n\n\n\n… or we can plot the MDES along with its (1-α)*100% CI as a function of the required number of schools.\n\n# include `ypar = \"mdes\"` to plot the MDES\n# include `locate=TRUE` to locate parameter values for the applied design\nplot(d.0, ypar = \"mdes\", \n     main = \"MDES as a Function of Number of Schools\", locate = TRUE)"
  },
  {
    "objectID": "three-level.html#scenario-2-how-many-schools-are-required-for-a-2l-crt",
    "href": "three-level.html#scenario-2-how-many-schools-are-required-for-a-2l-crt",
    "title": "Multilevel Designs",
    "section": "Scenario 2: How Many Schools are Required for a 2L-CRT?",
    "text": "Scenario 2: How Many Schools are Required for a 2L-CRT?\nResearch Team 1 would like to conduct a 2L-CRT on the effectiveness of a school-wide intervention to improve 4th graders’ mathematical achievement in Germany. Team 1 plans to sample 40 students from each school. A standardized treatment effect of d = .25 is considered meaningful, because it represents around one quarter of the expected annual growth in mathematics from Grade 3 to Grade 4 in the German student population (Brunner et al., 2023, Table 1). How many schools are required to detect MDES = .25?\n\nStep 1: Choose the Design Parameters\nWhich data frame contains the appropriate design parameters?\n\n\n# -- choose data frame B9 \ndp_s1 &lt;- multides1[[\"B9_General-2l\"]] |&gt; \n  # filter mathematics in grade 4\n  filter(domain == \"Mathematics\", grade == 4)\n\nLet’s have a look at the relevant design parameters.\ndp_s1 |&gt; \n  # select the ICC and its standard error\n  select(contains(\"icc\")) |&gt; \n  round(2) |&gt; \n  pivot_longer(everything(), names_to = \"Variable\", values_to = \"Value\") |&gt; \n  kable()\n\n\n\n\nVariable\nValue\n\n\n\n\nicc_l3.est\n0.12\n\n\nicc_l3.se\n0.01\n\n\n\n\n\n\nStep 2: Define the Assumptions\n\nDesign AssumptionsFormula\n\n\n\n\n\n\n\n\n\nParameter\nPowerUpR Conversion\n\n\n\n\nTarget output\n\n\n\nMinimum required sample size of a 2L-CRT: Number of schools J\nmrss.cra2()\n\n\nStatistical test\n\n\n\nPower 1-β = .80\npower=.80 (default)\n\n\nSignificance level α = .05\nalpha=.05 (default)\n\n\nTwo-tailed test\ntwo.tailed=TRUE (default)\n\n\nSample sizes\n\n\n\nHarmonic mean number of L1 units per L2 unit n = 40\nn=40\n\n\nProportion of sample assigned to treatment P = .50 (balanced)\np=.50 (default)\n\n\nDesign parameters\n\n\n\nICC at L2 ρL2 = .12\nrho2=dp_s1$icc_l3.est\n\n\nFurther parameters\n\n\n\nMinimum detectable effect size MDES = .25\nes=.25\n\n\n\n\n\nBased on the expression for the MDES of a 2L-CRT with randomization/treatment assignment at L2 as given in (dong_maynard2013?), the number of schools \\(J\\) is computed as \\[\nJ = \\left(\\frac{M_{J-2}}{MDES}\\right)^2\\left(\\frac{\\rho_{L2}}{P(1-P)}+\\frac{(1-\\rho_{L2})}{P(1-P)n} \\right)\n\\] with\n\n\\(n\\) = harmonic mean number of L1 units per L2 unit\n\\(J\\) = number of L2 units\n\\(P\\) = \\(J_{TG}/J\\) = proportion of sample assigned to treatment\n\\(MDES\\) = minimum detectable effect size\n\\(M_{J-2}\\) = \\(t_{\\alpha/2}+t_{1-\\beta}\\) = multiplier for two-tailed test with \\(J-2\\) degrees of freedom\n\\(\\rho_{L2}\\) = achievement differences at L2 (ICC at L2)\n\n\n\n\n\n\nStep 3: Power Analysis with PowerUpR\n\nSimple Design with Default Assumptions\n\nd.0 &lt;- mrss.cra2(power=.80, alpha=.05, two.tailed=TRUE,\n                 n=40, p=.50,\n                 rho2=dp_s1$icc_l3.est, \n                 es=.25)\n\nJ = 73 \n\n\nGiven this design, at least 73 schools are necessary to detect an MDES of .25.\nOf course, it is also possible to directly insert the numeric values for the design parameters, but using the variables instead is safer, more precise, and prevents typos. Note that the results can differ due to rounding.\n\n# Note: Here, we are omitting all default parameters...\nd.01 &lt;- mrss.cra2(n=40, rho2=.12, es=.25)\n\nJ = 73 \n\n\n\n\nChanging the Default Assumptions\nEverything else being equal, what happens, when…\n\n(a) … power increases from 80% to 90%?\n\n# adjust the `power` argument to .90\nd.a &lt;- mrss.cra2(power=.90, \n                 n=40, rho2=dp_s1$icc_l3.est, es=.25)\n\nJ = 97 \n\n\nIncreasing power requires a larger number of schools.\nTip: We could also update the respective parameter in the list $parms stored in the mrss object and then call the function again with the modified argument.\n\n# save design 0 as a new design\nd.a &lt;- d.0\n# update `power` argument to .90\nd.a$parms$power=.90\n# call the function\nd.a &lt;- exec(\"mrss.cra2\", !!!d.a$parms)\n\nJ = 97 \n\n\n\n\n(b) … Type I error rate is set to 1%?\n\n# adjust the `alpha` argument to .01\nd.b &lt;- mrss.cra2(alpha=.01, \n                 n=40, rho2=dp_s1$icc_l3.est, es=.25)\n\nJ = 109 \n\n\nDecreasing the Type I error rate requires a larger number of schools.\n\n\n(c) … applying a one-tailed test?\n\n# adjust the `two.tailed` argument to FALSE\nd.c &lt;- mrss.cra2(two.tailed=FALSE, \n                 n=40, rho2=dp_s1$icc_l3.est, es=.25)\n\nJ = 57 \n\n\nTesting one-tailed requires a smaller number of schools.\n\n\n(d) … sampling 20/40/60/80/100 students per school?\n\n# adjust the `n` argument to 20/40/60/80/100\nd.d1 &lt;- mrss.cra2(n=20, rho2=dp_s1$icc_l3.est, es=.25)\nd.d2 &lt;- mrss.cra2(n=40, rho2=dp_s1$icc_l3.est, es=.25)\nd.d3 &lt;- mrss.cra2(n=60, rho2=dp_s1$icc_l3.est, es=.25)\nd.d4 &lt;- mrss.cra2(n=80, rho2=dp_s1$icc_l3.est, es=.25)\nd.d5 &lt;- mrss.cra2(n=100, rho2=dp_s1$icc_l3.est, es=.25)\n\nTip: Performing power analysis over a range of possible input parameters can be more easily done via vectorization. To vectorize the functions of PowerUpR over a range of possible input parameters (here: n = 20/40/60/80/100), we need to write a custom function similar to what is suggested by the package authors in their vignette on vectorization).\n\ncustom_mrss.cra2 &lt;- function(n) {\n  parms &lt;- list(n=n, rho2 = dp_s1$icc_l3.est, es=.25)\n  design &lt;- exec(\"mrss.cra2\", !!!parms)\n  design$J\n}\n\nNow we simply have to map the function across the various sample sizes.\n\n# number of students per school n = 20/40/60/80/100 \nn &lt;- seq(20, 100, 20)\nd.d &lt;- map_dbl(n, custom_mrss.cra2)\n\nJ = 84 \nJ = 73 \nJ = 69 \nJ = 67 \nJ = 66 \n\n\nSampling fewer/more students per school requires a larger/smaller number of schools. However, it becomes clear that increasing the number of students per school quickly reaches a point of diminishing returns.\n\n\n(e) … using an unbalanced design with 75% of the sample assigned to the treatment condition?\n\n# adjust the `p` argument to .75\nd.e &lt;- mrss.cra2(n=20, p=.75, rho2=dp_s1$icc_l3.est, es=.25)\n\nJ = 111 \n\n\nThe more pronounced the imbalance between experimental conditions, the larger the required number of schools.\n\n\n(f) … larger achievement differences of \\(\\rho\\) = .20 are assumed?\n\n# adjust `rho2` to .20\nd.f &lt;-mrss.cra2(n=40, rho2=.20, es=.25)\n\nJ = 112 \n\n\nLarger ICCs increase the required number of schools.\n\n\n\nIncorporating Statistical Uncertainty\nThe design parameters are estimates of population quantities, and thus, associated with statistical uncertainty. The uncertainty can be incorporated by using the standard errors for each design parameter. Assuming large-sample properties, research Team 1 uses the standard normal distribution to compute the limits for 95% confidence intervals by means of the standard errors for the design parameters. This approach has been labeled the the “safeguard” approach (Perugini et al., 2014). A conservative approach for planning the sample size is to use the upper bound estimate of the 95% CI for \\(\\rho\\).\n\n# lower bound\nd.g_lb &lt;- mrss.cra2(n=40, \n                    rho2 = dp_s1$icc_l3.est-1.96*dp_s1$icc_l3.se, \n                    es=.25)\n\nJ = 61 \n\n# upper bound\nd.g_ub &lt;- mrss.cra2(n=40, \n                    rho2 = dp_s1$icc_l3.est+1.96*dp_s1$icc_l3.se, \n                    es=.25)\n\nJ = 85 \n\n\nTaking statistical uncertainty into account, the required number of schools likely ranges between 61 and 85.\nNote that there are also other approaches to tackle uncertainties and/or heterogeneities in the input parameters. For instance, (Bayesian) simulation-based approaches to power analysis have been proposed that implicitly take into account uncertainty(see e.g., Moerbeek & Teerenstra, 2015; Pek & Park, 2019; Spiegelhalter et al., 2003; Turner et al., 2004).\n\n\n\nStep 4: Plotting\nLet’s plot the results. Move your cursor across the bars to learn about the required number schools for each design and how large the difference in % is compared to the baseline design.\n\n\nshow code\n\n\npackages &lt;- c(\"plotly\", \"htmlwidgets\")\n\ninvisible(\n  lapply(packages,\n         function(x) {\n           if (!require(x, character.only = TRUE)) {\n             install.packages(x, dependencies = TRUE); require(x, character.only = TRUE)}\n         }\n  )\n)\n\n\ndesign &lt;- list(d.0, d.a, d.b, d.c, d.d1, d.d3, d.d5, d.e, d.f, d.g_lb, d.g_ub) |&gt; \n  set_names(\"d.0\", \"d.a\", \"d.b\", \"d.c\", \"d.d1\", \"d.d3\", \"d.d5\", \"d.e\", \"d.f\", \"d.g_lb\", \"d.g_ub\")\n\ndelta &lt;- function(design) (design[[\"J\"]]-d.0[[\"J\"]])/d.0[[\"J\"]]*100\n\n\np &lt;- data.frame(design = factor(names(design)), \n                schools = map_dbl(design, ~.[[\"J\"]]), \n                delta = map_dbl(design, delta)) |&gt; \n  ggplot(aes(design, schools, text = paste(\n    factor(design, \n           levels = c(\"d.0\", \"d.a\", \"d.b\", \"d.c\", \"d.d1\", \"d.d3\", \"d.d5\", \"d.e\", \"d.f\", \"d.g_lb\", \"d.g_ub\"), \n           labels = c(\"The baseline design\", \n                      \"... increasing power to 90%\", \n                      \" ... setting Type I error rate to 1%\", \n                      \" ... applying a one-tailed test\", \n                      \"... sampling 20 students per school\", \n                      \"... sampling 60 students per school\", \n                      \"... sampling 100 students per school\", \n                      \"... assigning 75% of the schools to the treatment condition\", \n                      \"... assuming increased achievement differences at L2 of 20%\", \n                      \"... applying a liberal approach\",\n                      \"... applying a conservative approach\")),\n    \" requires J = \", schools, \" schools.\",\"\\n\",\n    ifelse(design == \"d.0\", \"\", \n           ifelse(design != \"d.0\" & delta &gt; 0, \n           paste0(\"This amounts to \", round(delta, 0), \n                  \"% more schools compared to the baseline design.\"),\n           ifelse(design != \"d.0\" & delta == 0, \n           \"The required number of schools does not change compared to the baseline design.\",\n           paste0(\"This amounts to \", round(delta, 0)*-1, \n                  \"% fewer schools compared to the baseline design.\")))),\n    sep = \"\"\n    ))) +\n  geom_bar(stat=\"identity\", width=0.9) + \n  scale_x_discrete(\"Design\") + \n  scale_y_continuous(\"Number of schools\") + \n  theme_minimal() + \n  theme(axis.ticks = element_blank(), \n        plot.title = element_text(hjust = 0.5)) + \n  ggtitle(\"Number of Schools Required for an MDES of .25 by Design\")\n\nggplotly(p, tooltip = \"text\")\n\n\n\n\n\n\n\n\n\nBuilt-in Functionality for Plotting in PowerUpR\nPowerUpR also comes with a built-in plotting function. We will quickly check out PowerUpR::plot() with the baseline design.\nIt is not possible to plot the required sample size. Instead, we can either plot the statistical power as a function of the sample size (which is the default)…\n\nplot(d.0, main = \"Power as a Function of the Number of Schools\")\n\n\n\n\n… or we can plot the MDES along with its (1-α)*100% CI as a function of the required number of schools.\n\n# include `ypar = \"mdes\"` to plot the MDES\n# include `locate=TRUE` to locate parameter values for the applied design\nplot(d.0, ypar = \"mdes\", \n     main = \"MDES as a Function of Number of Schools\", locate = TRUE)"
  },
  {
    "objectID": "index.html#setup",
    "href": "index.html#setup",
    "title": "Workshop: Power Analysis for Experimental Designs in R with the PowerUpR Package",
    "section": "Setup",
    "text": "Setup\nFirst of all, check that you have the latest version of R and RStudio.\nYou can install the latest version of PowerUpR (currently, this is version 1.1.0) from CRAN. Throughout this tutorial, we will also use a bunch of tidyverse (Wickham et al., 2019) functions, as well as the kableExtra package (Zhu, 2024), so make sure you have installed these packages (for details on the versions used here, see the section “Session Info” below).\n\n# -- required packages\npkg &lt;- c(\"PowerUpR\", \"tidyverse\", \"kableExtra\")\n\n\n# -- load packages (or install from CRAN if not installed)\ninvisible(\n  lapply(pkg,\n         function(x) {\n           if (!require(x, character.only = TRUE)) {\n             install.packages(x, dependencies = TRUE)\n             require(x, character.only = TRUE)}\n         }\n  )\n)"
  },
  {
    "objectID": "index.html#the-powerupr-package",
    "href": "index.html#the-powerupr-package",
    "title": "Workshop: Power Analysis for Experimental Designs in R with the ‘PowerUpR’ Package",
    "section": "The PowerUpR Package",
    "text": "The PowerUpR Package\nThe PowerUpR Package provides functions to conduct three types of power analysis, depending on the desired output and the applied design. Specifically, PowerUpR offers power analysis tools to plan individually, multisite, and cluster randomized designs with up to four hierarchical levels. Note that this workshop covers only a selection thereof; namely, individually randomized trials (IRTs), two-level cluster randomized trials (2L-CRTs), and three-level cluster randomized trials (3L-CRTs). Multisite trials (MSRTs) are not covered. However, if you want to learn about power analysis for such designs, you may want to check out the illustrations and exercises at https://sophiestallasch.github.io/2022-workshop-CRT/#Multisite_Trials).\n\n\n\n\n\n\n\n\n\nOutput\nIRT Functions\n2L-CRT Functions\n3L-CRT Function\n\n\n\n\nMinimum required sample size (MRSS)\nmrss.ira()\nmrss.cra2()\nmrss.cra3()\n\n\nMinimum detectable effect size (MDES)\nmdes.ira()\nmdes.cra2()\nmdes.cra3()\n\n\nPower\npower.ira()\npower.cra()\npower.cra3()\n\n\n\nGo to the PowerUpR Documentation to see details on the arguments etc."
  },
  {
    "objectID": "index.html#tsession-info",
    "href": "index.html#tsession-info",
    "title": "Workshop: Power Analysis for Experimental Designs in R with the ‘PowerUpR’ Package",
    "section": "TSession Info",
    "text": "TSession Info\n\nsessionInfo()\n\nR version 4.3.3 (2024-02-29 ucrt)\nPlatform: x86_64-w64-mingw32/x64 (64-bit)\nRunning under: Windows 11 x64 (build 22631)\n\nMatrix products: default\n\n\nlocale:\n[1] LC_COLLATE=German_Germany.utf8  LC_CTYPE=German_Germany.utf8   \n[3] LC_MONETARY=German_Germany.utf8 LC_NUMERIC=C                   \n[5] LC_TIME=German_Germany.utf8    \n\ntime zone: Europe/Berlin\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] kableExtra_1.4.0 lubridate_1.9.3  forcats_1.0.0    stringr_1.5.1   \n [5] dplyr_1.1.4      purrr_1.0.2      readr_2.1.5      tidyr_1.3.1     \n [9] tibble_3.2.1     ggplot2_3.5.0    tidyverse_2.0.0  PowerUpR_1.1.0  \n\nloaded via a namespace (and not attached):\n [1] gtable_0.3.4      jsonlite_1.8.8    compiler_4.3.3    tidyselect_1.2.0 \n [5] xml2_1.3.6        systemfonts_1.0.5 scales_1.3.0      yaml_2.3.8       \n [9] fastmap_1.1.1     R6_2.5.1          generics_0.1.3    knitr_1.45       \n[13] htmlwidgets_1.6.4 munsell_0.5.0     svglite_2.1.3     pillar_1.9.0     \n[17] tzdb_0.4.0        rlang_1.1.3       utf8_1.2.4        stringi_1.8.3    \n[21] xfun_0.42         viridisLite_0.4.2 timechange_0.3.0  cli_3.6.2        \n[25] withr_3.0.0       magrittr_2.0.3    digest_0.6.34     grid_4.3.3       \n[29] rstudioapi_0.15.0 hms_1.1.3         lifecycle_1.0.4   vctrs_0.6.5      \n[33] evaluate_0.23     glue_1.7.0        fansi_1.0.6       colorspace_2.1-0 \n[37] rmarkdown_2.26    tools_4.3.3       pkgconfig_2.0.3   htmltools_0.5.7"
  },
  {
    "objectID": "index.html#worked-example",
    "href": "index.html#worked-example",
    "title": "Workshop: Power Analysis for Experimental Designs in R with the ‘PowerUpR’ Package",
    "section": "Worked Example",
    "text": "Worked Example\nTo illustrate the process of performing power analysis with PowerUpR, we will use the following worked example of an intervention to foster student achievement:\n\n\n\n\n\n\nA research team has programmed a comprehensive learning app. It is meant to function as a multidisciplinary digital learning environment for students in various grade levels in the German school system. Therefore, it can be used to support teaching and learning in manifold achievement domains throughout the entire school career. The researchers aim to experimentally evaluate whether the app actually improves student achievement."
  },
  {
    "objectID": "index.html#session-info",
    "href": "index.html#session-info",
    "title": "Workshop: Power Analysis for Experimental Designs in R with the PowerUpR Package",
    "section": "Session Info",
    "text": "Session Info\n\n\nR version 4.3.3 (2024-02-29 ucrt)\nPlatform: x86_64-w64-mingw32/x64 (64-bit)\nRunning under: Windows 11 x64 (build 22631)\n\nMatrix products: default\n\n\nlocale:\n[1] LC_COLLATE=German_Germany.utf8  LC_CTYPE=German_Germany.utf8   \n[3] LC_MONETARY=German_Germany.utf8 LC_NUMERIC=C                   \n[5] LC_TIME=German_Germany.utf8    \n\ntime zone: Europe/Berlin\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] kableExtra_1.4.0 lubridate_1.9.3  forcats_1.0.0    stringr_1.5.1   \n [5] dplyr_1.1.4      purrr_1.0.2      readr_2.1.5      tidyr_1.3.1     \n [9] tibble_3.2.1     ggplot2_3.5.0    tidyverse_2.0.0  PowerUpR_1.1.0  \n\nloaded via a namespace (and not attached):\n [1] gtable_0.3.4      jsonlite_1.8.8    compiler_4.3.3    tidyselect_1.2.0 \n [5] xml2_1.3.6        systemfonts_1.0.5 scales_1.3.0      yaml_2.3.8       \n [9] fastmap_1.1.1     R6_2.5.1          generics_0.1.3    knitr_1.45       \n[13] htmlwidgets_1.6.4 munsell_0.5.0     svglite_2.1.3     pillar_1.9.0     \n[17] tzdb_0.4.0        rlang_1.1.3       utf8_1.2.4        stringi_1.8.3    \n[21] xfun_0.42         viridisLite_0.4.2 timechange_0.3.0  cli_3.6.2        \n[25] withr_3.0.0       magrittr_2.0.3    digest_0.6.34     grid_4.3.3       \n[29] rstudioapi_0.15.0 hms_1.1.3         lifecycle_1.0.4   vctrs_0.6.5      \n[33] evaluate_0.23     glue_1.7.0        fansi_1.0.6       colorspace_2.1-0 \n[37] rmarkdown_2.26    tools_4.3.3       pkgconfig_2.0.3   htmltools_0.5.7"
  },
  {
    "objectID": "single-level.html#illustration-of-the-worked-example",
    "href": "single-level.html#illustration-of-the-worked-example",
    "title": "Single-Level Designs",
    "section": "Illustration of the Worked Example",
    "text": "Illustration of the Worked Example\n\nlibrary(PowerUpR)\nlibrary(tidyverse)\n\n\n\n\n\n\n\nWorked Example\n\n\n\nA research team has programmed a comprehensive learning app. It is meant to function as a multidisciplinary digital learning environment for students in various grade levels in the German school system. Therefore, it can be used to support teaching and learning in manifold achievement domains throughout the entire school career. The researchers aim to experimentally evaluate whether the app actually improves student achievement.\n\n\nAs a first step, the researchers aim to test the general efficacy of the underlying didactic approach. To this end, they plan a small-scale pilot IRT with elementary school students.\n\nScenario 1: Determining Statistical Power\nHow much power is achieved to detect a certain hypothesized treatment effect, given a specified number of students?\nThe research team considers a standardized treatment effect of d = .22 as meaningful, because it represents around one quarter of the expected annual growth in students’ achievement across elementary school for the German student population (Brunner et al., 2023, Table 1). The team wonders how much power can be achieved when sampling and randomizing N = 300 students in total to detect MDES = .22 at significance level α = .05 in a two-tailed t-test with power 1−β = .80. The researchers assume a balanced design, where students are allocated to the treatment group (TG) and control group (CG) in equal shares (i.e., nTG = nCG).\n\nFormula\nThe expressions to compute statistical power for IRTs (and also for multilevel RT designs) involve the cumulative distribution function of the noncentral t-distribution and are given in OSM C in Stallasch et al. (2023), and also in Hedges & Hedberg (2007) and Liu (2013).\n\n\nPower Analysis with PowerUpR\nThe R code looks like this:\n\npower.ira(\n  # properties of the statistical test\n  alpha=.05, two.tailed=TRUE, \n  # sample size and sample allocation ratio\n  n=300, p=.50,\n  # hypothesized effect size\n  es=.22,\n  # possibly applied covariates\n  g1=0, r21=0\n  )\n\nwith\n\n\n\n\n\n\n\n\nParameter\nDefinition\nPowerUpR argument\n\n\n\n\n\\(M_{n-g^*-2}\\)\nmultiplier for a two-tailed test \\(t_{\\alpha/2}+t_{1-\\beta}\\) with \\(n-g^*-2\\) degrees of freedom\npower=.80, alpha=.05,two.tailed=TRUE\n\n\n\\(MDES\\)\nminimum detectable effect size\nes=.25\n\n\n\\(n\\)\nmean number of students\nn\n\n\n\\(P\\)\nproportion of sample assigned to treatment \\(n_{TG}/N\\)\np=.50\n\n\n\\(g^*\\)\nnumber of covariates\ng1=0\n\n\n\\(R^2\\)\nexplained variance by covariates\nr21=0\n\n\n\nThe output looks like this:1\n\n\n\nStatistical power: \n--------------------------------------- \n 0.476\n--------------------------------------- \nDegrees of freedom: 298\nStandardized standard error: 0.115\nType I error rate: 0.05\nType II error rate: 0.524\nTwo-tailed test: TRUE\n\n\nThe achieved power level is well below an acceptable threshold for this design.\nAs we learned before, power increases with…\n\nincreasing Type I error rate (or, using a one-sided instead of a two-sided test)\nincreasing sample size\nincreasing effect size\n\nLet’s adjust some of the arguments and see, what happens.\nSet the alpha argument to .10.\n\npower.ira(alpha=.10, two.tailed=TRUE, n=300, p=.50, es=.22)\n\n\nStatistical power: \n--------------------------------------- \n 0.601\n--------------------------------------- \nDegrees of freedom: 298\nStandardized standard error: 0.115\nType I error rate: 0.1\nType II error rate: 0.399\nTwo-tailed test: TRUE\n\n\n… this should result in the same power as when setting the two.tailed argument to FALSE.\n\npower.ira(alpha=.05, two.tailed=FALSE, n=300, p=.50, es=.22)\n\n\nStatistical power: \n--------------------------------------- \n 0.601\n--------------------------------------- \nDegrees of freedom: 298\nStandardized standard error: 0.115\nType I error rate: 0.05\nType II error rate: 0.399\nTwo-tailed test: FALSE\n\n\nSet the n argument to 600.\n\npower.ira(alpha=.05, two.tailed=TRUE, n=600, p=.50, es=.22)\n\n\nStatistical power: \n--------------------------------------- \n 0.767\n--------------------------------------- \nDegrees of freedom: 598\nStandardized standard error: 0.082\nType I error rate: 0.05\nType II error rate: 0.233\nTwo-tailed test: TRUE\n\n\nSet the es argument to .30.\n\npower.ira(alpha=.05, two.tailed=TRUE, n=300, p=.50, es=.30)\n\n\nStatistical power: \n--------------------------------------- \n 0.736\n--------------------------------------- \nDegrees of freedom: 298\nStandardized standard error: 0.115\nType I error rate: 0.05\nType II error rate: 0.264\nTwo-tailed test: TRUE\n\n\n\n\nPlotting\nPowerUpR comes with built-in plotting functionality. We can create a power curve to see how many students would be necessary to achieve a certain power level.\n\ns1 &lt;- power.ira(alpha=.05, two.tailed=TRUE, n=500, p=.50, es=.22)\nplot(s1)\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nYou may also use ggplot in combination with plotly and htmlwidgets to generate an interactive power curve.\n\n\nUsing ggplot, the power curve looks like this:\n\n\nshow code\n\n\n# install/load required packages\npackages &lt;- c(\"plotly\", \"htmlwidgets\")\n\ninvisible(\n  lapply(packages,\n         function(x) {\n           if (!require(x, character.only = TRUE)) {\n             install.packages(x, dependencies = TRUE); require(x, character.only = TRUE)}\n         }\n  )\n)\n\n# write custom function to vectorize power across a range of sample sizes\ncustom_power.ira &lt;- function(n) {\n  parms &lt;- list(n=n, es=.22)\n  design &lt;- exec(\"power.ira\", !!!parms)\n  design$power[1]\n}\n\n# number of students ranging from 10 to 1000\nn &lt;- seq(10, 1000, 10)\n\n# map across the sample size vector\npwr &lt;- map_dbl(n, custom_power.ira) |&gt; set_names(n)\n\n\n# plot power curve\np &lt;- data.frame(n = n, pwr = pwr) %&gt;% \n  pivot_longer(pwr) %&gt;%\n  ggplot(aes(x = as.numeric(n), y = value, \n           text = paste(\n             \"With \" , n, \" students \",\n             round(value*100, 0), \"% Power is achieved.\", sep = \"\"), group = 1)) +\n  geom_line() +\n  geom_hline(yintercept = .8, lty = \"dotted\") + \n  scale_y_continuous(\"Statistical Power\", limits = c(0,1), breaks = seq(0, 1, .2)) + \n  scale_x_continuous(\"Number of students\", limits = c(10, 1000), breaks = seq(50, 1000, 100)) + \n  theme_minimal() + \n  theme(axis.ticks = element_blank(),\n        axis.title.x = element_text(margin = margin(0.25, 0, 0, 0)),\n        plot.title = element_text(hjust = 0.5), \n        plot.margin = margin(0,0.25,1,0.25, unit = \"cm\")) + \n  ggtitle(\"Statistical Power as a Function of the Number of Students\")\n\nggplotly(p, tooltip = \"text\")\n\n\n\n\n\n\n\n\nNote that you can move your cursor across the line to learn about the exact level of statistical power."
  },
  {
    "objectID": "single-level.html#illustration-of-the-worked-example-1",
    "href": "single-level.html#illustration-of-the-worked-example-1",
    "title": "Single-Level Designs",
    "section": "Illustration of the Worked Example",
    "text": "Illustration of the Worked Example\n\nScenario 1: Finding the Minimum Required Sample Size\nHow many students are required to adequately power an IRT to detect a certain hypothesized effect?\nThe research team considers a standardized treatment effect of d = .25 as meaningful, because it represents around one quarter of the expected annual growth in students’ achievement from Grade 3 to Grade 4 for the German student population (Brunner et al., 2023, Table 1). The team’s objective, therefore, is to sample enough 4th graders to detect MDES = .25 at significance level α = .05 in a two-tailed test with power 1−β = .80. The researchers assume a balanced design, where students are allocated to the treatment group (TG) and control group (CG) in equal shares (i.e., nTG = nCG).\n\nmrss.ira(\n  # properties of the statistical test\n  power=.80, alpha=.05, two.tailed=TRUE, \n  # sample allocation ratio\n  p=.50,\n  # hypothesized effect size\n  es=.25)\n\nn = 504 \n\n\nThe minimum required sample size (MRSS) for this design is N = 504 students.\nAs we learned before, the required sample size\n\n\nScenario 2: Computing the Minimum Detectable Effect Size\nWhich MDES is attainable for a certain sample size?\nA standardized treatment effect of d = .25 is considered meaningful, representing around one quarter of the expected annual growth in mathematics for Grade 3–4 in the German student population (Brunner et al., 2023, Table 1). The team’s objective, therefore, is to sample enough 4th graders to detect MDES = .25 at significance level α = .05 in a two-tailed test with power 1−β = .80, where PT = .50.\n\nmdes.ira(power=.80, alpha=.05, two.tailed=TRUE, p=.50, n=250)\n\n\nMinimum detectable effect size: \n--------------------------------------- \n 0.356 95% CI [0.107,0.605]\n---------------------------------------\nDegrees of freedom: 248\nStandardized standard error: 0.126\nType I error rate: 0.05\nType II error rate: 0.2\nTwo-tailed test: TRUE\n\n\nThe minimum required sample size (MRSS) to achieve this in an unconditional IRT design (i.e., without covariates) is N = 504 students."
  },
  {
    "objectID": "single-level.html#your-turn-1",
    "href": "single-level.html#your-turn-1",
    "title": "Single-Level Designs",
    "section": "Your turn!",
    "text": "Your turn!\n\nExercisesSolutions - R Code\n\n\n(I) MRSS\nHolding all remaining parameters constant, which sample size is required for\n\na one-sided test?\nα = .01?\n90% power (1-β = .90)?\nd = .15?\n\n(II) MDES\nHolding all remaining parameters constant, Which MDES is attainable for\n\na one-sided test?\nα = .10?\n95% Power (1-β = .95)?\nN = 300?\n\n(III) Power\nHolding all remaining parameters constant, how much power is achievable for\n\na one-sided test?\nα = .01?\nd = .20?\nN = 600?\n\n\n\n(I) Welche Stichprobengröße benötigt Team 1 bei\n\neinem einseitigen Hypothesentest?\n\n\npower.ira(es=.25, alpha=.05, two.tailed=TRUE, p=.50, n=250)\n\n\nStatistical power: \n--------------------------------------- \n 0.504\n--------------------------------------- \nDegrees of freedom: 248\nStandardized standard error: 0.126\nType I error rate: 0.05\nType II error rate: 0.496\nTwo-tailed test: TRUE\n\n\n\nα = .01?\n90% Power (1-β = .90)?\neiner Effektgröße von d = .15?\n\n(II) Welche MDES kann Team 1 statistisch absichern bei\n\neinem einseitigen Hypothesentest?\nα = .01?\n90% Power (1-β = .90)?\neiner Stichprobengröße von N = 300?\n\n(III) Welche Power kann Team 1 erreichen bei\n\neinem einseitigen Hypothesentest?\nα = .01?\neiner Effektgröße von d = .20?\neiner Stichprobengröße von N = 600?"
  },
  {
    "objectID": "multilevel.html#design-parameters-for-the-german-school-context",
    "href": "multilevel.html#design-parameters-for-the-german-school-context",
    "title": "Multilevel Designs",
    "section": "Design Parameters for the German School Context",
    "text": "Design Parameters for the German School Context\nFor the majority of workshop exercises, we draw on the compilation of ρ and R2 values (and corresponding standard errors) published in (stallasch_etal2021?). Based on three longitudinal German large-scale assessments (NEPS, PISA-I+, and DESI) that provide achievement data across the entire school career (grades 1 to 12), the authors generated design parameters that apply to\n\nseveral student populations,\n\nboth three-level designs (i.e., students at level [L] 1 within classrooms at L2 within schools at L3) as well as two-level designs (i.e., students at L1 within schools at L3), and\n\na broad array of domains.\n\nR2 values at each level are available for three covariate sets: (a) pretest scores, (b) sociodemographic characteristics (comprising students’ gender and migration background, as well as parents’ educational attainment, and families’ HISEI), and (c) the combination thereof.\nThe design parameters are provided via an interactive Excel file (Supplemental Online Material B) that comes with a detailed introduction on the application scopes of the various sets of estimates. This document can be downloaded from the OSF or the Journal’s website.\nTo facilitate the workflow in R (e.g., to avoid time-consuming and error-prone C&P of estimates), an .rda file that encloses the full compilation of design parameters (as a list of data frames) is shared in this course’s repository on github which is ready to be directly loaded:\n\n# load design parameters from github\nload(url(\"https://github.com/sophiestallasch/2022-workshop-CRT/blob/main/data/multides1.rda?raw=true\"))\n\nIf you run into problems, click here to download the data to your local machine and then load it into R.\n\n# inspect list\nsummary(multides1)\n\n                       Length Class  Mode\nB1_General             28     tbl_df list\nB2_General_ND          14     tbl_df list\nB3_Adjusted            28     tbl_df list\nB4_Adjusted_ND         14     tbl_df list\nB5_Academic            28     tbl_df list\nB6_Academic_ND         14     tbl_df list\nB7_Non-Academic        28     tbl_df list\nB8_Non-Academic_ND     14     tbl_df list\nB9_General-2l          20     tbl_df list\nB10_General-2l_ND      10     tbl_df list\nB11_Adjusted-2l        20     tbl_df list\nB12_Adjusted-2l_ND     10     tbl_df list\nB13_Academic-2l        20     tbl_df list\nB14_Academic-2l_ND     10     tbl_df list\nB15_Non-Academic-2l    20     tbl_df list\nB16_Non-Academic-2l_ND 10     tbl_df list\n\n\nThe list contains 16 data frames, that can be grouped into two broad classes:\n\nPoint Estimates and Standard Errors\nData frames B1, B3, B5, B7, B9, B11, B13, and B15 contain the full sets of (population-specific) empirical estimates of design parameters for each domain, subdomain, and grade, along with their standard errors.\nNormative Distributions\nData frames B2, B4, B6, B8, B10, B12, B14, and B16 (i.e., data frames ending with “_ND”) contain (population-specific) normative distributions (i.e., minimum, 25th percentile, median, 75th percentile, and maximum) of those design parameters summarized across domains and/or grades. These distributions can serve as guesstimates to plan studies whose target domain and/or grade is not covered in (stallasch_etal2021?).\n\n\nOverview of Data Frames\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData frame\n\n\nDescription\n\n\nGrades\n\n\nScope of application\n\n\nTarget design\n\n\nHierarchical structure\n\n\n\n\nL1\n\n\nL2\n\n\nL3\n\n\n\n\n\n\nB1_General\n\n\nDesign parameters for the general (total) student population\n\n\n1-10\n\n\nNationwide/ across all school types\n\n\n3L-(MS)CRT\n\n\nStudents\n\n\nClassrooms\n\n\nSchools\n\n\n\n\n11-12\n\n\n2L-MSIRT/CRT\n\n\nStudents\n\n\n-\n\n\nSchools\n\n\n\n\nB2_General_ND\n\n\nNormative distributions of B1\n\n\n1-10\n\n\nNationwide/ across all school types; target domain and/or grade not covered\n\n\n3L-(MS)CRT\n\n\nStudents\n\n\nClassrooms\n\n\nSchools\n\n\n\n\n11-12\n\n\n2L-MSIRT/CRT\n\n\nStudents\n\n\n-\n\n\nSchools\n\n\n\n\nB3_Adjusted\n\n\nDesign parameters for the general (total) student population, adjusted for mean-level differences between school types\n\n\n5-10\n\n\n1 school type in the non-academic track\n\n\n3L-(MS)CRT\n\n\nStudents\n\n\nClassrooms\n\n\nSchools\n\n\n\n\n11-12\n\n\n2L-MSIRT/CRT\n\n\nStudents\n\n\n-\n\n\nSchools\n\n\n\n\nB4_Adjusted_ND\n\n\nNormative distributions of B3\n\n\n5-10\n\n\n1 school type in the non-academic track; target domain and/or grade not covered\n\n\n3L-(MS)CRT\n\n\nStudents\n\n\nClassrooms\n\n\nSchools\n\n\n\n\n11-12\n\n\n2L-MSIRT/CRT\n\n\nStudents\n\n\n-\n\n\nSchools\n\n\n\n\nB5_Academic\n\n\nDesign parameters for the academic track\n\n\n5-10\n\n\nAcademic track school (“Gymnasium”)\n\n\n3L-(MS)CRT\n\n\nStudents\n\n\nClassrooms\n\n\nSchools\n\n\n\n\n11-12\n\n\n2L-MSIRT/CRT\n\n\nStudents\n\n\n-\n\n\nSchools\n\n\n\n\nB6_Academic_ND\n\n\nNormative distributions of B5\n\n\n5-10\n\n\nAcademic track school (“Gymnasium”); target domain and/or grade not covered\n\n\n3L-(MS)CRT\n\n\nStudents\n\n\nClassrooms\n\n\nSchools\n\n\n\n\n11-12\n\n\n2L-MSIRT/CRT\n\n\nStudents\n\n\n-\n\n\nSchools\n\n\n\n\nB7_Non-Academic\n\n\nDesign parameters for the non-academic track\n\n\n5-10\n\n\n2+ different school types in the non-academic track\n\n\n3L-(MS)CRT\n\n\nStudents\n\n\nClassrooms\n\n\nSchools\n\n\n\n\n11-12\n\n\n2L-MSIRT/CRT\n\n\nStudents\n\n\n-\n\n\nSchools\n\n\n\n\nB8_Non-Academic_ND\n\n\nNormative distributions of B7\n\n\n5-10\n\n\n2+ different school types in the non-academic track; target domain and/or grade not covered\n\n\n3L-(MS)CRT\n\n\nStudents\n\n\nClassrooms\n\n\nSchools\n\n\n\n\n11-12\n\n\n2L-MSIRT/CRT\n\n\nStudents\n\n\n-\n\n\nSchools\n\n\n\n\nB9_General-2l\n\n\nDesign parameters for the general (total) student population; for two-level designs\n\n\n1-10\n\n\nNationwide/ across all school types\n\n\n2L-MSIRT/CRT\n\n\nStudents\n\n\n-\n\n\nSchools\n\n\n\n\nB10_General-2l_ND\n\n\nNormative distributions of B9\n\n\n1-10\n\n\nNationwide/ across all school types; target domain and/or grade not covered\n\n\n2L-MSIRT/CRT\n\n\nStudents\n\n\n-\n\n\nSchools\n\n\n\n\nB11_Adjusted-2l\n\n\nDesign parameters for the general (total) student population, adjusted for mean-level differences between school types; for two-level designs\n\n\n5-10\n\n\n1 school type in the non-academic track\n\n\n2L-MSIRT/CRT\n\n\nStudents\n\n\n-\n\n\nSchools\n\n\n\n\nB12_Adjusted-2l_ND\n\n\nNormative distributions of B11\n\n\n5-10\n\n\n1 school type in the non-academic track; target domain and/or grade not covered\n\n\n2L-MSIRT/CRT\n\n\nStudents\n\n\n-\n\n\nSchools\n\n\n\n\nB13_Academic-2l\n\n\nDesign parameters for the academic track; for two-level designs\n\n\n5-10\n\n\nAcademic track school (“Gymnasium”)\n\n\n2L-MSIRT/CRT\n\n\nStudents\n\n\n-\n\n\nSchools\n\n\n\n\nB14_Academic-2l_ND\n\n\nNormative distributions of B13\n\n\n5-10\n\n\nAcademic track school (“Gymnasium”); target domain and/or grade not covered\n\n\n2L-MSIRT/CRT\n\n\nStudents\n\n\n-\n\n\nSchools\n\n\n\n\nB15_Non-Academic-2l\n\n\nDesign parameters for the non-academic track; for two-level designs\n\n\n5-10\n\n\n2+ different school types in the non-academic track\n\n\n2L-MSIRT/CRT\n\n\nStudents\n\n\n-\n\n\nSchools\n\n\n\n\nB16_Non-Academic-2l_ND\n\n\nNormative distributions of B15\n\n\n5-10\n\n\n2+ different school types in the non-academic track; target domain and/or grade not covered\n\n\n2L-MSIRT/CRT\n\n\nStudents\n\n\n-\n\n\nSchools\n\n\n\n\n\n \nFurther, (stallasch_etal2021?) created a flow chart to guide researchers through the choice of appropriate design parameters as a function of key characteristics of the target intervention.\n\n\n\nStructure of Data Frames\n\nPoint Estimates and Standard Errors\nData frames that contain the point estimates and standard errors (i.e., B1, B3, B5, B7, B9, B11, B13, and B15) are structured as follows.\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ndomain\nDomain of achievement outcome (for details, see section ‘Achievement Domains’)\n\n\nsubdomain\nSubdomain of achievement outcome (for details, see section ‘Achievement Domains’)\n\n\ngrade\nGrade of achievement outcome\n\n\nstudy\nLarge-scale assessment study (and cohort): ‘NEPS-SC2’, ‘NEPS-SC3’, ‘NEPS-SC4’, ‘PISA-I+’, ‘DESI’\n\n\nwave\nWave of large-scale assessment study\n\n\nmodel\nHierarchical structure of specified multilevel model: ‘3l’, ‘2l’\n\n\nicc_l2.est\nICC at classroom level ρL2\n\n\nicc_l2.se\nSE of ICC at classroom level SE(ρL2)\n\n\nicc_l3.est\nICC at school level ρL3\n\n\nicc_l3.se\nSE of ICC at school level SE(ρL3)\n\n\nr2_l1_pretest.est\nExplained variance by a pretest at student level R2L1\n\n\nr2_l1_pretest.se\nSE of explained variance by a pretest at student level SE(R2L1)\n\n\nr2_l2_pretest.est\nExplained variance by a pretest at classroom level R2L2\n\n\nr2_l2_pretest.se\nSE of explained variance by a pretest at classroom level SE(R2L2)\n\n\nr2_l3_pretest.est\nExplained variance by a pretest at school level R2L3\n\n\nr2_l3_pretest.se\nSE of explained variance by a pretest at school level SE(R2L3)\n\n\nr2_l1_ses.est\nExplained variance by sociodemographics at student level R2L1\n\n\nr2_l1_ses.se\nSE of explained variance by sociodemographics at student level SE(R2L1)\n\n\nr2_l2_ses.est\nExplained variance by sociodemographics at classroom level R2L2\n\n\nr2_l2_ses.se\nSE of explained variance by sociodemographics at classroom level SE(R2L2)\n\n\nr2_l3_ses.est\nExplained variance by sociodemographics at school level R2L3\n\n\nr2_l3_ses.se\nSE of explained variance by sociodemographics at school level SE(R2L3)\n\n\nr2_l1_pretestses.est\nExplained variance by a pretest and sociodemographics at student level R2L1\n\n\nr2_l1_pretestses.se\nSE of explained variance by a pretest and sociodemographics at student level SE(R2L1)\n\n\nr2_l2_pretestses.est\nExplained variance by a pretest and sociodemographics at classroom level R2L2\n\n\nr2_l2_pretestses.se\nSE of explained variance by a pretest and sociodemographics at classroom level SE(R2L2)\n\n\nr2_l3_pretestses.est\nExplained variance by a pretest and sociodemographics at school level R2L3\n\n\nr2_l3_pretestses.se\nSE of explained variance by a pretest and sociodemographics at school level SE(R2L3)\n\n\n\nNote that three-level design parameters (students at L1 within classrooms at L2 within schools at L3) were estimated for grades 1 to 10 only. For grades 11 to 12, no L2 estimates are available as 11th and 12th graders did not attend intact classrooms, but rather the grouping of students varied depending on the subject taught. Therefore, two-level design parameters (students at L1 within schools at L3) were estimated instead. Two-level equivalents for grades 1 to 10 (i.e., ignoring classroom-level clustering) are also provided; you can access them in the data frames labeled with ‘-2l’. Keep in mind that the top level (which is always the school level) is consistently indicated as ’_l3’ across all data frames; irrespective of whether L2 estimates were estimated (i.e., also for two-level designs). Detailed information on the provided design parameters and underlying analysis models can be retrieved from (stallasch_etal2021?).\n\n\nNormative Distributions\nData frames that contain normative distributions (i.e., B2, B4, B6, B8, B10, B12, B14, and B16) are structured as follows.\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ndomain\nDomain of summarized parameters (for details, see section ‘Achievement Domains’)\n\n\ngrade_range\nGrade range of summarized parameters\n\n\nstatistic\nSummary statistic: ‘Minimum’, ‘25th Percentile’, ‘Median’, ‘75th Percentile’, ‘Maximum’\n\n\nicc_l2.est\nICC at classroom level ρL2\n\n\nicc_l2.se\nSE of ICC at classroom level SE(ρL2)\n\n\nicc_l3.est\nICC at school level ρL3\n\n\nicc_l3.se\nSE of ICC at school level SE(ρL3)\n\n\nr2_l1_pretest.est\nExplained variance by a pretest at student level R2L1\n\n\nr2_l1_pretest.se\nSE of explained variance by a pretest at student level SE(R2L1)\n\n\nr2_l2_pretest.est\nExplained variance by a pretest at classroom level R2L2\n\n\nr2_l2_pretest.se\nSE of explained variance by a pretest at classroom level SE(R2L2)\n\n\nr2_l3_pretest.est\nExplained variance by a pretest at school level R2L3\n\n\nr2_l3_pretest.se\nSE of explained variance by a pretest at school level SE(R2L3)\n\n\nr2_l1_ses.est\nExplained variance by sociodemographics at student level R2L1\n\n\nr2_l1_ses.se\nSE of explained variance by sociodemographics at student level SE(R2L1)\n\n\nr2_l2_ses.est\nExplained variance by sociodemographics at classroom level R2L2\n\n\nr2_l2_ses.se\nSE of explained variance by sociodemographics at classroom level SE(R2L2)\n\n\nr2_l3_ses.est\nExplained variance by sociodemographics at school level R2L3\n\n\nr2_l3_ses.se\nSE of explained variance by sociodemographics at school level SE(R2L3)\n\n\nr2_l1_pretestses.est\nExplained variance by a pretest and sociodemographics at student level R2L1\n\n\nr2_l1_pretestses.se\nSE of explained variance by a pretest and sociodemographics at student level SE(R2L1)\n\n\nr2_l2_pretestses.est\nExplained variance by a pretest and sociodemographics at classroom level R2L2\n\n\nr2_l2_pretestses.se\nSE of explained variance by a pretest and sociodemographics at classroom level SE(R2L2)\n\n\nr2_l3_pretestses.est\nExplained variance by a pretest and sociodemographics at school level R2L3\n\n\nr2_l3_pretestses.se\nSE of explained variance by a pretest and sociodemographics at school level SE(R2L3)\n\n\n\nNote that three-level design parameters (students at L1 within classrooms at L2 within schools at L3) were estimated for grades 1 to 10 only. For grades 11 to 12, no L2 estimates are available as 11th and 12th graders did not attend intact classrooms, but rather the grouping of students varied depending on the subject taught. Therefore, two-level design parameters (students at L1 within schools at L3) were estimated instead. Two-level equivalents for grades 1 to 10 (i.e., ignoring classroom-level clustering) are also provided; you can access them in the data frames labeled with ‘-2l’. Keep in mind that the top level (which is always the school level) is consistently indicated as ’_l3’ across all data frames; irrespective of whether L2 estimates were estimated (i.e., also for two-level designs). Detailed information on the provided design parameters and underlying analysis models can be retrieved from (stallasch_etal2021?).\n\n\n\nAchievement Domains\nThe design parameters cover the following achievement domains.\n\n\n\n\n\n\nDomain\n\n\nSubdomain\n\n\n\n\n\n\nMathematics\n\n\nMathematics\n\n\n\n\nScience\n\n\nScience\n\n\n\n\nVerbal Skills in German (as First Language)\n\n\nReading Comprehension\n\n\n\n\nReading Speed\n\n\n\n\nSpelling\n\n\n\n\nGrammar\n\n\n\n\nVocabulary\n\n\n\n\nWriting\n\n\n\n\nArgumentation\n\n\n\n\nListening Comprehension\n\n\n\n\nVerbal Skills in English (as Foreign Language)\n\n\nReading Comprehension\n\n\n\n\nText Reconstruction (C-Test)\n\n\n\n\nLanguage Awareness: Sociopragmatics\n\n\n\n\nLanguage Awareness: Grammar\n\n\n\n\nWriting\n\n\n\n\nListening Comprehension\n\n\n\n\nDomain-General Achievement\n\n\nDeclarative Metacognition\n\n\n\n\nICT Literacy\n\n\n\n\nProblem Solving\n\n\n\n\nBasic Cognitive Functions: Perception Speed\n\n\n\n\nBasic Cognitive Functions: Reasoning\n\n\n\n\n\n \nNote that the (sub)domain character strings in the data frames are named exactly like shown here. For instance, if we want to filter design parameters for English text reconstruction from data frame B1, we could use the following code.\n\n# filter English text reconstruction from data frame B1\neng_ctest &lt;- multides1[[\"B1_General\"]] %&gt;% \n  filter(domain == \"Verbal Skills in English (as Foreign Language)\", \n         subdomain == \"Text Reconstruction (C-Test)\")\n\nTip: However, avoid to type the full strings. We recommend using pattern matching functions like from the grep() family instead that will do the job for you.\n\n# better:\neng_ctest &lt;- multides1[[\"B1_General\"]] %&gt;% \n  filter(grepl(\"Eng\", domain), \n         grepl(\"C-Test\", subdomain))\n\nLet’s have a look at the filtered design parameters.\n\neng_ctest %&gt;%\n  t() %&gt;% # transpose for better readability\n  kbl %&gt;% \n  kable_styling(bootstrap_options = c(\"condensed\", \"responsive\")) %&gt;% \n  scroll_box(height = \"350px\")\n\n\n\n\n\n\ndomain\nVerbal Skills in English (as Foreign Language)\nVerbal Skills in English (as Foreign Language)\nVerbal Skills in English (as Foreign Language)\n\n\nsubdomain\nText Reconstruction (C-Test)\nText Reconstruction (C-Test)\nText Reconstruction (C-Test)\n\n\ngrade\n9\n9\n9\n\n\nstudy\nDESI\nDESI\nDESI (Pooled)\n\n\nwave\n1\n2\nNA\n\n\nmodel\n3l\n3l\n3l\n\n\nicc_l2.est\n0.07484727\n0.09329552\n0.08274759\n\n\nicc_l2.se\n0.009634811\n0.011132797\n0.007285329\n\n\nicc_l3.est\n0.5839861\n0.5519840\n0.5687772\n\n\nicc_l3.se\n0.01762045\n0.01851544\n0.01276421\n\n\nr2_l1_pretest.est\nNA\n0.4270869\n0.4270869\n\n\nr2_l1_pretest.se\nNA\n0.007683032\n0.007683032\n\n\nr2_l2_pretest.est\nNA\n0.8440895\n0.8440895\n\n\nr2_l2_pretest.se\nNA\n0.01575307\n0.01575307\n\n\nr2_l3_pretest.est\nNA\n0.998872\n0.998872\n\n\nr2_l3_pretest.se\nNA\n0.0006166911\n0.0006166911\n\n\nr2_l1_ses.est\n0.01315652\n0.01675238\n0.01483982\n\n\nr2_l1_ses.se\n0.002402910\n0.002561325\n0.001752443\n\n\nr2_l2_ses.est\n0.6742777\n0.6423608\n0.6577857\n\n\nr2_l2_ses.se\n0.09820881\n0.09497836\n0.06827333\n\n\nr2_l3_ses.est\n0.8845148\n0.9068157\n0.8968653\n\n\nr2_l3_ses.se\n0.01972262\n0.01770283\n0.01317418\n\n\nr2_l1_pretestses.est\nNA\n0.4306028\n0.4306028\n\n\nr2_l1_pretestses.se\nNA\n0.007663661\n0.007663661\n\n\nr2_l2_pretestses.est\nNA\n0.8838199\n0.8838199\n\n\nr2_l2_pretestses.se\nNA\n0.01990558\n0.01990558\n\n\nr2_l3_pretestses.est\nNA\n0.9993725\n0.9993725\n\n\nr2_l3_pretestses.se\nNA\n0.000219044\n0.000219044\n\n\n\n\n\n\n\n\n \nAs can be seen, there are three entries for English text reconstruction as the respective test was administered to students at two time points in the DESI study, namely at the beginning and at the end of grade 9. For the beginning of grade 9, no pretests were available, therefore the corresponding cells are set to NA. A third set of estimates is provided here that contains the meta-analytically pooled results across these two time points (as indicated by ‘DESI (Pooled)’). Note that this integration strategy (applying a fixed effect model approach) was also adopted for other domains in grade 9 in case multiple design parameters were available (as obtained either from several studies [as indicated by ‘All (Pooled)’] or from the two time points in DESI).\nLoad the design parameter collection.\n\nload(\"C:/Users/Sophie Stallasch/Documents/Workshops/2024_GEBF_Poweranalyse_Stallasch/2024-workshop-GEBF-power/multides1.rda\")"
  },
  {
    "objectID": "multilevel.html#multilevel-design-parameters",
    "href": "multilevel.html#multilevel-design-parameters",
    "title": "Multilevel Designs",
    "section": "Multilevel Design Parameters",
    "text": "Multilevel Design Parameters\nTo plan sensitive (i.e., sufficiently powered and precise) CRTs on student achievement, reliable estimates of multilevel design parameters that adequately mirror the clustered variance structure of the outcome are critical. These design parameters include:\n\nIntraclass correlation coefficients (ICCs)\nρ values that quantify achievement differences between clusters\nExplained Variances\nR2 values that quantify the proportions of explained variance by covariates at the various levels\n\nGenerally, design parameters should match the peculiarities of the target research context as closely as possible (e.g., the target population of the intervention, the specific hierarchical data structure, and the achievement outcome under investigation). There are multiple resources of empirical values of ρ and R2. A review of existing international and German research on design parameters for student achievement can be found in Stallasch et al. (2021). A useful collection of respective estimates for the United States is the “Online Intraclass Correlation Database” created by Larry V. Hedges and colleagues and hosted by the Institute for Policy Research at the Northwestern University.\n\nDesign Parameters for the German School Context\nIn this workshop, we draw on our own compilation of ρ and R2 values (and corresponding standard errors) for the German school system published in Stallasch et al. (2021). Based on three longitudinal German large-scale assessments (NEPS, PISA-I+, and DESI) which provided achievement data across the entire school career (Grades 1 to 12), we generated design parameters that apply to:\n\nseveral student populations\nboth two-level (students within schools) and three-level designs (students within classrooms within schools)\na broad array of domains\n\nR2 values at each level are available for three covariate sets:\n\npretest scores\nsociodemographic characteristics (comprising students’ gender and migration background, as well as parents’ educational attainment, and families’ HISEI)\nthe combination thereof\n\nThe design parameters are provided via an interactive Excel file (Supplemental Online Material B) that comes with a detailed introduction on the application scopes of the various sets of estimates. This document can be downloaded from the OSF or the Journal’s website.\nTo facilitate the workflow in R (e.g., to avoid time-consuming and error-prone C&P of estimates), an .rda file that encloses the full compilation of design parameters (as a list of data frames) is shared in this course’s repository on github which is ready to be directly loaded:\n\n# load design parameters from github\nload(url(\"https://github.com/sophiestallasch/2022-workshop-CRT/blob/main/data/multides1.rda?raw=true\"))\n\nIf you run into problems, click here to download the data to your local machine and then load it into R.\n\n# inspect list\nsummary(multides1)\n\n                       Length Class  Mode\nB1_General             28     tbl_df list\nB2_General_ND          14     tbl_df list\nB3_Adjusted            28     tbl_df list\nB4_Adjusted_ND         14     tbl_df list\nB5_Academic            28     tbl_df list\nB6_Academic_ND         14     tbl_df list\nB7_Non-Academic        28     tbl_df list\nB8_Non-Academic_ND     14     tbl_df list\nB9_General-2l          20     tbl_df list\nB10_General-2l_ND      10     tbl_df list\nB11_Adjusted-2l        20     tbl_df list\nB12_Adjusted-2l_ND     10     tbl_df list\nB13_Academic-2l        20     tbl_df list\nB14_Academic-2l_ND     10     tbl_df list\nB15_Non-Academic-2l    20     tbl_df list\nB16_Non-Academic-2l_ND 10     tbl_df list\n\n\nThe list contains 16 data frames, that can be grouped into two broad classes:\n\nPoint Estimates and Standard Errors\nData frames B1, B3, B5, B7, B9, B11, B13, and B15 contain the full sets of (population-specific) empirical estimates of design parameters for each domain, subdomain, and grade, along with their standard errors.\nNormative Distributions\nData frames B2, B4, B6, B8, B10, B12, B14, and B16 (all data frames ending with “_ND”) contain (population-specific) normative distributions (i.e., minimum, 25th percentile, median, 75th percentile, and maximum) of those design parameters summarized across domains and/or grades. These distributions can serve as guesstimates to plan studies whose target domain and/or grade is not covered in .\n\n\nOverview of Data Frames\nWe also created a flow chart to guide the choice of appropriate design parameters as a function of key characteristics of the target intervention.\n\n\n\nStructure of Data Frames\n\nPoint Estimates and Standard ErrorsNormative Distributions\n\n\nData frames that contain the point estimates and standard errors (i.e., B1, B3, B5, B7, B9, B11, B13, and B15) are structured as follows.\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ndomain\nDomain of achievement outcome (for details, see section ‘Achievement Domains’)\n\n\nsubdomain\nSubdomain of achievement outcome (for details, see section ‘Achievement Domains’)\n\n\ngrade\nGrade of achievement outcome\n\n\nstudy\nLarge-scale assessment study (and cohort): ‘NEPS-SC2’, ‘NEPS-SC3’, ‘NEPS-SC4’, ‘PISA-I+’, ‘DESI’\n\n\nwave\nWave of large-scale assessment study\n\n\nmodel\nHierarchical structure of specified multilevel model: ‘3l’, ‘2l’\n\n\nicc_l2.est\nICC at the classroom level ρL2\n\n\nicc_l2.se\nSE of ICC at the classroom level SE(ρL2)\n\n\nicc_l3.est\nICC at the school level ρL3\n\n\nicc_l3.se\nSE of ICC at the school level SE(ρL3)\n\n\nr2_l1_pretest.est\nExplained variance by a pretest at the student level R2L1\n\n\nr2_l1_pretest.se\nSE of explained variance by a pretest at the student level SE(R2L1)\n\n\nr2_l2_pretest.est\nExplained variance by a pretest at the classroom level R2L2\n\n\nr2_l2_pretest.se\nSE of explained variance by a pretest at the classroom level SE(R2L2)\n\n\nr2_l3_pretest.est\nExplained variance by a pretest at the school level R2L3\n\n\nr2_l3_pretest.se\nSE of explained variance by a pretest at the school level SE(R2L3)\n\n\nr2_l1_ses.est\nExplained variance by sociodemographics at the student level R2L1\n\n\nr2_l1_ses.se\nSE of explained variance by sociodemographics at the student level SE(R2L1)\n\n\nr2_l2_ses.est\nExplained variance by sociodemographics at the classroom level R2L2\n\n\nr2_l2_ses.se\nSE of explained variance by sociodemographics at the classroom level SE(R2L2)\n\n\nr2_l3_ses.est\nExplained variance by sociodemographics at the school level R2L3\n\n\nr2_l3_ses.se\nSE of explained variance by sociodemographics at the school level SE(R2L3)\n\n\nr2_l1_pretestses.est\nExplained variance by a pretest and sociodemographics at the student level R2L1\n\n\nr2_l1_pretestses.se\nSE of explained variance by a pretest and sociodemographics at the student level SE(R2L1)\n\n\nr2_l2_pretestses.est\nExplained variance by a pretest and sociodemographics at the classroom level R2L2\n\n\nr2_l2_pretestses.se\nSE of explained variance by a pretest and sociodemographics at the classroom level SE(R2L2)\n\n\nr2_l3_pretestses.est\nExplained variance by a pretest and sociodemographics at the school level R2L3\n\n\nr2_l3_pretestses.se\nSE of explained variance by a pretest and sociodemographics at the school level SE(R2L3)\n\n\n\n\n\nData frames that contain normative distributions (i.e., B2, B4, B6, B8, B10, B12, B14, and B16) are structured as follows.\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ndomain\nDomain of summarized parameters (for details, see section ‘Achievement Domains’)\n\n\ngrade_range\nGrade range of summarized parameters\n\n\nstatistic\nSummary statistic: ‘Minimum’, ‘25th Percentile’, ‘Median’, ‘75th Percentile’, ‘Maximum’\n\n\nicc_l2.est\nICC at the classroom level ρL2\n\n\nicc_l2.se\nSE of ICC at the classroom level SE(ρL2)\n\n\nicc_l3.est\nICC at the school level ρL3\n\n\nicc_l3.se\nSE of ICC at the school level SE(ρL3)\n\n\nr2_l1_pretest.est\nExplained variance by a pretest at the student level R2L1\n\n\nr2_l1_pretest.se\nSE of explained variance by a pretest at the student level SE(R2L1)\n\n\nr2_l2_pretest.est\nExplained variance by a pretest at the classroom level R2L2\n\n\nr2_l2_pretest.se\nSE of explained variance by a pretest at the classroom level SE(R2L2)\n\n\nr2_l3_pretest.est\nExplained variance by a pretest at the school level R2L3\n\n\nr2_l3_pretest.se\nSE of explained variance by a pretest at the school level SE(R2L3)\n\n\nr2_l1_ses.est\nExplained variance by sociodemographics at the student level R2L1\n\n\nr2_l1_ses.se\nSE of explained variance by sociodemographics at the student level SE(R2L1)\n\n\nr2_l2_ses.est\nExplained variance by sociodemographics at the classroom level R2L2\n\n\nr2_l2_ses.se\nSE of explained variance by sociodemographics at the classroom level SE(R2L2)\n\n\nr2_l3_ses.est\nExplained variance by sociodemographics at the school level R2L3\n\n\nr2_l3_ses.se\nSE of explained variance by sociodemographics at the school level SE(R2L3)\n\n\nr2_l1_pretestses.est\nExplained variance by a pretest and sociodemographics at the student level R2L1\n\n\nr2_l1_pretestses.se\nSE of explained variance by a pretest and sociodemographics at the student level SE(R2L1)\n\n\nr2_l2_pretestses.est\nExplained variance by a pretest and sociodemographics at the classroom level R2L2\n\n\nr2_l2_pretestses.se\nSE of explained variance by a pretest and sociodemographics at the classroom level SE(R2L2)\n\n\nr2_l3_pretestses.est\nExplained variance by a pretest and sociodemographics at the school level R2L3\n\n\nr2_l3_pretestses.se\nSE of explained variance by a pretest and sociodemographics at the school level SE(R2L3)\n\n\n\n\n\n\nNote that three-level design parameters (students at L1 within classrooms at L2 within schools at L3) were estimated for grades 1 to 10 only. For grades 11 to 12, no L2 estimates are available as 11th and 12th graders did not attend intact classrooms, but rather the grouping of students varied depending on the subject taught. Therefore, two-level design parameters (students at L1 within schools at L3) were estimated instead. Two-level equivalents for grades 1 to 10 (i.e., ignoring classroom-level clustering) are also provided; you can access them in the data frames labeled with ‘-2l’.\n\n\n\n\n\n\nNote\n\n\n\nKeep in mind that the top level (which is always the school level) is consistently indicated as ‘_l3’ across all data frames; irrespective of whether L2 estimates were estimated (i.e., also for two-level designs).\n\n\nDetailed information on the provided design parameters and underlying analysis models can be retrieved from Stallasch et al. (2021).\n\n\nAchievement Domains\nThe design parameters cover the following achievement domains.\nNote that the (sub)domain character strings in the data frames are named exactly like shown here. For instance, if we want to filter design parameters for English text reconstruction from data frame B1, we could use the following code.\n\nlibrary(PowerUpR)\nlibrary(tidyverse)\nlibrary(kableExtra)\n\n\n# filter English text reconstruction from data frame B1\neng_ctest &lt;- multides1[[\"B1_General\"]] %&gt;% \n  filter(domain == \"Verbal Skills in English (as Foreign Language)\", \n         subdomain == \"Text Reconstruction (C-Test)\")\n\nTip: However, avoid to type the full strings. We recommend using pattern matching functions like from the grep() family instead that will do the job for you.\n\n# better:\neng_ctest &lt;- multides1[[\"B1_General\"]] %&gt;% \n  filter(grepl(\"Eng\", domain), \n         grepl(\"C-Test\", subdomain))\n\nLet’s have a look at the filtered design parameters.\n\neng_ctest %&gt;%\n  t() %&gt;% # transpose for better readability\n  kbl %&gt;% \n  kable_styling(bootstrap_options = c(\"condensed\", \"responsive\")) %&gt;% \n  scroll_box(height = \"350px\")\n\n\n\n\n\n\ndomain\nVerbal Skills in English (as Foreign Language)\nVerbal Skills in English (as Foreign Language)\nVerbal Skills in English (as Foreign Language)\n\n\nsubdomain\nText Reconstruction (C-Test)\nText Reconstruction (C-Test)\nText Reconstruction (C-Test)\n\n\ngrade\n9\n9\n9\n\n\nstudy\nDESI\nDESI\nDESI (Pooled)\n\n\nwave\n1\n2\nNA\n\n\nmodel\n3l\n3l\n3l\n\n\nicc_l2.est\n0.07484727\n0.09329552\n0.08274759\n\n\nicc_l2.se\n0.009634811\n0.011132797\n0.007285329\n\n\nicc_l3.est\n0.5839861\n0.5519840\n0.5687772\n\n\nicc_l3.se\n0.01762045\n0.01851544\n0.01276421\n\n\nr2_l1_pretest.est\nNA\n0.4270869\n0.4270869\n\n\nr2_l1_pretest.se\nNA\n0.007683032\n0.007683032\n\n\nr2_l2_pretest.est\nNA\n0.8440895\n0.8440895\n\n\nr2_l2_pretest.se\nNA\n0.01575307\n0.01575307\n\n\nr2_l3_pretest.est\nNA\n0.998872\n0.998872\n\n\nr2_l3_pretest.se\nNA\n0.0006166911\n0.0006166911\n\n\nr2_l1_ses.est\n0.01315652\n0.01675238\n0.01483982\n\n\nr2_l1_ses.se\n0.002402910\n0.002561325\n0.001752443\n\n\nr2_l2_ses.est\n0.6742777\n0.6423608\n0.6577857\n\n\nr2_l2_ses.se\n0.09820881\n0.09497836\n0.06827333\n\n\nr2_l3_ses.est\n0.8845148\n0.9068157\n0.8968653\n\n\nr2_l3_ses.se\n0.01972262\n0.01770283\n0.01317418\n\n\nr2_l1_pretestses.est\nNA\n0.4306028\n0.4306028\n\n\nr2_l1_pretestses.se\nNA\n0.007663661\n0.007663661\n\n\nr2_l2_pretestses.est\nNA\n0.8838199\n0.8838199\n\n\nr2_l2_pretestses.se\nNA\n0.01990558\n0.01990558\n\n\nr2_l3_pretestses.est\nNA\n0.9993725\n0.9993725\n\n\nr2_l3_pretestses.se\nNA\n0.000219044\n0.000219044\n\n\n\n\n\n\n\n\n \nAs can be seen, there are three entries for English text reconstruction as the respective test was administered to students at two time points in the DESI study, namely at the beginning and at the end of grade 9. For the beginning of grade 9, no pretests were available, therefore the corresponding cells are set to NA. A third set of estimates is provided here that contains the meta-analytically pooled results across these two time points (as indicated by ‘DESI (Pooled)’). Note that this integration strategy (applying a fixed effect model approach) was also adopted for other domains in grade 9 in case multiple design parameters were available (as obtained either from several studies [as indicated by ‘All (Pooled)’] or from the two time points in DESI).\nLoad the design parameter collection.\n\nload(\"C:/Users/Sophie Stallasch/Documents/Workshops/2024_GEBF_Poweranalyse_Stallasch/2024-workshop-GEBF-power/multides1.rda\")"
  },
  {
    "objectID": "dp.html",
    "href": "dp.html",
    "title": "Design Parameters",
    "section": "",
    "text": "To plan sensitive (i.e., sufficiently powered and precise) RTs on student achievement, reliable estimates of design parameters that adequately mirror the (clustered) variance structure of the intervention’s target outcome are critical.\nThese design parameters include:\nGenerally, design parameters should match the peculiarities of the target research context as closely as possible (e.g., the target population of the intervention, the specific hierarchical data structure, and the achievement outcome under investigation). There are multiple resources of empirical values of ρ and R2. A review of existing international and German research on multilevel design parameters for student achievement can be found in Stallasch et al. (2021). A meta-analytic integration of both single- and multilevel R2 values is provided in Stallasch et al. (2023). A useful collection of respective estimates for the United States is the ‘Online Intraclass Correlation Database’ created by Larry V. Hedges and colleagues and hosted by the Institute for Policy Research at the Northwestern University."
  },
  {
    "objectID": "dp.html#scenario-1-how-many-schools-are-required-for-a-2l-crt",
    "href": "dp.html#scenario-1-how-many-schools-are-required-for-a-2l-crt",
    "title": "Multilevel Design Parameters",
    "section": "Scenario 1: How Many Schools are Required for a 2L-CRT?",
    "text": "Scenario 1: How Many Schools are Required for a 2L-CRT?\nResearch Team 1 would like to conduct a 2L-CRT on the effectiveness of a school-wide intervention to improve 4th graders’ mathematical achievement in Germany. Team 1 plans to sample 40 students from each school. A standardized treatment effect of d = .25 is considered meaningful, because it represents around one quarter of the expected annual growth in mathematics from Grade 3 to Grade 4 in the German student population (Brunner et al., 2023, Table 1). How many schools are required to detect MDES = .25?\n\nStep 1: Choose the Design Parameters\nWhich data frame contains the appropriate design parameters?\n\n\n# -- choose data frame B9 \ndp_s1 &lt;- multides1[[\"B9_General-2l\"]] |&gt; \n  # filter mathematics in grade 4\n  filter(domain == \"Mathematics\", grade == 4)\n\nLet’s have a look at the relevant design parameters.\ndp_s1 |&gt; \n  # select the ICC and its standard error\n  select(contains(\"icc\")) |&gt; \n  round(2) |&gt; \n  pivot_longer(everything(), names_to = \"Variable\", values_to = \"Value\") |&gt; \n  kable()\n\n\n\n\nVariable\nValue\n\n\n\n\nicc_l3.est\n0.12\n\n\nicc_l3.se\n0.01\n\n\n\n\n\n\nStep 2: Define the Assumptions\n\nDesign AssumptionsFormula\n\n\n\n\n\n\n\n\n\nParameter\nPowerUpR Conversion\n\n\n\n\nTarget output\n\n\n\nMinimum required sample size of a 2L-CRT: Number of schools J\nmrss.cra2()\n\n\nStatistical test\n\n\n\nPower 1-β = .80\npower=.80 (default)\n\n\nSignificance level α = .05\nalpha=.05 (default)\n\n\nTwo-tailed test\ntwo.tailed=TRUE (default)\n\n\nSample sizes\n\n\n\nHarmonic mean number of L1 units per L2 unit n = 40\nn=40\n\n\nProportion of sample assigned to treatment P = .50 (balanced)\np=.50 (default)\n\n\nDesign parameters\n\n\n\nICC at L2 ρL2 = .12\nrho2=dp_s1$icc_l3.est\n\n\nFurther parameters\n\n\n\nMinimum detectable effect size MDES = .25\nes=.25\n\n\n\n\n\nBased on the expression for the MDES of a 2L-CRT with randomization/treatment assignment at L2 as given in (dong_maynard2013?), the number of schools \\(J\\) is computed as \\[\nJ = \\left(\\frac{M_{J-2}}{MDES}\\right)^2\\left(\\frac{\\rho_{L2}}{P(1-P)}+\\frac{(1-\\rho_{L2})}{P(1-P)n} \\right)\n\\] with\n\n\\(n\\) = harmonic mean number of L1 units per L2 unit\n\\(J\\) = number of L2 units\n\\(P\\) = \\(J_{TG}/J\\) = proportion of sample assigned to treatment\n\\(MDES\\) = minimum detectable effect size\n\\(M_{J-2}\\) = \\(t_{\\alpha/2}+t_{1-\\beta}\\) = multiplier for two-tailed test with \\(J-2\\) degrees of freedom\n\\(\\rho_{L2}\\) = achievement differences at L2 (ICC at L2)\n\n\n\n\n\n\nStep 3: Power Analysis with PowerUpR\n\nSimple Design with Default Assumptions\n\nd.0 &lt;- mrss.cra2(power=.80, alpha=.05, two.tailed=TRUE,\n                 n=40, p=.50,\n                 rho2=dp_s1$icc_l3.est, \n                 es=.25)\n\nJ = 73 \n\n\nGiven this design, at least 73 schools are necessary to detect an MDES of .25.\nOf course, it is also possible to directly insert the numeric values for the design parameters, but using the variables instead is safer, more precise, and prevents typos. Note that the results can differ due to rounding.\n\n# Note: Here, we are omitting all default parameters...\nd.01 &lt;- mrss.cra2(n=40, rho2=.12, es=.25)\n\nJ = 73 \n\n\n\n\nChanging the Default Assumptions\nEverything else being equal, what happens, when…\n\n(a) … power increases from 80% to 90%?\n\n# adjust the `power` argument to .90\nd.a &lt;- mrss.cra2(power=.90, \n                 n=40, rho2=dp_s1$icc_l3.est, es=.25)\n\nJ = 97 \n\n\nIncreasing power requires a larger number of schools.\nTip: We could also update the respective parameter in the list $parms stored in the mrss object and then call the function again with the modified argument.\n\n# save design 0 as a new design\nd.a &lt;- d.0\n# update `power` argument to .90\nd.a$parms$power=.90\n# call the function\nd.a &lt;- exec(\"mrss.cra2\", !!!d.a$parms)\n\nJ = 97 \n\n\n\n\n(b) … Type I error rate is set to 1%?\n\n# adjust the `alpha` argument to .01\nd.b &lt;- mrss.cra2(alpha=.01, \n                 n=40, rho2=dp_s1$icc_l3.est, es=.25)\n\nJ = 109 \n\n\nDecreasing the Type I error rate requires a larger number of schools.\n\n\n(c) … applying a one-tailed test?\n\n# adjust the `two.tailed` argument to FALSE\nd.c &lt;- mrss.cra2(two.tailed=FALSE, \n                 n=40, rho2=dp_s1$icc_l3.est, es=.25)\n\nJ = 57 \n\n\nTesting one-tailed requires a smaller number of schools.\n\n\n(d) … sampling 20/40/60/80/100 students per school?\n\n# adjust the `n` argument to 20/40/60/80/100\nd.d1 &lt;- mrss.cra2(n=20, rho2=dp_s1$icc_l3.est, es=.25)\nd.d2 &lt;- mrss.cra2(n=40, rho2=dp_s1$icc_l3.est, es=.25)\nd.d3 &lt;- mrss.cra2(n=60, rho2=dp_s1$icc_l3.est, es=.25)\nd.d4 &lt;- mrss.cra2(n=80, rho2=dp_s1$icc_l3.est, es=.25)\nd.d5 &lt;- mrss.cra2(n=100, rho2=dp_s1$icc_l3.est, es=.25)\n\nTip: Performing power analysis over a range of possible input parameters can be more easily done via vectorization. To vectorize the functions of PowerUpR over a range of possible input parameters (here: n = 20/40/60/80/100), we need to write a custom function similar to what is suggested by the package authors in their vignette on vectorization).\n\ncustom_mrss.cra2 &lt;- function(n) {\n  parms &lt;- list(n=n, rho2 = dp_s1$icc_l3.est, es=.25)\n  design &lt;- exec(\"mrss.cra2\", !!!parms)\n  design$J\n}\n\nNow we simply have to map the function across the various sample sizes.\n\n# number of students per school n = 20/40/60/80/100 \nn &lt;- seq(20, 100, 20)\nd.d &lt;- map_dbl(n, custom_mrss.cra2)\n\nJ = 84 \nJ = 73 \nJ = 69 \nJ = 67 \nJ = 66 \n\n\nSampling fewer/more students per school requires a larger/smaller number of schools. However, it becomes clear that increasing the number of students per school quickly reaches a point of diminishing returns.\n\n\n(e) … using an unbalanced design with 75% of the sample assigned to the treatment condition?\n\n# adjust the `p` argument to .75\nd.e &lt;- mrss.cra2(n=20, p=.75, rho2=dp_s1$icc_l3.est, es=.25)\n\nJ = 111 \n\n\nThe more pronounced the imbalance between experimental conditions, the larger the required number of schools.\n\n\n(f) … larger achievement differences of \\(\\rho\\) = .20 are assumed?\n\n# adjust `rho2` to .20\nd.f &lt;-mrss.cra2(n=40, rho2=.20, es=.25)\n\nJ = 112 \n\n\nLarger ICCs increase the required number of schools.\n\n\n\nIncorporating Statistical Uncertainty\nThe design parameters are estimates of population quantities, and thus, associated with statistical uncertainty. The uncertainty can be incorporated by using the standard errors for each design parameter. Assuming large-sample properties, research Team 1 uses the standard normal distribution to compute the limits for 95% confidence intervals by means of the standard errors for the design parameters. This approach has been labeled the the “safeguard” approach (Perugini et al., 2014). A conservative approach for planning the sample size is to use the upper bound estimate of the 95% CI for \\(\\rho\\).\n\n# lower bound\nd.g_lb &lt;- mrss.cra2(n=40, \n                    rho2 = dp_s1$icc_l3.est-1.96*dp_s1$icc_l3.se, \n                    es=.25)\n\nJ = 61 \n\n# upper bound\nd.g_ub &lt;- mrss.cra2(n=40, \n                    rho2 = dp_s1$icc_l3.est+1.96*dp_s1$icc_l3.se, \n                    es=.25)\n\nJ = 85 \n\n\nTaking statistical uncertainty into account, the required number of schools likely ranges between 61 and 85.\nNote that there are also other approaches to tackle uncertainties and/or heterogeneities in the input parameters. For instance, (Bayesian) simulation-based approaches to power analysis have been proposed that implicitly take into account uncertainty(see e.g., Moerbeek & Teerenstra, 2015; Pek & Park, 2019; Spiegelhalter et al., 2003; Turner et al., 2004).\n\n\n\nStep 4: Plotting\nLet’s plot the results. Move your cursor across the bars to learn about the required number schools for each design and how large the difference in % is compared to the baseline design.\n\n\nshow code\n\n\npackages &lt;- c(\"plotly\", \"htmlwidgets\")\n\ninvisible(\n  lapply(packages,\n         function(x) {\n           if (!require(x, character.only = TRUE)) {\n             install.packages(x, dependencies = TRUE); require(x, character.only = TRUE)}\n         }\n  )\n)\n\n\ndesign &lt;- list(d.0, d.a, d.b, d.c, d.d1, d.d3, d.d5, d.e, d.f, d.g_lb, d.g_ub) |&gt; \n  set_names(\"d.0\", \"d.a\", \"d.b\", \"d.c\", \"d.d1\", \"d.d3\", \"d.d5\", \"d.e\", \"d.f\", \"d.g_lb\", \"d.g_ub\")\n\ndelta &lt;- function(design) (design[[\"J\"]]-d.0[[\"J\"]])/d.0[[\"J\"]]*100\n\n\np &lt;- data.frame(design = factor(names(design)), \n                schools = map_dbl(design, ~.[[\"J\"]]), \n                delta = map_dbl(design, delta)) |&gt; \n  ggplot(aes(design, schools, text = paste(\n    factor(design, \n           levels = c(\"d.0\", \"d.a\", \"d.b\", \"d.c\", \"d.d1\", \"d.d3\", \"d.d5\", \"d.e\", \"d.f\", \"d.g_lb\", \"d.g_ub\"), \n           labels = c(\"The baseline design\", \n                      \"... increasing power to 90%\", \n                      \" ... setting Type I error rate to 1%\", \n                      \" ... applying a one-tailed test\", \n                      \"... sampling 20 students per school\", \n                      \"... sampling 60 students per school\", \n                      \"... sampling 100 students per school\", \n                      \"... assigning 75% of the schools to the treatment condition\", \n                      \"... assuming increased achievement differences at L2 of 20%\", \n                      \"... applying a liberal approach\",\n                      \"... applying a conservative approach\")),\n    \" requires J = \", schools, \" schools.\",\"\\n\",\n    ifelse(design == \"d.0\", \"\", \n           ifelse(design != \"d.0\" & delta &gt; 0, \n           paste0(\"This amounts to \", round(delta, 0), \n                  \"% more schools compared to the baseline design.\"),\n           ifelse(design != \"d.0\" & delta == 0, \n           \"The required number of schools does not change compared to the baseline design.\",\n           paste0(\"This amounts to \", round(delta, 0)*-1, \n                  \"% fewer schools compared to the baseline design.\")))),\n    sep = \"\"\n    ))) +\n  geom_bar(stat=\"identity\", width=0.9) + \n  scale_x_discrete(\"Design\") + \n  scale_y_continuous(\"Number of schools\") + \n  theme_minimal() + \n  theme(axis.ticks = element_blank(), \n        plot.title = element_text(hjust = 0.5)) + \n  ggtitle(\"Number of Schools Required for an MDES of .25 by Design\")\n\nggplotly(p, tooltip = \"text\")\n\n\n\n\n\n\n\n\n\nBuilt-in Functionality for Plotting in PowerUpR\nPowerUpR also comes with a built-in plotting function. We will quickly check out PowerUpR::plot() with the baseline design.\nIt is not possible to plot the required sample size. Instead, we can either plot the statistical power as a function of the sample size (which is the default)…\n\nplot(d.0, main = \"Power as a Function of the Number of Schools\")\n\n\n\n\n… or we can plot the MDES along with its (1-α)*100% CI as a function of the required number of schools.\n\n# include `ypar = \"mdes\"` to plot the MDES\n# include `locate=TRUE` to locate parameter values for the applied design\nplot(d.0, ypar = \"mdes\", \n     main = \"MDES as a Function of Number of Schools\", locate = TRUE)"
  },
  {
    "objectID": "dp.html#scenario-2-how-many-schools-are-required-for-a-2l-crt",
    "href": "dp.html#scenario-2-how-many-schools-are-required-for-a-2l-crt",
    "title": "Multilevel Design Parameters",
    "section": "Scenario 2: How Many Schools are Required for a 2L-CRT?",
    "text": "Scenario 2: How Many Schools are Required for a 2L-CRT?\nResearch Team 1 would like to conduct a 2L-CRT on the effectiveness of a school-wide intervention to improve 4th graders’ mathematical achievement in Germany. Team 1 plans to sample 40 students from each school. A standardized treatment effect of d = .25 is considered meaningful, because it represents around one quarter of the expected annual growth in mathematics from Grade 3 to Grade 4 in the German student population (Brunner et al., 2023, Table 1). How many schools are required to detect MDES = .25?\n\nStep 1: Choose the Design Parameters\nWhich data frame contains the appropriate design parameters?\n\n\n# -- choose data frame B9 \ndp_s1 &lt;- multides1[[\"B9_General-2l\"]] |&gt; \n  # filter mathematics in grade 4\n  filter(domain == \"Mathematics\", grade == 4)\n\nLet’s have a look at the relevant design parameters.\ndp_s1 |&gt; \n  # select the ICC and its standard error\n  select(contains(\"icc\")) |&gt; \n  round(2) |&gt; \n  pivot_longer(everything(), names_to = \"Variable\", values_to = \"Value\") |&gt; \n  kable()\n\n\n\n\nVariable\nValue\n\n\n\n\nicc_l3.est\n0.12\n\n\nicc_l3.se\n0.01\n\n\n\n\n\n\nStep 2: Define the Assumptions\n\nDesign AssumptionsFormula\n\n\n\n\n\n\n\n\n\nParameter\nPowerUpR Conversion\n\n\n\n\nTarget output\n\n\n\nMinimum required sample size of a 2L-CRT: Number of schools J\nmrss.cra2()\n\n\nStatistical test\n\n\n\nPower 1-β = .80\npower=.80 (default)\n\n\nSignificance level α = .05\nalpha=.05 (default)\n\n\nTwo-tailed test\ntwo.tailed=TRUE (default)\n\n\nSample sizes\n\n\n\nHarmonic mean number of L1 units per L2 unit n = 40\nn=40\n\n\nProportion of sample assigned to treatment P = .50 (balanced)\np=.50 (default)\n\n\nDesign parameters\n\n\n\nICC at L2 ρL2 = .12\nrho2=dp_s1$icc_l3.est\n\n\nFurther parameters\n\n\n\nMinimum detectable effect size MDES = .25\nes=.25\n\n\n\n\n\nBased on the expression for the MDES of a 2L-CRT with randomization/treatment assignment at L2 as given in (dong_maynard2013?), the number of schools \\(J\\) is computed as \\[\nJ = \\left(\\frac{M_{J-2}}{MDES}\\right)^2\\left(\\frac{\\rho_{L2}}{P(1-P)}+\\frac{(1-\\rho_{L2})}{P(1-P)n} \\right)\n\\] with\n\n\\(n\\) = harmonic mean number of L1 units per L2 unit\n\\(J\\) = number of L2 units\n\\(P\\) = \\(J_{TG}/J\\) = proportion of sample assigned to treatment\n\\(MDES\\) = minimum detectable effect size\n\\(M_{J-2}\\) = \\(t_{\\alpha/2}+t_{1-\\beta}\\) = multiplier for two-tailed test with \\(J-2\\) degrees of freedom\n\\(\\rho_{L2}\\) = achievement differences at L2 (ICC at L2)\n\n\n\n\n\n\nStep 3: Power Analysis with PowerUpR\n\nSimple Design with Default Assumptions\n\nd.0 &lt;- mrss.cra2(power=.80, alpha=.05, two.tailed=TRUE,\n                 n=40, p=.50,\n                 rho2=dp_s1$icc_l3.est, \n                 es=.25)\n\nJ = 73 \n\n\nGiven this design, at least 73 schools are necessary to detect an MDES of .25.\nOf course, it is also possible to directly insert the numeric values for the design parameters, but using the variables instead is safer, more precise, and prevents typos. Note that the results can differ due to rounding.\n\n# Note: Here, we are omitting all default parameters...\nd.01 &lt;- mrss.cra2(n=40, rho2=.12, es=.25)\n\nJ = 73 \n\n\n\n\nChanging the Default Assumptions\nEverything else being equal, what happens, when…\n\n(a) … power increases from 80% to 90%?\n\n# adjust the `power` argument to .90\nd.a &lt;- mrss.cra2(power=.90, \n                 n=40, rho2=dp_s1$icc_l3.est, es=.25)\n\nJ = 97 \n\n\nIncreasing power requires a larger number of schools.\nTip: We could also update the respective parameter in the list $parms stored in the mrss object and then call the function again with the modified argument.\n\n# save design 0 as a new design\nd.a &lt;- d.0\n# update `power` argument to .90\nd.a$parms$power=.90\n# call the function\nd.a &lt;- exec(\"mrss.cra2\", !!!d.a$parms)\n\nJ = 97 \n\n\n\n\n(b) … Type I error rate is set to 1%?\n\n# adjust the `alpha` argument to .01\nd.b &lt;- mrss.cra2(alpha=.01, \n                 n=40, rho2=dp_s1$icc_l3.est, es=.25)\n\nJ = 109 \n\n\nDecreasing the Type I error rate requires a larger number of schools.\n\n\n(c) … applying a one-tailed test?\n\n# adjust the `two.tailed` argument to FALSE\nd.c &lt;- mrss.cra2(two.tailed=FALSE, \n                 n=40, rho2=dp_s1$icc_l3.est, es=.25)\n\nJ = 57 \n\n\nTesting one-tailed requires a smaller number of schools.\n\n\n(d) … sampling 20/40/60/80/100 students per school?\n\n# adjust the `n` argument to 20/40/60/80/100\nd.d1 &lt;- mrss.cra2(n=20, rho2=dp_s1$icc_l3.est, es=.25)\nd.d2 &lt;- mrss.cra2(n=40, rho2=dp_s1$icc_l3.est, es=.25)\nd.d3 &lt;- mrss.cra2(n=60, rho2=dp_s1$icc_l3.est, es=.25)\nd.d4 &lt;- mrss.cra2(n=80, rho2=dp_s1$icc_l3.est, es=.25)\nd.d5 &lt;- mrss.cra2(n=100, rho2=dp_s1$icc_l3.est, es=.25)\n\nTip: Performing power analysis over a range of possible input parameters can be more easily done via vectorization. To vectorize the functions of PowerUpR over a range of possible input parameters (here: n = 20/40/60/80/100), we need to write a custom function similar to what is suggested by the package authors in their vignette on vectorization).\n\ncustom_mrss.cra2 &lt;- function(n) {\n  parms &lt;- list(n=n, rho2 = dp_s1$icc_l3.est, es=.25)\n  design &lt;- exec(\"mrss.cra2\", !!!parms)\n  design$J\n}\n\nNow we simply have to map the function across the various sample sizes.\n\n# number of students per school n = 20/40/60/80/100 \nn &lt;- seq(20, 100, 20)\nd.d &lt;- map_dbl(n, custom_mrss.cra2)\n\nJ = 84 \nJ = 73 \nJ = 69 \nJ = 67 \nJ = 66 \n\n\nSampling fewer/more students per school requires a larger/smaller number of schools. However, it becomes clear that increasing the number of students per school quickly reaches a point of diminishing returns.\n\n\n(e) … using an unbalanced design with 75% of the sample assigned to the treatment condition?\n\n# adjust the `p` argument to .75\nd.e &lt;- mrss.cra2(n=20, p=.75, rho2=dp_s1$icc_l3.est, es=.25)\n\nJ = 111 \n\n\nThe more pronounced the imbalance between experimental conditions, the larger the required number of schools.\n\n\n(f) … larger achievement differences of \\(\\rho\\) = .20 are assumed?\n\n# adjust `rho2` to .20\nd.f &lt;-mrss.cra2(n=40, rho2=.20, es=.25)\n\nJ = 112 \n\n\nLarger ICCs increase the required number of schools.\n\n\n\nIncorporating Statistical Uncertainty\nThe design parameters are estimates of population quantities, and thus, associated with statistical uncertainty. The uncertainty can be incorporated by using the standard errors for each design parameter. Assuming large-sample properties, research Team 1 uses the standard normal distribution to compute the limits for 95% confidence intervals by means of the standard errors for the design parameters. This approach has been labeled the the “safeguard” approach (Perugini et al., 2014). A conservative approach for planning the sample size is to use the upper bound estimate of the 95% CI for \\(\\rho\\).\n\n# lower bound\nd.g_lb &lt;- mrss.cra2(n=40, \n                    rho2 = dp_s1$icc_l3.est-1.96*dp_s1$icc_l3.se, \n                    es=.25)\n\nJ = 61 \n\n# upper bound\nd.g_ub &lt;- mrss.cra2(n=40, \n                    rho2 = dp_s1$icc_l3.est+1.96*dp_s1$icc_l3.se, \n                    es=.25)\n\nJ = 85 \n\n\nTaking statistical uncertainty into account, the required number of schools likely ranges between 61 and 85.\nNote that there are also other approaches to tackle uncertainties and/or heterogeneities in the input parameters. For instance, (Bayesian) simulation-based approaches to power analysis have been proposed that implicitly take into account uncertainty(see e.g., Moerbeek & Teerenstra, 2015; Pek & Park, 2019; Spiegelhalter et al., 2003; Turner et al., 2004).\n\n\n\nStep 4: Plotting\nLet’s plot the results. Move your cursor across the bars to learn about the required number schools for each design and how large the difference in % is compared to the baseline design.\n\n\nshow code\n\n\npackages &lt;- c(\"plotly\", \"htmlwidgets\")\n\ninvisible(\n  lapply(packages,\n         function(x) {\n           if (!require(x, character.only = TRUE)) {\n             install.packages(x, dependencies = TRUE); require(x, character.only = TRUE)}\n         }\n  )\n)\n\n\ndesign &lt;- list(d.0, d.a, d.b, d.c, d.d1, d.d3, d.d5, d.e, d.f, d.g_lb, d.g_ub) |&gt; \n  set_names(\"d.0\", \"d.a\", \"d.b\", \"d.c\", \"d.d1\", \"d.d3\", \"d.d5\", \"d.e\", \"d.f\", \"d.g_lb\", \"d.g_ub\")\n\ndelta &lt;- function(design) (design[[\"J\"]]-d.0[[\"J\"]])/d.0[[\"J\"]]*100\n\n\np &lt;- data.frame(design = factor(names(design)), \n                schools = map_dbl(design, ~.[[\"J\"]]), \n                delta = map_dbl(design, delta)) |&gt; \n  ggplot(aes(design, schools, text = paste(\n    factor(design, \n           levels = c(\"d.0\", \"d.a\", \"d.b\", \"d.c\", \"d.d1\", \"d.d3\", \"d.d5\", \"d.e\", \"d.f\", \"d.g_lb\", \"d.g_ub\"), \n           labels = c(\"The baseline design\", \n                      \"... increasing power to 90%\", \n                      \" ... setting Type I error rate to 1%\", \n                      \" ... applying a one-tailed test\", \n                      \"... sampling 20 students per school\", \n                      \"... sampling 60 students per school\", \n                      \"... sampling 100 students per school\", \n                      \"... assigning 75% of the schools to the treatment condition\", \n                      \"... assuming increased achievement differences at L2 of 20%\", \n                      \"... applying a liberal approach\",\n                      \"... applying a conservative approach\")),\n    \" requires J = \", schools, \" schools.\",\"\\n\",\n    ifelse(design == \"d.0\", \"\", \n           ifelse(design != \"d.0\" & delta &gt; 0, \n           paste0(\"This amounts to \", round(delta, 0), \n                  \"% more schools compared to the baseline design.\"),\n           ifelse(design != \"d.0\" & delta == 0, \n           \"The required number of schools does not change compared to the baseline design.\",\n           paste0(\"This amounts to \", round(delta, 0)*-1, \n                  \"% fewer schools compared to the baseline design.\")))),\n    sep = \"\"\n    ))) +\n  geom_bar(stat=\"identity\", width=0.9) + \n  scale_x_discrete(\"Design\") + \n  scale_y_continuous(\"Number of schools\") + \n  theme_minimal() + \n  theme(axis.ticks = element_blank(), \n        plot.title = element_text(hjust = 0.5)) + \n  ggtitle(\"Number of Schools Required for an MDES of .25 by Design\")\n\nggplotly(p, tooltip = \"text\")\n\n\n\n\n\n\n\n\n\nBuilt-in Functionality for Plotting in PowerUpR\nPowerUpR also comes with a built-in plotting function. We will quickly check out PowerUpR::plot() with the baseline design.\nIt is not possible to plot the required sample size. Instead, we can either plot the statistical power as a function of the sample size (which is the default)…\n\nplot(d.0, main = \"Power as a Function of the Number of Schools\")\n\n\n\n\n… or we can plot the MDES along with its (1-α)*100% CI as a function of the required number of schools.\n\n# include `ypar = \"mdes\"` to plot the MDES\n# include `locate=TRUE` to locate parameter values for the applied design\nplot(d.0, ypar = \"mdes\", \n     main = \"MDES as a Function of Number of Schools\", locate = TRUE)"
  },
  {
    "objectID": "dp.html#design-parameters-for-the-german-school-context",
    "href": "dp.html#design-parameters-for-the-german-school-context",
    "title": "Multilevel Design Parameters",
    "section": "Design Parameters for the German School Context",
    "text": "Design Parameters for the German School Context\nIn this workshop, we draw on our own compilation of ρ and R2 values (and corresponding standard errors) for the German school system published in Stallasch et al. (2021). Based on three longitudinal German large-scale assessments (NEPS, PISA-I+, and DESI) which provided achievement data across the entire school career (Grades 1 to 12), we generated design parameters that apply to:\n\nseveral student populations\nboth two-level (students within schools) and three-level designs (students within classrooms within schools)\na broad array of domains\n\nR2 values at each level are available for three covariate sets:\n\npretest scores\nsociodemographic characteristics (comprising students’ gender and migration background, as well as parents’ educational attainment, and families’ HISEI)\nthe combination thereof\n\nThe design parameters are provided via an interactive Excel file (Supplemental Online Material B) that comes with a detailed introduction on the application scopes of the various sets of estimates. This document can be downloaded from the OSF or the Journal’s website.\nTo facilitate the workflow in R (e.g., to avoid time-consuming and error-prone C&P of estimates), an .rda file that encloses the full compilation of design parameters (as a list of data frames) is shared in this course’s repository on github which is ready to be directly loaded:\n\n# load design parameters from github\nload(url(\"https://github.com/sophiestallasch/2022-workshop-CRT/blob/main/data/multides1.rda?raw=true\"))\n\nIf you run into problems, click here to download the data to your local machine and then load it into R.\n\n# inspect list\nsummary(multides1)\n\n                       Length Class  Mode\nB1_General             28     tbl_df list\nB2_General_ND          14     tbl_df list\nB3_Adjusted            28     tbl_df list\nB4_Adjusted_ND         14     tbl_df list\nB5_Academic            28     tbl_df list\nB6_Academic_ND         14     tbl_df list\nB7_Non-Academic        28     tbl_df list\nB8_Non-Academic_ND     14     tbl_df list\nB9_General-2l          20     tbl_df list\nB10_General-2l_ND      10     tbl_df list\nB11_Adjusted-2l        20     tbl_df list\nB12_Adjusted-2l_ND     10     tbl_df list\nB13_Academic-2l        20     tbl_df list\nB14_Academic-2l_ND     10     tbl_df list\nB15_Non-Academic-2l    20     tbl_df list\nB16_Non-Academic-2l_ND 10     tbl_df list\n\n\nThe list contains 16 data frames, that can be grouped into two broad classes:\n\nPoint Estimates and Standard Errors\nData frames B1, B3, B5, B7, B9, B11, B13, and B15 contain the full sets of (population-specific) empirical estimates of design parameters for each domain, subdomain, and grade, along with their standard errors.\nNormative Distributions\nData frames B2, B4, B6, B8, B10, B12, B14, and B16 (all data frames ending with “_ND”) contain (population-specific) normative distributions (i.e., minimum, 25th percentile, median, 75th percentile, and maximum) of those design parameters summarized across domains and/or grades. These distributions can serve as guesstimates to plan studies whose target domain and/or grade is not covered in .\n\n\nOverview of Data Frames\nWe also created a flow chart to guide the choice of appropriate design parameters as a function of key characteristics of the target intervention.\n\n\n\nStructure of Data Frames\n\nPoint Estimates and Standard ErrorsNormative Distributions\n\n\nData frames that contain the point estimates and standard errors (i.e., B1, B3, B5, B7, B9, B11, B13, and B15) are structured as follows.\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ndomain\nDomain of achievement outcome (for details, see section ‘Achievement Domains’)\n\n\nsubdomain\nSubdomain of achievement outcome (for details, see section ‘Achievement Domains’)\n\n\ngrade\nGrade of achievement outcome\n\n\nstudy\nLarge-scale assessment study (and cohort): ‘NEPS-SC2’, ‘NEPS-SC3’, ‘NEPS-SC4’, ‘PISA-I+’, ‘DESI’\n\n\nwave\nWave of large-scale assessment study\n\n\nmodel\nHierarchical structure of specified multilevel model: ‘3l’, ‘2l’\n\n\nicc_l2.est\nICC at the classroom level ρL2\n\n\nicc_l2.se\nSE of ICC at the classroom level SE(ρL2)\n\n\nicc_l3.est\nICC at the school level ρL3\n\n\nicc_l3.se\nSE of ICC at the school level SE(ρL3)\n\n\nr2_l1_pretest.est\nExplained variance by a pretest at the student level R2L1\n\n\nr2_l1_pretest.se\nSE of explained variance by a pretest at the student level SE(R2L1)\n\n\nr2_l2_pretest.est\nExplained variance by a pretest at the classroom level R2L2\n\n\nr2_l2_pretest.se\nSE of explained variance by a pretest at the classroom level SE(R2L2)\n\n\nr2_l3_pretest.est\nExplained variance by a pretest at the school level R2L3\n\n\nr2_l3_pretest.se\nSE of explained variance by a pretest at the school level SE(R2L3)\n\n\nr2_l1_ses.est\nExplained variance by sociodemographics at the student level R2L1\n\n\nr2_l1_ses.se\nSE of explained variance by sociodemographics at the student level SE(R2L1)\n\n\nr2_l2_ses.est\nExplained variance by sociodemographics at the classroom level R2L2\n\n\nr2_l2_ses.se\nSE of explained variance by sociodemographics at the classroom level SE(R2L2)\n\n\nr2_l3_ses.est\nExplained variance by sociodemographics at the school level R2L3\n\n\nr2_l3_ses.se\nSE of explained variance by sociodemographics at the school level SE(R2L3)\n\n\nr2_l1_pretestses.est\nExplained variance by a pretest and sociodemographics at the student level R2L1\n\n\nr2_l1_pretestses.se\nSE of explained variance by a pretest and sociodemographics at the student level SE(R2L1)\n\n\nr2_l2_pretestses.est\nExplained variance by a pretest and sociodemographics at the classroom level R2L2\n\n\nr2_l2_pretestses.se\nSE of explained variance by a pretest and sociodemographics at the classroom level SE(R2L2)\n\n\nr2_l3_pretestses.est\nExplained variance by a pretest and sociodemographics at the school level R2L3\n\n\nr2_l3_pretestses.se\nSE of explained variance by a pretest and sociodemographics at the school level SE(R2L3)\n\n\n\n\n\nData frames that contain normative distributions (i.e., B2, B4, B6, B8, B10, B12, B14, and B16) are structured as follows.\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ndomain\nDomain of summarized parameters (for details, see section ‘Achievement Domains’)\n\n\ngrade_range\nGrade range of summarized parameters\n\n\nstatistic\nSummary statistic: ‘Minimum’, ‘25th Percentile’, ‘Median’, ‘75th Percentile’, ‘Maximum’\n\n\nicc_l2.est\nICC at the classroom level ρL2\n\n\nicc_l2.se\nSE of ICC at the classroom level SE(ρL2)\n\n\nicc_l3.est\nICC at the school level ρL3\n\n\nicc_l3.se\nSE of ICC at the school level SE(ρL3)\n\n\nr2_l1_pretest.est\nExplained variance by a pretest at the student level R2L1\n\n\nr2_l1_pretest.se\nSE of explained variance by a pretest at the student level SE(R2L1)\n\n\nr2_l2_pretest.est\nExplained variance by a pretest at the classroom level R2L2\n\n\nr2_l2_pretest.se\nSE of explained variance by a pretest at the classroom level SE(R2L2)\n\n\nr2_l3_pretest.est\nExplained variance by a pretest at the school level R2L3\n\n\nr2_l3_pretest.se\nSE of explained variance by a pretest at the school level SE(R2L3)\n\n\nr2_l1_ses.est\nExplained variance by sociodemographics at the student level R2L1\n\n\nr2_l1_ses.se\nSE of explained variance by sociodemographics at the student level SE(R2L1)\n\n\nr2_l2_ses.est\nExplained variance by sociodemographics at the classroom level R2L2\n\n\nr2_l2_ses.se\nSE of explained variance by sociodemographics at the classroom level SE(R2L2)\n\n\nr2_l3_ses.est\nExplained variance by sociodemographics at the school level R2L3\n\n\nr2_l3_ses.se\nSE of explained variance by sociodemographics at the school level SE(R2L3)\n\n\nr2_l1_pretestses.est\nExplained variance by a pretest and sociodemographics at the student level R2L1\n\n\nr2_l1_pretestses.se\nSE of explained variance by a pretest and sociodemographics at the student level SE(R2L1)\n\n\nr2_l2_pretestses.est\nExplained variance by a pretest and sociodemographics at the classroom level R2L2\n\n\nr2_l2_pretestses.se\nSE of explained variance by a pretest and sociodemographics at the classroom level SE(R2L2)\n\n\nr2_l3_pretestses.est\nExplained variance by a pretest and sociodemographics at the school level R2L3\n\n\nr2_l3_pretestses.se\nSE of explained variance by a pretest and sociodemographics at the school level SE(R2L3)\n\n\n\n\n\n\nNote that three-level design parameters (students at L1 within classrooms at L2 within schools at L3) were estimated for grades 1 to 10 only. For grades 11 to 12, no L2 estimates are available as 11th and 12th graders did not attend intact classrooms, but rather the grouping of students varied depending on the subject taught. Therefore, two-level design parameters (students at L1 within schools at L3) were estimated instead. Two-level equivalents for grades 1 to 10 (i.e., ignoring classroom-level clustering) are also provided; you can access them in the data frames labeled with ‘-2l’.\n\n\n\n\n\n\nNote\n\n\n\nKeep in mind that the top level (which is always the school level) is consistently indicated as ‘_l3’ across all data frames; irrespective of whether L2 estimates were estimated (i.e., also for two-level designs).\n\n\nDetailed information on the provided design parameters and underlying analysis models can be retrieved from Stallasch et al. (2021).\n\n\nAchievement Domains\nThe design parameters cover the following achievement domains.\nNote that the (sub)domain character strings in the data frames are named exactly like shown here. For instance, if we want to filter design parameters for English text reconstruction from data frame B1, we could use the following code.\n\nlibrary(tidyverse)\nlibrary(kableExtra)\n\n\n# filter English text reconstruction from data frame B1\neng_ctest &lt;- multides1[[\"B1_General\"]] |&gt;  \n  filter(domain == \"Verbal Skills in English (as Foreign Language)\", \n         subdomain == \"Text Reconstruction (C-Test)\")\n\nHowever, to avoid to type the full strings, better use pattern matching functions like from the grep() family instead that will do the job for you.\n\n# better:\neng_ctest &lt;- multides1[[\"B1_General\"]] |&gt;  \n  filter(grepl(\"Eng\", domain), \n         grepl(\"C-Test\", subdomain))\n\nLet’s have a look at the filtered design parameters.\n\neng_ctest |&gt; \n  t() |&gt;  # transpose for better readability\n  kable() |&gt; \n  scroll_box(height = \"350px\")\n\n\n\n\n\n\n\n\n\n\n\n\n\ndomain\nVerbal Skills in English (as Foreign Language)\nVerbal Skills in English (as Foreign Language)\nVerbal Skills in English (as Foreign Language)\n\n\nsubdomain\nText Reconstruction (C-Test)\nText Reconstruction (C-Test)\nText Reconstruction (C-Test)\n\n\ngrade\n9\n9\n9\n\n\nstudy\nDESI\nDESI\nDESI (Pooled)\n\n\nwave\n1\n2\nNA\n\n\nmodel\n3l\n3l\n3l\n\n\nicc_l2.est\n0.07484727\n0.09329552\n0.08274759\n\n\nicc_l2.se\n0.009634811\n0.011132797\n0.007285329\n\n\nicc_l3.est\n0.5839861\n0.5519840\n0.5687772\n\n\nicc_l3.se\n0.01762045\n0.01851544\n0.01276421\n\n\nr2_l1_pretest.est\nNA\n0.4270869\n0.4270869\n\n\nr2_l1_pretest.se\nNA\n0.007683032\n0.007683032\n\n\nr2_l2_pretest.est\nNA\n0.8440895\n0.8440895\n\n\nr2_l2_pretest.se\nNA\n0.01575307\n0.01575307\n\n\nr2_l3_pretest.est\nNA\n0.998872\n0.998872\n\n\nr2_l3_pretest.se\nNA\n0.0006166911\n0.0006166911\n\n\nr2_l1_ses.est\n0.01315652\n0.01675238\n0.01483982\n\n\nr2_l1_ses.se\n0.002402910\n0.002561325\n0.001752443\n\n\nr2_l2_ses.est\n0.6742777\n0.6423608\n0.6577857\n\n\nr2_l2_ses.se\n0.09820881\n0.09497836\n0.06827333\n\n\nr2_l3_ses.est\n0.8845148\n0.9068157\n0.8968653\n\n\nr2_l3_ses.se\n0.01972262\n0.01770283\n0.01317418\n\n\nr2_l1_pretestses.est\nNA\n0.4306028\n0.4306028\n\n\nr2_l1_pretestses.se\nNA\n0.007663661\n0.007663661\n\n\nr2_l2_pretestses.est\nNA\n0.8838199\n0.8838199\n\n\nr2_l2_pretestses.se\nNA\n0.01990558\n0.01990558\n\n\nr2_l3_pretestses.est\nNA\n0.9993725\n0.9993725\n\n\nr2_l3_pretestses.se\nNA\n0.000219044\n0.000219044\n\n\n\n\n\n\n\nAs can be seen, there are three entries for English text reconstruction as the respective test was administered to students at two time points in the DESI study, namely at the beginning and at the end of grade 9. For the beginning of grade 9, no pretests were available, therefore the corresponding cells are set to NA. A third set of estimates is provided here that contains the meta-analytically pooled results across these two time points (as indicated by ‘DESI (Pooled)’). Note that this integration strategy (applying a fixed effect model approach) was also adopted for other domains in grade 9 in case multiple design parameters were available (as obtained either from several studies [as indicated by ‘All (Pooled)’] or from the two time points in DESI)."
  },
  {
    "objectID": "dp.html#advanced-covariate-selection",
    "href": "dp.html#advanced-covariate-selection",
    "title": "Design Parameters",
    "section": "Advanced Covariate Selection",
    "text": "Advanced Covariate Selection\nWell-chosen covariates can dramatically boost power and precision in both IRTs and CRTs. Recently, we generated an extensive compilation of single- and multilevel R2 (and ρ) values for student achievement (Stallasch et al., 2023). Alongside three psychometric heuristics, we analyzed (a) covariate types of varying bandwidth-fidelity, (b) covariate combinations to quantify incremental validities , and (c) covariate time lags of 1–7 years to test potential validity degradation in the covariates. We meta-analyzed the estimates from six quasi-representative German samples, covering various outcome domains and the entire school career. We also used the estimates to simulate precision. We won’t use these design parameters in the present workshop. However, feel free to check out our preprint and the corresponding Online Supplemental Material for manifold illustrative scenarios of study planning."
  },
  {
    "objectID": "dp.html#multilevel-design-parameters-for-the-german-school-context",
    "href": "dp.html#multilevel-design-parameters-for-the-german-school-context",
    "title": "Design Parameters",
    "section": "Multilevel Design Parameters for the German School Context",
    "text": "Multilevel Design Parameters for the German School Context\nIn this workshop, we draw on our own compilation of ρ and R2 values (and corresponding standard errors) for the German school system published in Stallasch et al. (2021). Based on three longitudinal German large-scale assessments (NEPS, PISA-I+, and DESI) which provided achievement data across the entire school career (Grades 1 to 12), we generated design parameters that apply to:\n\nSeveral student populations\nBoth two-level (students within schools) and three-level designs (students within classrooms within schools)\nA broad array of domains\n\nR2 values at each level are available for three covariate sets:\n\nPretest scores\nSociodemographic characteristics (comprising students’ gender and migration background, as well as parents’ educational attainment, and families’ HISEI)\nThe combination thereof\n\nThe design parameters are provided via an interactive Excel file (Supplemental Online Material B) that comes with a detailed introduction on the application scopes of the various sets of estimates. This document can be downloaded from the OSF or the Journal’s website.\nTo facilitate the workflow in R (e.g., to avoid time-consuming and error-prone C&P of estimates), an .rda file that encloses the full compilation of design parameters (as a list of data frames) is shared in this course’s repository on github which is ready to be directly loaded:\n\n# load design parameters from github\nload(url(\"https://github.com/sophiestallasch/2022-workshop-CRT/blob/main/data/multides1.rda?raw=true\"))\n\nIf you run into problems, click here to download the data to your local machine and then load it into R.\n\n# inspect list\nsummary(multides1)\n\n                       Length Class  Mode\nB1_General             28     tbl_df list\nB2_General_ND          14     tbl_df list\nB3_Adjusted            28     tbl_df list\nB4_Adjusted_ND         14     tbl_df list\nB5_Academic            28     tbl_df list\nB6_Academic_ND         14     tbl_df list\nB7_Non-Academic        28     tbl_df list\nB8_Non-Academic_ND     14     tbl_df list\nB9_General-2l          20     tbl_df list\nB10_General-2l_ND      10     tbl_df list\nB11_Adjusted-2l        20     tbl_df list\nB12_Adjusted-2l_ND     10     tbl_df list\nB13_Academic-2l        20     tbl_df list\nB14_Academic-2l_ND     10     tbl_df list\nB15_Non-Academic-2l    20     tbl_df list\nB16_Non-Academic-2l_ND 10     tbl_df list\n\n\nThe list contains 16 data frames, that can be grouped into two broad classes:\n\nPoint Estimates and Standard Errors\nData frames B1, B3, B5, B7, B9, B11, B13, and B15 contain the full sets of (population-specific) empirical estimates of design parameters for each domain, subdomain, and grade, along with their standard errors.\nNormative Distributions\nData frames B2, B4, B6, B8, B10, B12, B14, and B16 (all data frames ending with “_ND”) contain (population-specific) normative distributions (i.e., minimum, 25th percentile, median, 75th percentile, and maximum) of those design parameters summarized across domains and/or grades. These distributions can serve as guesstimates to plan studies whose target domain and/or grade is not covered in Stallasch et al. (2021).\n\n\nOverview of Data Frames\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData frame\n\n\nDescription\n\n\nGrades\n\n\nScope of application\n\n\nTarget design\n\n\nHierarchical structure\n\n\n\n\nL1\n\n\nL2\n\n\nL3\n\n\n\n\n\n\nB1_General\n\n\nDesign parameters for the general (total) student population\n\n\n1-10\n\n\nNationwide/ across all school types\n\n\n3L-(MS)CRT\n\n\nStudents\n\n\nClassrooms\n\n\nSchools\n\n\n\n\n11-12\n\n\n2L-MSIRT/CRT\n\n\nStudents\n\n\n-\n\n\nSchools\n\n\n\n\nB2_General_ND\n\n\nNormative distributions of B1\n\n\n1-10\n\n\nNationwide/ across all school types; target domain and/or grade not covered\n\n\n3L-(MS)CRT\n\n\nStudents\n\n\nClassrooms\n\n\nSchools\n\n\n\n\n11-12\n\n\n2L-MSIRT/CRT\n\n\nStudents\n\n\n-\n\n\nSchools\n\n\n\n\nB3_Adjusted\n\n\nDesign parameters for the general (total) student population, adjusted for mean-level differences between school types\n\n\n5-10\n\n\n1 school type in the non-academic track\n\n\n3L-(MS)CRT\n\n\nStudents\n\n\nClassrooms\n\n\nSchools\n\n\n\n\n11-12\n\n\n2L-MSIRT/CRT\n\n\nStudents\n\n\n-\n\n\nSchools\n\n\n\n\nB4_Adjusted_ND\n\n\nNormative distributions of B3\n\n\n5-10\n\n\n1 school type in the non-academic track; target domain and/or grade not covered\n\n\n3L-(MS)CRT\n\n\nStudents\n\n\nClassrooms\n\n\nSchools\n\n\n\n\n11-12\n\n\n2L-MSIRT/CRT\n\n\nStudents\n\n\n-\n\n\nSchools\n\n\n\n\nB5_Academic\n\n\nDesign parameters for the academic track\n\n\n5-10\n\n\nAcademic track school (“Gymnasium”)\n\n\n3L-(MS)CRT\n\n\nStudents\n\n\nClassrooms\n\n\nSchools\n\n\n\n\n11-12\n\n\n2L-MSIRT/CRT\n\n\nStudents\n\n\n-\n\n\nSchools\n\n\n\n\nB6_Academic_ND\n\n\nNormative distributions of B5\n\n\n5-10\n\n\nAcademic track school (“Gymnasium”); target domain and/or grade not covered\n\n\n3L-(MS)CRT\n\n\nStudents\n\n\nClassrooms\n\n\nSchools\n\n\n\n\n11-12\n\n\n2L-MSIRT/CRT\n\n\nStudents\n\n\n-\n\n\nSchools\n\n\n\n\nB7_Non-Academic\n\n\nDesign parameters for the non-academic track\n\n\n5-10\n\n\n2+ different school types in the non-academic track\n\n\n3L-(MS)CRT\n\n\nStudents\n\n\nClassrooms\n\n\nSchools\n\n\n\n\n11-12\n\n\n2L-MSIRT/CRT\n\n\nStudents\n\n\n-\n\n\nSchools\n\n\n\n\nB8_Non-Academic_ND\n\n\nNormative distributions of B7\n\n\n5-10\n\n\n2+ different school types in the non-academic track; target domain and/or grade not covered\n\n\n3L-(MS)CRT\n\n\nStudents\n\n\nClassrooms\n\n\nSchools\n\n\n\n\n11-12\n\n\n2L-MSIRT/CRT\n\n\nStudents\n\n\n-\n\n\nSchools\n\n\n\n\nB9_General-2l\n\n\nDesign parameters for the general (total) student population; for two-level designs\n\n\n1-10\n\n\nNationwide/ across all school types\n\n\n2L-MSIRT/CRT\n\n\nStudents\n\n\n-\n\n\nSchools\n\n\n\n\nB10_General-2l_ND\n\n\nNormative distributions of B9\n\n\n1-10\n\n\nNationwide/ across all school types; target domain and/or grade not covered\n\n\n2L-MSIRT/CRT\n\n\nStudents\n\n\n-\n\n\nSchools\n\n\n\n\nB11_Adjusted-2l\n\n\nDesign parameters for the general (total) student population, adjusted for mean-level differences between school types; for two-level designs\n\n\n5-10\n\n\n1 school type in the non-academic track\n\n\n2L-MSIRT/CRT\n\n\nStudents\n\n\n-\n\n\nSchools\n\n\n\n\nB12_Adjusted-2l_ND\n\n\nNormative distributions of B11\n\n\n5-10\n\n\n1 school type in the non-academic track; target domain and/or grade not covered\n\n\n2L-MSIRT/CRT\n\n\nStudents\n\n\n-\n\n\nSchools\n\n\n\n\nB13_Academic-2l\n\n\nDesign parameters for the academic track; for two-level designs\n\n\n5-10\n\n\nAcademic track school (“Gymnasium”)\n\n\n2L-MSIRT/CRT\n\n\nStudents\n\n\n-\n\n\nSchools\n\n\n\n\nB14_Academic-2l_ND\n\n\nNormative distributions of B13\n\n\n5-10\n\n\nAcademic track school (“Gymnasium”); target domain and/or grade not covered\n\n\n2L-MSIRT/CRT\n\n\nStudents\n\n\n-\n\n\nSchools\n\n\n\n\nB15_Non-Academic-2l\n\n\nDesign parameters for the non-academic track; for two-level designs\n\n\n5-10\n\n\n2+ different school types in the non-academic track\n\n\n2L-MSIRT/CRT\n\n\nStudents\n\n\n-\n\n\nSchools\n\n\n\n\nB16_Non-Academic-2l_ND\n\n\nNormative distributions of B15\n\n\n5-10\n\n\n2+ different school types in the non-academic track; target domain and/or grade not covered\n\n\n2L-MSIRT/CRT\n\n\nStudents\n\n\n-\n\n\nSchools\n\n\n\n\n\nWe also created a flow chart to guide the choice of appropriate design parameters as a function of key characteristics of the target intervention.\n\n\n\nStructure of Data Frames\n\nPoint Estimates and Standard ErrorsNormative Distributions\n\n\nData frames that contain the point estimates and standard errors (i.e., B1, B3, B5, B7, B9, B11, B13, and B15) are structured as follows.\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ndomain\nDomain of achievement outcome (for details, see section ‘Achievement Domains’)\n\n\nsubdomain\nSubdomain of achievement outcome (for details, see section ‘Achievement Domains’)\n\n\ngrade\nGrade of achievement outcome\n\n\nstudy\nLarge-scale assessment study (and cohort): ‘NEPS-SC2’, ‘NEPS-SC3’, ‘NEPS-SC4’, ‘PISA-I+’, ‘DESI’\n\n\nwave\nWave of large-scale assessment study\n\n\nmodel\nHierarchical structure of specified multilevel model: ‘3l’, ‘2l’\n\n\nicc_l2.est\nICC at the classroom level ρL2\n\n\nicc_l2.se\nSE of ICC at the classroom level SE(ρL2)\n\n\nicc_l3.est\nICC at the school level ρL3\n\n\nicc_l3.se\nSE of ICC at the school level SE(ρL3)\n\n\nr2_l1_pretest.est\nExplained variance by a pretest at the student level R2L1\n\n\nr2_l1_pretest.se\nSE of explained variance by a pretest at the student level SE(R2L1)\n\n\nr2_l2_pretest.est\nExplained variance by a pretest at the classroom level R2L2\n\n\nr2_l2_pretest.se\nSE of explained variance by a pretest at the classroom level SE(R2L2)\n\n\nr2_l3_pretest.est\nExplained variance by a pretest at the school level R2L3\n\n\nr2_l3_pretest.se\nSE of explained variance by a pretest at the school level SE(R2L3)\n\n\nr2_l1_ses.est\nExplained variance by sociodemographics at the student level R2L1\n\n\nr2_l1_ses.se\nSE of explained variance by sociodemographics at the student level SE(R2L1)\n\n\nr2_l2_ses.est\nExplained variance by sociodemographics at the classroom level R2L2\n\n\nr2_l2_ses.se\nSE of explained variance by sociodemographics at the classroom level SE(R2L2)\n\n\nr2_l3_ses.est\nExplained variance by sociodemographics at the school level R2L3\n\n\nr2_l3_ses.se\nSE of explained variance by sociodemographics at the school level SE(R2L3)\n\n\nr2_l1_pretestses.est\nExplained variance by a pretest and sociodemographics at the student level R2L1\n\n\nr2_l1_pretestses.se\nSE of explained variance by a pretest and sociodemographics at the student level SE(R2L1)\n\n\nr2_l2_pretestses.est\nExplained variance by a pretest and sociodemographics at the classroom level R2L2\n\n\nr2_l2_pretestses.se\nSE of explained variance by a pretest and sociodemographics at the classroom level SE(R2L2)\n\n\nr2_l3_pretestses.est\nExplained variance by a pretest and sociodemographics at the school level R2L3\n\n\nr2_l3_pretestses.se\nSE of explained variance by a pretest and sociodemographics at the school level SE(R2L3)\n\n\n\n\n\nData frames that contain normative distributions (i.e., B2, B4, B6, B8, B10, B12, B14, and B16) are structured as follows.\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ndomain\nDomain of summarized parameters (for details, see section ‘Achievement Domains’)\n\n\ngrade_range\nGrade range of summarized parameters\n\n\nstatistic\nSummary statistic: ‘Minimum’, ‘25th Percentile’, ‘Median’, ‘75th Percentile’, ‘Maximum’\n\n\nicc_l2.est\nICC at the classroom level ρL2\n\n\nicc_l2.se\nSE of ICC at the classroom level SE(ρL2)\n\n\nicc_l3.est\nICC at the school level ρL3\n\n\nicc_l3.se\nSE of ICC at the school level SE(ρL3)\n\n\nr2_l1_pretest.est\nExplained variance by a pretest at the student level R2L1\n\n\nr2_l1_pretest.se\nSE of explained variance by a pretest at the student level SE(R2L1)\n\n\nr2_l2_pretest.est\nExplained variance by a pretest at the classroom level R2L2\n\n\nr2_l2_pretest.se\nSE of explained variance by a pretest at the classroom level SE(R2L2)\n\n\nr2_l3_pretest.est\nExplained variance by a pretest at the school level R2L3\n\n\nr2_l3_pretest.se\nSE of explained variance by a pretest at the school level SE(R2L3)\n\n\nr2_l1_ses.est\nExplained variance by sociodemographics at the student level R2L1\n\n\nr2_l1_ses.se\nSE of explained variance by sociodemographics at the student level SE(R2L1)\n\n\nr2_l2_ses.est\nExplained variance by sociodemographics at the classroom level R2L2\n\n\nr2_l2_ses.se\nSE of explained variance by sociodemographics at the classroom level SE(R2L2)\n\n\nr2_l3_ses.est\nExplained variance by sociodemographics at the school level R2L3\n\n\nr2_l3_ses.se\nSE of explained variance by sociodemographics at the school level SE(R2L3)\n\n\nr2_l1_pretestses.est\nExplained variance by a pretest and sociodemographics at the student level R2L1\n\n\nr2_l1_pretestses.se\nSE of explained variance by a pretest and sociodemographics at the student level SE(R2L1)\n\n\nr2_l2_pretestses.est\nExplained variance by a pretest and sociodemographics at the classroom level R2L2\n\n\nr2_l2_pretestses.se\nSE of explained variance by a pretest and sociodemographics at the classroom level SE(R2L2)\n\n\nr2_l3_pretestses.est\nExplained variance by a pretest and sociodemographics at the school level R2L3\n\n\nr2_l3_pretestses.se\nSE of explained variance by a pretest and sociodemographics at the school level SE(R2L3)\n\n\n\n\n\n\nNote that three-level design parameters (students at L1 within classrooms at L2 within schools at L3) were estimated for grades 1 to 10 only. For grades 11 to 12, no L2 estimates are available as 11th and 12th graders did not attend intact classrooms, but rather the grouping of students varied depending on the subject taught. Therefore, two-level design parameters (students at L1 within schools at L3) were estimated instead. Two-level equivalents for grades 1 to 10 (i.e., ignoring classroom-level clustering) are also provided; you can access them in the data frames labeled with ‘-2l’.\n\n\n\n\n\n\nNote\n\n\n\nKeep in mind that the top level (which is always the school level) is consistently indicated as ‘_l3’ across all data frames; irrespective of whether L2 estimates were estimated (i.e., also for two-level designs).\n\n\nDetailed information on the provided design parameters and underlying analysis models can be retrieved from Stallasch et al. (2021).\n\n\nAchievement Domains\nThe design parameters cover the following achievement domains.\n\n\n\n\n\n\nDomain\n\n\nSubdomain\n\n\n\n\n\n\nMathematics\n\n\nMathematics\n\n\n\n\nScience\n\n\nScience\n\n\n\n\nVerbal Skills in German (as First Language)\n\n\nReading Comprehension\n\n\n\n\nReading Speed\n\n\n\n\nSpelling\n\n\n\n\nGrammar\n\n\n\n\nVocabulary\n\n\n\n\nWriting\n\n\n\n\nArgumentation\n\n\n\n\nListening Comprehension\n\n\n\n\nVerbal Skills in English (as Foreign Language)\n\n\nReading Comprehension\n\n\n\n\nText Reconstruction (C-Test)\n\n\n\n\nLanguage Awareness: Sociopragmatics\n\n\n\n\nLanguage Awareness: Grammar\n\n\n\n\nWriting\n\n\n\n\nListening Comprehension\n\n\n\n\nDomain-General Achievement\n\n\nDeclarative Metacognition\n\n\n\n\nICT Literacy\n\n\n\n\nProblem Solving\n\n\n\n\nBasic Cognitive Functions: Perception Speed\n\n\n\n\nBasic Cognitive Functions: Reasoning\n\n\n\n\n\nNote that the (sub)domain character strings in the data frames are named exactly like shown here. For instance, if we want to filter design parameters for English text reconstruction from data frame B1, we could use the following code.\n\nlibrary(tidyverse)\nlibrary(kableExtra)\n\n\n# filter English text reconstruction from data frame B1\neng_ctest &lt;- multides1[[\"B1_General\"]] |&gt;  \n  filter(domain == \"Verbal Skills in English (as Foreign Language)\", \n         subdomain == \"Text Reconstruction (C-Test)\")\n\nHowever, to avoid to type the full strings, better use pattern matching functions like from the grep() family instead that will do the job for you.\n\n# better:\neng_ctest &lt;- multides1[[\"B1_General\"]] |&gt;  \n  filter(grepl(\"Eng\", domain), \n         grepl(\"C-Test\", subdomain))\n\nLet’s have a look at the filtered design parameters.\n\neng_ctest |&gt; \n  # transpose for better readability\n  t() |&gt;  \n  kable() |&gt; \n  scroll_box(height = \"350px\")\n\n\n\n\n\n\n\n\n\n\n\n\n\ndomain\nVerbal Skills in English (as Foreign Language)\nVerbal Skills in English (as Foreign Language)\nVerbal Skills in English (as Foreign Language)\n\n\nsubdomain\nText Reconstruction (C-Test)\nText Reconstruction (C-Test)\nText Reconstruction (C-Test)\n\n\ngrade\n9\n9\n9\n\n\nstudy\nDESI\nDESI\nDESI (Pooled)\n\n\nwave\n1\n2\nNA\n\n\nmodel\n3l\n3l\n3l\n\n\nicc_l2.est\n0.07484727\n0.09329552\n0.08274759\n\n\nicc_l2.se\n0.009634811\n0.011132797\n0.007285329\n\n\nicc_l3.est\n0.5839861\n0.5519840\n0.5687772\n\n\nicc_l3.se\n0.01762045\n0.01851544\n0.01276421\n\n\nr2_l1_pretest.est\nNA\n0.4270869\n0.4270869\n\n\nr2_l1_pretest.se\nNA\n0.007683032\n0.007683032\n\n\nr2_l2_pretest.est\nNA\n0.8440895\n0.8440895\n\n\nr2_l2_pretest.se\nNA\n0.01575307\n0.01575307\n\n\nr2_l3_pretest.est\nNA\n0.998872\n0.998872\n\n\nr2_l3_pretest.se\nNA\n0.0006166911\n0.0006166911\n\n\nr2_l1_ses.est\n0.01315652\n0.01675238\n0.01483982\n\n\nr2_l1_ses.se\n0.002402910\n0.002561325\n0.001752443\n\n\nr2_l2_ses.est\n0.6742777\n0.6423608\n0.6577857\n\n\nr2_l2_ses.se\n0.09820881\n0.09497836\n0.06827333\n\n\nr2_l3_ses.est\n0.8845148\n0.9068157\n0.8968653\n\n\nr2_l3_ses.se\n0.01972262\n0.01770283\n0.01317418\n\n\nr2_l1_pretestses.est\nNA\n0.4306028\n0.4306028\n\n\nr2_l1_pretestses.se\nNA\n0.007663661\n0.007663661\n\n\nr2_l2_pretestses.est\nNA\n0.8838199\n0.8838199\n\n\nr2_l2_pretestses.se\nNA\n0.01990558\n0.01990558\n\n\nr2_l3_pretestses.est\nNA\n0.9993725\n0.9993725\n\n\nr2_l3_pretestses.se\nNA\n0.000219044\n0.000219044\n\n\n\n\n\n\n\nAs can be seen, there are three entries for English text reconstruction as the respective test was administered to students at two time points in the DESI study, namely at the beginning and at the end of grade 9. For the beginning of grade 9, no pretests were available, therefore the corresponding cells are set to NA. A third set of estimates is provided here that contains the meta-analytically pooled results across these two time points (as indicated by ‘DESI (Pooled)’). Note that this integration strategy (applying a fixed effect model approach) was also adopted for other domains in grade 9 in case multiple design parameters were available (as obtained either from several studies [as indicated by ‘All (Pooled)’] or from the two time points in DESI)."
  },
  {
    "objectID": "index.html#the-powerupr-package-in-a-nutshell",
    "href": "index.html#the-powerupr-package-in-a-nutshell",
    "title": "Workshop: Power Analysis for Experimental Designs in R with the PowerUpR Package",
    "section": "The PowerUpR Package in a Nutshell",
    "text": "The PowerUpR Package in a Nutshell\nPowerUpR is the R implementation of the ‘PowerUp!’ Excel tool created by Dong & Maynard (2013), which is accessible at the ‘Causal Evaluation’ website. PowerUpR provides functions to conduct three types of power analysis, depending on the desired output and the applied design. Specifically, PowerUpR offers power analysis tools to plan individually, multisite, and cluster randomized designs with up to four hierarchical levels. Note that this workshop does not cover multisite trials (MSRTs). However, if you want to learn about power analysis for such designs, you may want to check out my tutorials at https://sophiestallasch.github.io/2022-workshop-CRT/#Multisite_Trials).\n\n\n\n\n\n\n\n\n\nType of power analysis: Output\nIRT functions\n2L-CRT functions\n3L-CRT functions\n\n\n\n\nMinimum required sample size (MRSS)\nmrss.ira()\nmrss.cra2()\nmrss.cra3()\n\n\nMinimum detectable effect size (MDES)\nmdes.ira()\nmdes.cra2()\nmdes.cra3()\n\n\nPower\npower.ira()\npower.cra()\npower.cra3()\n\n\n\nGo to the PowerUpR Documentation to see details on the arguments etc.\n\n\n\n\n\n\nTip\n\n\n\nAt the ‘Causal Evaluation’ website, you also find the PowerUpR Shiny App, which nicely implements (and visualizes) most of the functionality of the PowerUpR package."
  },
  {
    "objectID": "index.html#worked-example-for-the-workshop",
    "href": "index.html#worked-example-for-the-workshop",
    "title": "Workshop: Power Analysis for Experimental Designs in R with the PowerUpR Package",
    "section": "Worked Example for the Workshop",
    "text": "Worked Example for the Workshop\nTo illustrate the process of performing power analysis with PowerUpR, we will use the following worked example of an intervention to foster student achievement.\n\n\n\n\n\n\nWorked Example\n\n\n\nA research team has programmed a comprehensive learning app. It is meant to function as a multidisciplinary digital learning environment for students in various grade levels in the German school system. Therefore, it can be used to support teaching and learning in manifold achievement domains throughout the entire school career. The researchers aim to experimentally evaluate whether the app actually improves student achievement."
  },
  {
    "objectID": "dp.html#advanced-covariate-selection-for-single--and-multilevel-designs",
    "href": "dp.html#advanced-covariate-selection-for-single--and-multilevel-designs",
    "title": "Design Parameters",
    "section": "Advanced Covariate Selection for Single- and Multilevel Designs",
    "text": "Advanced Covariate Selection for Single- and Multilevel Designs\nWell-chosen covariates can dramatically boost power and precision in both IRTs and CRTs. Recently, we generated an extensive compilation of single- and multilevel R2 (and ρ) values for student achievement (Stallasch et al., 2023). Alongside three psychometric heuristics, we analyzed (a) covariate types of varying bandwidth-fidelity, (b) covariate combinations to quantify incremental validities , and (c) covariate time lags of 1–7 years to test potential validity degradation in the covariates. We meta-analyzed the estimates from six quasi-representative German samples, covering various outcome domains and the entire school career. We also used the estimates to simulate precision. We won’t use these design parameters in the present workshop. However, feel free to check out our preprint and the corresponding Online Supplemental Material for manifold illustrative scenarios of study planning."
  },
  {
    "objectID": "multilevel.html#illustration-of-the-worked-example",
    "href": "multilevel.html#illustration-of-the-worked-example",
    "title": "Multilevel Designs",
    "section": "Illustration of the Worked Example",
    "text": "Illustration of the Worked Example\nIn the following we will walk through the process of planning a 3L-CRT, as the more general case. Power analysis for a 3L-CRT is basically an extension to power analysis for a 2L-CRT. Therefore, transferring and/or adjusting the demonstrated steps to plan a 2L-CRT is quite straightforward. Later on, in the practical hands-on section, you can check this.\n\nlibrary(PowerUpR)\nlibrary(tidyverse)\nlibrary(kableExtra)\n\n\n\n\n\n\n\nWorked Example\n\n\n\nA research team has programmed a comprehensive learning app. It is meant to function as a multidisciplinary digital learning environment for students in various grade levels in the German school system. Therefore, it can be used to support teaching and learning in manifold achievement domains throughout the entire school career. The researchers aim to experimentally evaluate whether the app actually improves student achievement.\n\n\nAfter having proven the general efficacy of the apps’s underlying didactic approach by means of an IRT (see Single-Level Designs), the research team aims to scale up the intervention and implement it in the regular school routine, as a CRT.\n\nScenario 1: Finding the Minimum Required Sample Size for a 3L-CRT\nHow many schools are required to detect a certain hypothesized treatment effect, given a specified design?\nThe research team would like to conduct a 3L-CRT to test whether the app fosters 7th graders reading comprehension in German as first language. According to Table 1 in Brunner et al. (2023), students in Germany typically show learning gains of d = .27 in their reading skills from Grade 6 to Grade 7. Since the app was programmed with a special focus on reading, the researchers expect to find at least a treatment effect that corresponds to an achievement growth across half a school year. The researchers therefore wonder how an efficient study design which is sensitive to detect MDES = .13 at α = .05 in a two-tailed t-test would look like. The research team performs power analyses to find the required number of schools, under the assumption to sample (on average) 3 classrooms of 20 students from every school.\n\nFormula\nThe number of schools \\(K\\) necessary for a 3L-CRT with randomization/treatment assignment at L3 is computed as (Dong & Maynard, 2013, p. 52): \\[ K = \\left(\\frac{M_{K-g^*_{L3}-2}}{MDES}\\right)^2\\left(\\frac{\\rho_{L3}(1-R^2_{L3})}{P(1-P)}+\\frac{\\rho_{L2}(1-R^2_{L2})}{P(1-P)J}+\\frac{(1-\\rho_{L3}-\\rho_{L2})(1-R^2_{L1})}{P(1-P)Jn} \\right)\\]\nwith\n\n\n\n\n\n\n\n\nParameter\nDefinition\nPowerUpR argument\n\n\n\n\n\\(M_{K-g^*_{L3}-2}\\)\nmultiplier for a two-tailed test \\(t_{\\alpha/2}+t_{1-\\beta}\\) with \\(K-g^*_{L3}-2\\) degrees of freedom\npower=.80, alpha=.05,two.tailed=TRUE\n\n\n\\(MDES\\)\nminimum detectable effect size\nes=.25\n\n\n\\(n\\)\nmean number of students per classroom\nn\n\n\n\\(J\\)\nmean number of classrooms per school\nJ\n\n\n\\(K\\)\ntotal number of schools\nK\n\n\n\\(P\\)\nproportion of sample assigned to treatment \\(K_{TG}/K\\)\np=.50\n\n\n\\(g^*_{L3}\\)\nnumber of school-level covariates\ng3=0\n\n\n\\(\\rho_{L2}\\)\nachievement differences between classrooms\nrho2\n\n\n\\(\\rho_{L3}\\)\nachievement differences between schools\nrho3\n\n\n\\(R^2_{L1}\\)\nexplained variance at the student level\nr21=0\n\n\n\\(R^2_{L2}\\)\nexplained variance at the classroom level\nr22=0\n\n\n\\(R^2_{L3}\\)\nexplained variance at the school level\nr23=0\n\n\n\n\n\nDesign Parameters\nThe research team uses the flow chart to find the appropriate design parameters.\n\nLoad the design parameter collection and select the relevant estimates.\n\nload(url(\"https://github.com/sophiestallasch/2022-workshop-CRT/blob/main/data/multides1.rda?raw=true\"))\n\n\n# -- choose data frame B1 \ndp_s1 &lt;- multides1[[\"B1_General\"]] |&gt; \n  # filter German reading comprehension in grade 7\n  filter(grepl(\"German\", domain), \n         grepl(\"Reading Comp\", subdomain)) |&gt; \n  filter(grade == 7)\n\nLet’s have a look at the ρ and R2 values and their standard errors.\ndp_s1 |&gt; \n  select(contains(c(\"icc\", \"r2\"))) |&gt; \n  round(2) |&gt; \n  pivot_longer(everything(), names_to = \"Variable\", values_to = \"Value\") |&gt; \n    kable() |&gt; \n  scroll_box(height = \"350px\")\n\n\n\n\n\nVariable\nValue\n\n\n\n\nicc_l2.est\n0.04\n\n\nicc_l2.se\n0.01\n\n\nicc_l3.est\n0.31\n\n\nicc_l3.se\n0.02\n\n\nr2_l1_pretest.est\n0.21\n\n\nr2_l1_pretest.se\n0.01\n\n\nr2_l2_pretest.est\n0.65\n\n\nr2_l2_pretest.se\n0.09\n\n\nr2_l3_pretest.est\n0.94\n\n\nr2_l3_pretest.se\n0.02\n\n\nr2_l1_ses.est\n0.02\n\n\nr2_l1_ses.se\n0.00\n\n\nr2_l2_ses.est\n0.40\n\n\nr2_l2_ses.se\n0.15\n\n\nr2_l3_ses.est\n0.85\n\n\nr2_l3_ses.se\n0.04\n\n\nr2_l1_pretestses.est\n0.22\n\n\nr2_l1_pretestses.se\n0.01\n\n\nr2_l2_pretestses.est\n0.74\n\n\nr2_l2_pretestses.se\n0.08\n\n\nr2_l3_pretestses.est\n0.97\n\n\nr2_l3_pretestses.se\n0.02\n\n\n\n\n\n\n\n\nPower Analysis\n\nBasline: Simple unconditional design\n\nd1.0 &lt;- mrss.cra3(power=.80, alpha=.05, two.tailed=TRUE,\n                  n = 20, J = 3, K0 = 10, tol=.10,\n                  es = .13,\n                  rho2 = dp_s1$icc_l2.est, \n                  rho3 = dp_s1$icc_l3.est, \n                  g3 = 0, r21 = 0, r22 = 0, r23 = 0)\n\nK = 621 \n\n\nNote that the arguments K0 and tol denote the starting value and stopping tolerance for determining K, respectively. K0=10 and tol=.10 are the default values.\n\n\nCovariate adjustment: Conditional design with…\n… 1 pretest at each hierarchical level\n\n# omit all arguments with an appropriate default value\nd1.1 &lt;- mrss.cra3(n = 20, J = 3,\n                  es = .13,\n                  rho2 = dp_s1$icc_l2.est, \n                  rho3 = dp_s1$icc_l3.est, \n                  # one covariate at L3\n                  g3 = 1, \n                  # a pretest at L1 that explains 21% of variance at L1 \n                  r21 = dp_s1$r2_l1_pretest.est, \n                  # a pretest at L2 that explains 65% of variance at L2 \n                  r22 = dp_s1$r2_l2_pretest.est,  \n                  # a pretest at L3 that explains 94% of variance at L3 \n                  r23 = dp_s1$r2_l3_pretest.est)\n\nK = 63 \n\n\n… 4 sociodemographic characteristics at each hierarchical level (i.e., gender, migration background, HISEI, educational attainment)\n\n# omit all arguments with an appropriate default value\nd1.2 &lt;- mrss.cra3(n = 20, J = 3,\n                  es = .13,\n                  rho2 = dp_s1$icc_l2.est, \n                  rho3 = dp_s1$icc_l3.est, \n                  # 4 covariates at L3\n                  g3 = 4, \n                  # sociodemographics at L1 that explain 2% of variance at L1 \n                  r21 = dp_s1$r2_l1_ses.est, \n                  # sociodemographics at L2 that explain 40% of variance at L2 \n                  r22 = dp_s1$r2_l2_ses.est,  \n                  # sociodemographics at L3 that explain 85% of variance at L3 \n                  r23 = dp_s1$r2_l3_ses.est)\n\nK = 123 \n\n\n… 1 pretest plus 4 sociodemographics at each hierarchical level\n\n# omit all arguments with an appropriate default value\nd1.3 &lt;- mrss.cra3(n = 20, J = 3,\n                es = .13,\n                rho2 = dp_s1$icc_l2.est, \n                rho3 = dp_s1$icc_l3.est, \n                # 5 covariates at L3\n                g3 = 5, \n                # a pretest and sociodemographics at L1 that explain 22% of variance at L1 \n                r21 = dp_s1$r2_l1_pretestses.est, \n                # a pretest and sociodemographics at L2 that explain 74% of variance at L2 \n                r22 = dp_s1$r2_l2_pretestses.est,  \n                # a pretest and sociodemographics at L3 that explain 97% of variance at L3 \n                r23 = dp_s1$r2_l3_pretestses.est)\n\nK = 41 \n\n\n\n\n\n\n\n\nTip\n\n\n\nYou could also update the respective parameter in the list $parms stored in the mrss object and then call the function again with the modified argument.\n\n\n\n# save baseline design as a new object\nd1.3a &lt;- d1.0\n# update the covariate arguments\nd1.3a$parms$g3=5\nd1.3a$parms$r21=dp_s1$r2_l1_pretestses.est\nd1.3a$parms$r22=dp_s1$r2_l2_pretestses.est\nd1.3a$parms$r23=dp_s1$r2_l3_pretestses.est\n# call the function\nd1.3a &lt;- exec(\"mrss.cra3\", !!!d1.3a$parms)\n\nK = 41 \n\n\nOf course, it is also possible to directly insert the numeric values for the design parameters. However, using the variables instead is safer, more precise, and prevents typos. Note that the results can differ due to rounding.\n\nd1.3b &lt;- mrss.cra3(n = 20, J = 3, es = .13, rho2 = .04, rho3 = .31, g3 = 5, r21 = .22, r22 = .74, r23 = .97)\n\nK = 42 \n\n\n\n\nIncorporating (Statistical) Uncertainty\nThe design parameters are estimates of population quantities, and thus, associated with statistical uncertainty. The uncertainty can be incorporated by using the standard errors for each design parameter. Assuming large-sample properties, research Team 1 uses the standard normal distribution to compute the limits for 95% confidence intervals by means of the standard errors for the design parameters. This approach has been labeled the the “safeguard” approach (Perugini et al., 2014). A conservative approach for planning the sample size is to use the upper bound estimate of the 95% CI for values of ρ and lower bound estimates of the 95% CI for values of R2.\n\nd1.4 &lt;- mrss.cra3(n = 20, J = 3,\n                es = .13,\n                # upper bound estimates of the 95% CI\n                rho2 = dp_s1$icc_l2.est+1.96*dp_s1$icc_l2.se, \n                rho3 = dp_s1$icc_l3.est+1.96*dp_s1$icc_l3.se, \n                g3 = 5, \n                # lower bound estimates of the 95% CI\n                r21 = dp_s1$r2_l1_pretest.est-1.96*dp_s1$r2_l1_pretest.se, \n                r22 = dp_s1$r2_l2_pretest.est-1.96*dp_s1$r2_l2_pretest.se,  \n                r23 = dp_s1$r2_l3_pretest.est-1.96*dp_s1$r2_l3_pretest.se)\n\nK = 97 \n\n\nNote that there are also other approaches to tackle uncertainties and/or heterogeneities in the input parameters. For instance, (Bayesian) simulation-based approaches to power analysis have been proposed that implicitly take into account uncertainty (see e.g., Moerbeek & Teerenstra, 2015; Pek & Park, 2019; Spiegelhalter et al., 2003; Turner et al., 2004). For an illustration of precision simulations based on a hybrid Bayesian-classical approach (Spiegelhalter et al., 2003) to power analysis, see Stallasch et al. (2023).\n\n\nVectorization\nMost often researchers would like to calculate power analysis outputs over a range of input values, instead of only for a single point estimate. For instance, the research team wonders whether sampling more students per classroom would raise power and precision.\nWe could do something like this…\n\n# adjust the `n` argument to 21/22/23/24/25/26/27/28/29/30\nd1.5a &lt;- mrss.cra3(n = 21, J = 3, es = .13, rho2 = dp_s1$icc_l2.est, rho3 = dp_s1$icc_l3.est, \n                g3 = 5, r21 = dp_s1$r2_l1_pretest.est, r22 = dp_s1$r2_l2_pretest.est, r23 = dp_s1$r2_l3_pretest.est)\nd1.5b &lt;- mrss.cra3(n = 22, J = 3, es = .13, rho2 = dp_s1$icc_l2.est, rho3 = dp_s1$icc_l3.est, \n                g3 = 5, r21 = dp_s1$r2_l1_pretest.est, r22 = dp_s1$r2_l2_pretest.est, r23 = dp_s1$r2_l3_pretest.est)\nd1.5c &lt;- mrss.cra3(n = 23, J = 3, es = .13, rho2 = dp_s1$icc_l2.est, rho3 = dp_s1$icc_l3.est, \n                g3 = 5, r21 = dp_s1$r2_l1_pretest.est, r22 = dp_s1$r2_l2_pretest.est, r23 = dp_s1$r2_l3_pretest.est)\nd1.5d &lt;- mrss.cra3(n = 24, J = 3, es = .13, rho2 = dp_s1$icc_l2.est, rho3 = dp_s1$icc_l3.est, \n                g3 = 5, r21 = dp_s1$r2_l1_pretest.est, r22 = dp_s1$r2_l2_pretest.est, r23 = dp_s1$r2_l3_pretest.est)\n# and so on...\n\nBUT WE SHOULD ABSOLUTELY NOT!!! Not only is this code pretty ugly, it is – most importantly – highly prone to typos, C&P mistakes etc.\n\n\n\n\n\n\nTip\n\n\n\nPerforming power analysis over a range of possible input parameters can be much more easily done via vectorization. To vectorize the functions of PowerUpR over a range of possible input parameters (here: 21 ≤ n ≤ 30), we need to write a custom function similar to what is suggested by the package authors in their vignette on vectorization). See also Scenario 3 for another example how to use vectorization.\n\n\n\n# custom function, for instance, with the option to include a pretest\ncustom_mrss.cra3 &lt;- function(n, pretest=FALSE) {\n  parms &lt;- list(n=n, J=3, es=.13, \n                rho2=dp_s1$icc_l2.est, \n                rho3=dp_s1$icc_l3.est,\n                g3=0, r21=0, r22=0, r23=0)\n  \n  # to include a pretest\n  if(isTRUE(pretest)) {\n    parms &lt;- list(n=n, J=3, es=.13,\n                  rho2=dp_s1$icc_l2.est, \n                  rho3=dp_s1$icc_l3.est,\n                  g3=1, \n                  r21=dp_s1$r2_l1_pretest.est, \n                  r22=dp_s1$r2_l2_pretest.est, \n                  r23=dp_s1$r2_l3_pretest.est)\n  }\n  design &lt;- exec(\"mrss.cra3\", !!!parms)\n  design$K\n}\n\nNow we simply have to map the function across the various sample sizes.\n\n# number of students per school 21 ≤ n ≤ 30 \nn &lt;- seq(21, 30, 1)\n\n# without a pretest\nd1.5 &lt;- map_dbl(n, custom_mrss.cra3) |&gt; set_names(n)\n\nK = 620 \nK = 619 \nK = 618 \nK = 617 \nK = 617 \nK = 616 \nK = 615 \nK = 615 \nK = 614 \nK = 614 \n\n\n\n# with a pretest\nd1.6 &lt;- map_dbl(n, ~custom_mrss.cra3(n = ., pretest=TRUE)) |&gt;  set_names(n)\n\nK = 62 \nK = 62 \nK = 61 \nK = 60 \nK = 60 \nK = 59 \nK = 59 \nK = 58 \nK = 58 \nK = 58 \n\n\nSampling more students per school can reduce the required number of schools. However, it becomes clear that increasing the number of students per school is by far not as effective than increasing the number of schools and quickly reaches a point of diminishing returns.\n\n\n\nPlotting\nLet’s plot the results. Move your cursor across the bars to learn about the required number schools for each design and how large the difference in % is compared to the baseline design.\n\n\nshow code\n\n\npackages &lt;- c(\"plotly\", \"htmlwidgets\")\n\ninvisible(\n  lapply(packages,\n         function(x) {\n           if (!require(x, character.only = TRUE)) {\n             install.packages(x, dependencies = TRUE); require(x, character.only = TRUE)}\n         }\n  )\n)\n\n\ndesign &lt;- list(d1.0, d1.1, d1.2, d1.3, d1.4) |&gt; \n  set_names(\"d1.0 Basline\", \n            \"d1.1 Pretest\", \n            \"d1.2 Sociodemographics\", \n            \"d1.3 Combi\", \n            \"d1.4 Pretest conservative\")\n\ndelta &lt;- function(design) (design[[\"K\"]]-d1.0[[\"K\"]])/d1.0[[\"K\"]]*100\n\n\np &lt;- data.frame(design = factor(names(design)), \n                schools = map_dbl(design, ~.[[\"K\"]]), \n                delta = map_dbl(design, delta)) |&gt; \n  ggplot(aes(design, schools, text = paste(\n    factor(design, \n           levels = c(\"d1.0 Basline\", \n                      \"d1.1 Pretest\", \n                      \"d1.2 Sociodemographics\", \n                      \"d1.3 Combi\", \n                      \"d1.4 Pretest conservative\"), \n           labels = c(\"The baseline design\", \n                      \"... statistically controlling for a pretest\", \n                      \"... statistically controlling for sociodemographics\", \n                      \"... statistically controlling for the full covariate battery\", \n                      \"... applying a conservative approach with pretests\")),\n    \" requires K = \", schools, \" schools.\",\"\\n\",\n    ifelse(design==\"d1.0 Basline\", \"\", \n           ifelse(design!=\"d1.0 Basline\" & delta &gt; 0, \n           paste0(\"This amounts to \", round(delta, 0), \n                  \"% more schools compared to the baseline design.\"),\n           ifelse(design!=\"d1.0 Basline\" & delta == 0, \n           \"The required number of schools does not change compared to the baseline design.\",\n           paste0(\"This amounts to \", round(delta, 0)*-1, \n                  \"% fewer schools compared to the baseline design.\")))),\n    sep = \"\"\n    ))) +\n  geom_bar(stat=\"identity\", width=0.9) + \n  scale_x_discrete(\"Design\") + \n  scale_y_continuous(\"Number of schools\") + \n  theme_minimal() + \n  theme(axis.ticks = element_blank(), \n        plot.title = element_text(hjust = 0.5)) + \n  ggtitle(\"Number of Schools Required for an MDES of .13 by Design\")\n\nggplotly(p, tooltip = \"text\")"
  },
  {
    "objectID": "covariates.html",
    "href": "covariates.html",
    "title": "Designs with Covariates",
    "section": "",
    "text": "In a CRT, entire groups of students (e.g. whole schools) are randomly assigned to the experimental groups; likewise, the treatment and control protocols are delivered at the cluster level.\nIn this tutorial, we will walk through the process of planning two CRT designs:"
  },
  {
    "objectID": "covariates.html#multilevel-design-parameters",
    "href": "covariates.html#multilevel-design-parameters",
    "title": "Designs with Covariates",
    "section": "Multilevel Design Parameters",
    "text": "Multilevel Design Parameters\nTo plan sensitive (i.e., sufficiently powered and precise) CRTs on student achievement, reliable estimates of multilevel design parameters that adequately mirror the clustered variance structure of the outcome are critical. These design parameters include:\n\nIntraclass correlation coefficients (ICCs)\nρ values that quantify achievement differences between clusters\nExplained Variances\nR2 values that quantify the proportions of explained variance by covariates at the various levels\n\nGenerally, design parameters should match the peculiarities of the target research context as closely as possible (e.g., the target population of the intervention, the specific hierarchical data structure, and the achievement outcome under investigation). There are multiple resources of empirical values of ρ and R2. A review of existing international and German research on design parameters for student achievement can be found in Stallasch et al. (2021). A useful collection of respective estimates for the United States is the “Online Intraclass Correlation Database” created by Larry V. Hedges and colleagues and hosted by the Institute for Policy Research at the Northwestern University.\n\nDesign Parameters for the German School Context\nIn this workshop, we draw on our own compilation of ρ and R2 values (and corresponding standard errors) for the German school system published in Stallasch et al. (2021). Based on three longitudinal German large-scale assessments (NEPS, PISA-I+, and DESI) which provided achievement data across the entire school career (Grades 1 to 12), we generated design parameters that apply to:\n\nseveral student populations\nboth two-level (students within schools) and three-level designs (students within classrooms within schools)\na broad array of domains\n\nR2 values at each level are available for three covariate sets:\n\npretest scores\nsociodemographic characteristics (comprising students’ gender and migration background, as well as parents’ educational attainment, and families’ HISEI)\nthe combination thereof\n\nThe design parameters are provided via an interactive Excel file (Supplemental Online Material B) that comes with a detailed introduction on the application scopes of the various sets of estimates. This document can be downloaded from the OSF or the Journal’s website.\nTo facilitate the workflow in R (e.g., to avoid time-consuming and error-prone C&P of estimates), an .rda file that encloses the full compilation of design parameters (as a list of data frames) is shared in this course’s repository on github which is ready to be directly loaded:\n\n# load design parameters from github\nload(url(\"https://github.com/sophiestallasch/2022-workshop-CRT/blob/main/data/multides1.rda?raw=true\"))\n\nIf you run into problems, click here to download the data to your local machine and then load it into R.\n\n# inspect list\nsummary(multides1)\n\n                       Length Class  Mode\nB1_General             28     tbl_df list\nB2_General_ND          14     tbl_df list\nB3_Adjusted            28     tbl_df list\nB4_Adjusted_ND         14     tbl_df list\nB5_Academic            28     tbl_df list\nB6_Academic_ND         14     tbl_df list\nB7_Non-Academic        28     tbl_df list\nB8_Non-Academic_ND     14     tbl_df list\nB9_General-2l          20     tbl_df list\nB10_General-2l_ND      10     tbl_df list\nB11_Adjusted-2l        20     tbl_df list\nB12_Adjusted-2l_ND     10     tbl_df list\nB13_Academic-2l        20     tbl_df list\nB14_Academic-2l_ND     10     tbl_df list\nB15_Non-Academic-2l    20     tbl_df list\nB16_Non-Academic-2l_ND 10     tbl_df list\n\n\nThe list contains 16 data frames, that can be grouped into two broad classes:\n\nPoint Estimates and Standard Errors\nData frames B1, B3, B5, B7, B9, B11, B13, and B15 contain the full sets of (population-specific) empirical estimates of design parameters for each domain, subdomain, and grade, along with their standard errors.\nNormative Distributions\nData frames B2, B4, B6, B8, B10, B12, B14, and B16 (all data frames ending with “_ND”) contain (population-specific) normative distributions (i.e., minimum, 25th percentile, median, 75th percentile, and maximum) of those design parameters summarized across domains and/or grades. These distributions can serve as guesstimates to plan studies whose target domain and/or grade is not covered in .\n\n\nOverview of Data Frames\nWe also created a flow chart to guide the choice of appropriate design parameters as a function of key characteristics of the target intervention.\n\n\n\nStructure of Data Frames\n\nPoint Estimates and Standard ErrorsNormative Distributions\n\n\nData frames that contain the point estimates and standard errors (i.e., B1, B3, B5, B7, B9, B11, B13, and B15) are structured as follows.\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ndomain\nDomain of achievement outcome (for details, see section ‘Achievement Domains’)\n\n\nsubdomain\nSubdomain of achievement outcome (for details, see section ‘Achievement Domains’)\n\n\ngrade\nGrade of achievement outcome\n\n\nstudy\nLarge-scale assessment study (and cohort): ‘NEPS-SC2’, ‘NEPS-SC3’, ‘NEPS-SC4’, ‘PISA-I+’, ‘DESI’\n\n\nwave\nWave of large-scale assessment study\n\n\nmodel\nHierarchical structure of specified multilevel model: ‘3l’, ‘2l’\n\n\nicc_l2.est\nICC at the classroom level ρL2\n\n\nicc_l2.se\nSE of ICC at the classroom level SE(ρL2)\n\n\nicc_l3.est\nICC at the school level ρL3\n\n\nicc_l3.se\nSE of ICC at the school level SE(ρL3)\n\n\nr2_l1_pretest.est\nExplained variance by a pretest at the student level R2L1\n\n\nr2_l1_pretest.se\nSE of explained variance by a pretest at the student level SE(R2L1)\n\n\nr2_l2_pretest.est\nExplained variance by a pretest at the classroom level R2L2\n\n\nr2_l2_pretest.se\nSE of explained variance by a pretest at the classroom level SE(R2L2)\n\n\nr2_l3_pretest.est\nExplained variance by a pretest at the school level R2L3\n\n\nr2_l3_pretest.se\nSE of explained variance by a pretest at the school level SE(R2L3)\n\n\nr2_l1_ses.est\nExplained variance by sociodemographics at the student level R2L1\n\n\nr2_l1_ses.se\nSE of explained variance by sociodemographics at the student level SE(R2L1)\n\n\nr2_l2_ses.est\nExplained variance by sociodemographics at the classroom level R2L2\n\n\nr2_l2_ses.se\nSE of explained variance by sociodemographics at the classroom level SE(R2L2)\n\n\nr2_l3_ses.est\nExplained variance by sociodemographics at the school level R2L3\n\n\nr2_l3_ses.se\nSE of explained variance by sociodemographics at the school level SE(R2L3)\n\n\nr2_l1_pretestses.est\nExplained variance by a pretest and sociodemographics at the student level R2L1\n\n\nr2_l1_pretestses.se\nSE of explained variance by a pretest and sociodemographics at the student level SE(R2L1)\n\n\nr2_l2_pretestses.est\nExplained variance by a pretest and sociodemographics at the classroom level R2L2\n\n\nr2_l2_pretestses.se\nSE of explained variance by a pretest and sociodemographics at the classroom level SE(R2L2)\n\n\nr2_l3_pretestses.est\nExplained variance by a pretest and sociodemographics at the school level R2L3\n\n\nr2_l3_pretestses.se\nSE of explained variance by a pretest and sociodemographics at the school level SE(R2L3)\n\n\n\n\n\nData frames that contain normative distributions (i.e., B2, B4, B6, B8, B10, B12, B14, and B16) are structured as follows.\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ndomain\nDomain of summarized parameters (for details, see section ‘Achievement Domains’)\n\n\ngrade_range\nGrade range of summarized parameters\n\n\nstatistic\nSummary statistic: ‘Minimum’, ‘25th Percentile’, ‘Median’, ‘75th Percentile’, ‘Maximum’\n\n\nicc_l2.est\nICC at the classroom level ρL2\n\n\nicc_l2.se\nSE of ICC at the classroom level SE(ρL2)\n\n\nicc_l3.est\nICC at the school level ρL3\n\n\nicc_l3.se\nSE of ICC at the school level SE(ρL3)\n\n\nr2_l1_pretest.est\nExplained variance by a pretest at the student level R2L1\n\n\nr2_l1_pretest.se\nSE of explained variance by a pretest at the student level SE(R2L1)\n\n\nr2_l2_pretest.est\nExplained variance by a pretest at the classroom level R2L2\n\n\nr2_l2_pretest.se\nSE of explained variance by a pretest at the classroom level SE(R2L2)\n\n\nr2_l3_pretest.est\nExplained variance by a pretest at the school level R2L3\n\n\nr2_l3_pretest.se\nSE of explained variance by a pretest at the school level SE(R2L3)\n\n\nr2_l1_ses.est\nExplained variance by sociodemographics at the student level R2L1\n\n\nr2_l1_ses.se\nSE of explained variance by sociodemographics at the student level SE(R2L1)\n\n\nr2_l2_ses.est\nExplained variance by sociodemographics at the classroom level R2L2\n\n\nr2_l2_ses.se\nSE of explained variance by sociodemographics at the classroom level SE(R2L2)\n\n\nr2_l3_ses.est\nExplained variance by sociodemographics at the school level R2L3\n\n\nr2_l3_ses.se\nSE of explained variance by sociodemographics at the school level SE(R2L3)\n\n\nr2_l1_pretestses.est\nExplained variance by a pretest and sociodemographics at the student level R2L1\n\n\nr2_l1_pretestses.se\nSE of explained variance by a pretest and sociodemographics at the student level SE(R2L1)\n\n\nr2_l2_pretestses.est\nExplained variance by a pretest and sociodemographics at the classroom level R2L2\n\n\nr2_l2_pretestses.se\nSE of explained variance by a pretest and sociodemographics at the classroom level SE(R2L2)\n\n\nr2_l3_pretestses.est\nExplained variance by a pretest and sociodemographics at the school level R2L3\n\n\nr2_l3_pretestses.se\nSE of explained variance by a pretest and sociodemographics at the school level SE(R2L3)\n\n\n\n\n\n\nNote that three-level design parameters (students at L1 within classrooms at L2 within schools at L3) were estimated for grades 1 to 10 only. For grades 11 to 12, no L2 estimates are available as 11th and 12th graders did not attend intact classrooms, but rather the grouping of students varied depending on the subject taught. Therefore, two-level design parameters (students at L1 within schools at L3) were estimated instead. Two-level equivalents for grades 1 to 10 (i.e., ignoring classroom-level clustering) are also provided; you can access them in the data frames labeled with ‘-2l’.\n\n\n\n\n\n\nNote\n\n\n\nKeep in mind that the top level (which is always the school level) is consistently indicated as ‘_l3’ across all data frames; irrespective of whether L2 estimates were estimated (i.e., also for two-level designs).\n\n\nDetailed information on the provided design parameters and underlying analysis models can be retrieved from Stallasch et al. (2021).\n\n\nAchievement Domains\nThe design parameters cover the following achievement domains.\nNote that the (sub)domain character strings in the data frames are named exactly like shown here. For instance, if we want to filter design parameters for English text reconstruction from data frame B1, we could use the following code.\n\nlibrary(PowerUpR)\nlibrary(tidyverse)\nlibrary(kableExtra)\n\n\n# filter English text reconstruction from data frame B1\neng_ctest &lt;- multides1[[\"B1_General\"]] %&gt;% \n  filter(domain == \"Verbal Skills in English (as Foreign Language)\", \n         subdomain == \"Text Reconstruction (C-Test)\")\n\nTip: However, avoid to type the full strings. We recommend using pattern matching functions like from the grep() family instead that will do the job for you.\n\n# better:\neng_ctest &lt;- multides1[[\"B1_General\"]] %&gt;% \n  filter(grepl(\"Eng\", domain), \n         grepl(\"C-Test\", subdomain))\n\nLet’s have a look at the filtered design parameters.\n\neng_ctest %&gt;%\n  t() %&gt;% # transpose for better readability\n  kbl %&gt;% \n  kable_styling(bootstrap_options = c(\"condensed\", \"responsive\")) %&gt;% \n  scroll_box(height = \"350px\")\n\n\n\n\n\n\ndomain\nVerbal Skills in English (as Foreign Language)\nVerbal Skills in English (as Foreign Language)\nVerbal Skills in English (as Foreign Language)\n\n\nsubdomain\nText Reconstruction (C-Test)\nText Reconstruction (C-Test)\nText Reconstruction (C-Test)\n\n\ngrade\n9\n9\n9\n\n\nstudy\nDESI\nDESI\nDESI (Pooled)\n\n\nwave\n1\n2\nNA\n\n\nmodel\n3l\n3l\n3l\n\n\nicc_l2.est\n0.07484727\n0.09329552\n0.08274759\n\n\nicc_l2.se\n0.009634811\n0.011132797\n0.007285329\n\n\nicc_l3.est\n0.5839861\n0.5519840\n0.5687772\n\n\nicc_l3.se\n0.01762045\n0.01851544\n0.01276421\n\n\nr2_l1_pretest.est\nNA\n0.4270869\n0.4270869\n\n\nr2_l1_pretest.se\nNA\n0.007683032\n0.007683032\n\n\nr2_l2_pretest.est\nNA\n0.8440895\n0.8440895\n\n\nr2_l2_pretest.se\nNA\n0.01575307\n0.01575307\n\n\nr2_l3_pretest.est\nNA\n0.998872\n0.998872\n\n\nr2_l3_pretest.se\nNA\n0.0006166911\n0.0006166911\n\n\nr2_l1_ses.est\n0.01315652\n0.01675238\n0.01483982\n\n\nr2_l1_ses.se\n0.002402910\n0.002561325\n0.001752443\n\n\nr2_l2_ses.est\n0.6742777\n0.6423608\n0.6577857\n\n\nr2_l2_ses.se\n0.09820881\n0.09497836\n0.06827333\n\n\nr2_l3_ses.est\n0.8845148\n0.9068157\n0.8968653\n\n\nr2_l3_ses.se\n0.01972262\n0.01770283\n0.01317418\n\n\nr2_l1_pretestses.est\nNA\n0.4306028\n0.4306028\n\n\nr2_l1_pretestses.se\nNA\n0.007663661\n0.007663661\n\n\nr2_l2_pretestses.est\nNA\n0.8838199\n0.8838199\n\n\nr2_l2_pretestses.se\nNA\n0.01990558\n0.01990558\n\n\nr2_l3_pretestses.est\nNA\n0.9993725\n0.9993725\n\n\nr2_l3_pretestses.se\nNA\n0.000219044\n0.000219044\n\n\n\n\n\n\n\n\n \nAs can be seen, there are three entries for English text reconstruction as the respective test was administered to students at two time points in the DESI study, namely at the beginning and at the end of grade 9. For the beginning of grade 9, no pretests were available, therefore the corresponding cells are set to NA. A third set of estimates is provided here that contains the meta-analytically pooled results across these two time points (as indicated by ‘DESI (Pooled)’). Note that this integration strategy (applying a fixed effect model approach) was also adopted for other domains in grade 9 in case multiple design parameters were available (as obtained either from several studies [as indicated by ‘All (Pooled)’] or from the two time points in DESI).\nLoad the design parameter collection.\n\nload(\"C:/Users/Sophie Stallasch/Documents/Workshops/2024_GEBF_Poweranalyse_Stallasch/2024-workshop-GEBF-power/multides1.rda\")"
  },
  {
    "objectID": "covariates.html#scenario-1-how-many-schools-are-required-for-a-2l-crt",
    "href": "covariates.html#scenario-1-how-many-schools-are-required-for-a-2l-crt",
    "title": "Designs with Covariates",
    "section": "Scenario 1: How Many Schools are Required for a 2L-CRT?",
    "text": "Scenario 1: How Many Schools are Required for a 2L-CRT?\nResearch Team 1 would like to conduct a 2L-CRT on the effectiveness of a school-wide intervention to improve 4th graders’ mathematical achievement in Germany. Team 1 plans to sample 40 students from each school. A standardized treatment effect of d = .25 is considered meaningful, because it represents around one quarter of the expected annual growth in mathematics from Grade 3 to Grade 4 in the German student population (Brunner et al., 2023, Table 1). How many schools are required to detect MDES = .25?\n\nStep 1: Choose the Design Parameters\nWhich data frame contains the appropriate design parameters?\n\n\n# -- choose data frame B9 \ndp_s1 &lt;- multides1[[\"B9_General-2l\"]] |&gt; \n  # filter mathematics in grade 4\n  filter(domain == \"Mathematics\", grade == 4)\n\nLet’s have a look at the relevant design parameters.\ndp_s1 |&gt; \n  # select the ICC and its standard error\n  select(contains(\"icc\")) |&gt; \n  round(2) |&gt; \n  pivot_longer(everything(), names_to = \"Variable\", values_to = \"Value\") |&gt; \n  kable()\n\n\n\n\nVariable\nValue\n\n\n\n\nicc_l3.est\n0.12\n\n\nicc_l3.se\n0.01\n\n\n\n\n\n\nStep 2: Define the Assumptions\n\nDesign AssumptionsFormula\n\n\n\n\n\n\n\n\n\nParameter\nPowerUpR Conversion\n\n\n\n\nTarget output\n\n\n\nMinimum required sample size of a 2L-CRT: Number of schools J\nmrss.cra2()\n\n\nStatistical test\n\n\n\nPower 1-β = .80\npower=.80 (default)\n\n\nSignificance level α = .05\nalpha=.05 (default)\n\n\nTwo-tailed test\ntwo.tailed=TRUE (default)\n\n\nSample sizes\n\n\n\nHarmonic mean number of L1 units per L2 unit n = 40\nn=40\n\n\nProportion of sample assigned to treatment P = .50 (balanced)\np=.50 (default)\n\n\nDesign parameters\n\n\n\nICC at L2 ρL2 = .12\nrho2=dp_s1$icc_l3.est\n\n\nFurther parameters\n\n\n\nMinimum detectable effect size MDES = .25\nes=.25\n\n\n\n\n\nBased on the expression for the MDES of a 2L-CRT with randomization/treatment assignment at L2 as given in (dong_maynard2013?), the number of schools \\(J\\) is computed as \\[\nJ = \\left(\\frac{M_{J-2}}{MDES}\\right)^2\\left(\\frac{\\rho_{L2}}{P(1-P)}+\\frac{(1-\\rho_{L2})}{P(1-P)n} \\right)\n\\] with\n\n\\(n\\) = harmonic mean number of L1 units per L2 unit\n\\(J\\) = number of L2 units\n\\(P\\) = \\(J_{TG}/J\\) = proportion of sample assigned to treatment\n\\(MDES\\) = minimum detectable effect size\n\\(M_{J-2}\\) = \\(t_{\\alpha/2}+t_{1-\\beta}\\) = multiplier for two-tailed test with \\(J-2\\) degrees of freedom\n\\(\\rho_{L2}\\) = achievement differences at L2 (ICC at L2)\n\n\n\n\n\n\nStep 3: Power Analysis with PowerUpR\n\nSimple Design with Default Assumptions\n\nd.0 &lt;- mrss.cra2(power=.80, alpha=.05, two.tailed=TRUE,\n                 n=40, p=.50,\n                 rho2=dp_s1$icc_l3.est, \n                 es=.25)\n\nJ = 73 \n\n\nGiven this design, at least 73 schools are necessary to detect an MDES of .25.\nOf course, it is also possible to directly insert the numeric values for the design parameters, but using the variables instead is safer, more precise, and prevents typos. Note that the results can differ due to rounding.\n\n# Note: Here, we are omitting all default parameters...\nd.01 &lt;- mrss.cra2(n=40, rho2=.12, es=.25)\n\nJ = 73 \n\n\n\n\nChanging the Default Assumptions\nEverything else being equal, what happens, when…\n\n(a) … power increases from 80% to 90%?\n\n# adjust the `power` argument to .90\nd.a &lt;- mrss.cra2(power=.90, \n                 n=40, rho2=dp_s1$icc_l3.est, es=.25)\n\nJ = 97 \n\n\nIncreasing power requires a larger number of schools.\nTip: We could also update the respective parameter in the list $parms stored in the mrss object and then call the function again with the modified argument.\n\n# save design 0 as a new design\nd.a &lt;- d.0\n# update `power` argument to .90\nd.a$parms$power=.90\n# call the function\nd.a &lt;- exec(\"mrss.cra2\", !!!d.a$parms)\n\nJ = 97 \n\n\n\n\n(b) … Type I error rate is set to 1%?\n\n# adjust the `alpha` argument to .01\nd.b &lt;- mrss.cra2(alpha=.01, \n                 n=40, rho2=dp_s1$icc_l3.est, es=.25)\n\nJ = 109 \n\n\nDecreasing the Type I error rate requires a larger number of schools.\n\n\n(c) … applying a one-tailed test?\n\n# adjust the `two.tailed` argument to FALSE\nd.c &lt;- mrss.cra2(two.tailed=FALSE, \n                 n=40, rho2=dp_s1$icc_l3.est, es=.25)\n\nJ = 57 \n\n\nTesting one-tailed requires a smaller number of schools.\n\n\n(d) … sampling 20/40/60/80/100 students per school?\n\n# adjust the `n` argument to 20/40/60/80/100\nd.d1 &lt;- mrss.cra2(n=20, rho2=dp_s1$icc_l3.est, es=.25)\nd.d2 &lt;- mrss.cra2(n=40, rho2=dp_s1$icc_l3.est, es=.25)\nd.d3 &lt;- mrss.cra2(n=60, rho2=dp_s1$icc_l3.est, es=.25)\nd.d4 &lt;- mrss.cra2(n=80, rho2=dp_s1$icc_l3.est, es=.25)\nd.d5 &lt;- mrss.cra2(n=100, rho2=dp_s1$icc_l3.est, es=.25)\n\nTip: Performing power analysis over a range of possible input parameters can be more easily done via vectorization. To vectorize the functions of PowerUpR over a range of possible input parameters (here: n = 20/40/60/80/100), we need to write a custom function similar to what is suggested by the package authors in their vignette on vectorization).\n\ncustom_mrss.cra2 &lt;- function(n) {\n  parms &lt;- list(n=n, rho2 = dp_s1$icc_l3.est, es=.25)\n  design &lt;- exec(\"mrss.cra2\", !!!parms)\n  design$J\n}\n\nNow we simply have to map the function across the various sample sizes.\n\n# number of students per school n = 20/40/60/80/100 \nn &lt;- seq(20, 100, 20)\nd.d &lt;- map_dbl(n, custom_mrss.cra2)\n\nJ = 84 \nJ = 73 \nJ = 69 \nJ = 67 \nJ = 66 \n\n\nSampling fewer/more students per school requires a larger/smaller number of schools. However, it becomes clear that increasing the number of students per school quickly reaches a point of diminishing returns.\n\n\n(e) … using an unbalanced design with 75% of the sample assigned to the treatment condition?\n\n# adjust the `p` argument to .75\nd.e &lt;- mrss.cra2(n=20, p=.75, rho2=dp_s1$icc_l3.est, es=.25)\n\nJ = 111 \n\n\nThe more pronounced the imbalance between experimental conditions, the larger the required number of schools.\n\n\n(f) … larger achievement differences of \\(\\rho\\) = .20 are assumed?\n\n# adjust `rho2` to .20\nd.f &lt;-mrss.cra2(n=40, rho2=.20, es=.25)\n\nJ = 112 \n\n\nLarger ICCs increase the required number of schools.\n\n\n\nIncorporating Statistical Uncertainty\nThe design parameters are estimates of population quantities, and thus, associated with statistical uncertainty. The uncertainty can be incorporated by using the standard errors for each design parameter. Assuming large-sample properties, research Team 1 uses the standard normal distribution to compute the limits for 95% confidence intervals by means of the standard errors for the design parameters. This approach has been labeled the the “safeguard” approach (Perugini et al., 2014). A conservative approach for planning the sample size is to use the upper bound estimate of the 95% CI for \\(\\rho\\).\n\n# lower bound\nd.g_lb &lt;- mrss.cra2(n=40, \n                    rho2 = dp_s1$icc_l3.est-1.96*dp_s1$icc_l3.se, \n                    es=.25)\n\nJ = 61 \n\n# upper bound\nd.g_ub &lt;- mrss.cra2(n=40, \n                    rho2 = dp_s1$icc_l3.est+1.96*dp_s1$icc_l3.se, \n                    es=.25)\n\nJ = 85 \n\n\nTaking statistical uncertainty into account, the required number of schools likely ranges between 61 and 85.\nNote that there are also other approaches to tackle uncertainties and/or heterogeneities in the input parameters. For instance, (Bayesian) simulation-based approaches to power analysis have been proposed that implicitly take into account uncertainty(see e.g., Moerbeek & Teerenstra, 2015; Pek & Park, 2019; Spiegelhalter et al., 2003; Turner et al., 2004).\n\n\n\nStep 4: Plotting\nLet’s plot the results. Move your cursor across the bars to learn about the required number schools for each design and how large the difference in % is compared to the baseline design.\n\n\nshow code\n\n\npackages &lt;- c(\"plotly\", \"htmlwidgets\")\n\ninvisible(\n  lapply(packages,\n         function(x) {\n           if (!require(x, character.only = TRUE)) {\n             install.packages(x, dependencies = TRUE); require(x, character.only = TRUE)}\n         }\n  )\n)\n\n\ndesign &lt;- list(d.0, d.a, d.b, d.c, d.d1, d.d3, d.d5, d.e, d.f, d.g_lb, d.g_ub) |&gt; \n  set_names(\"d.0\", \"d.a\", \"d.b\", \"d.c\", \"d.d1\", \"d.d3\", \"d.d5\", \"d.e\", \"d.f\", \"d.g_lb\", \"d.g_ub\")\n\ndelta &lt;- function(design) (design[[\"J\"]]-d.0[[\"J\"]])/d.0[[\"J\"]]*100\n\n\np &lt;- data.frame(design = factor(names(design)), \n                schools = map_dbl(design, ~.[[\"J\"]]), \n                delta = map_dbl(design, delta)) |&gt; \n  ggplot(aes(design, schools, text = paste(\n    factor(design, \n           levels = c(\"d.0\", \"d.a\", \"d.b\", \"d.c\", \"d.d1\", \"d.d3\", \"d.d5\", \"d.e\", \"d.f\", \"d.g_lb\", \"d.g_ub\"), \n           labels = c(\"The baseline design\", \n                      \"... increasing power to 90%\", \n                      \" ... setting Type I error rate to 1%\", \n                      \" ... applying a one-tailed test\", \n                      \"... sampling 20 students per school\", \n                      \"... sampling 60 students per school\", \n                      \"... sampling 100 students per school\", \n                      \"... assigning 75% of the schools to the treatment condition\", \n                      \"... assuming increased achievement differences at L2 of 20%\", \n                      \"... applying a liberal approach\",\n                      \"... applying a conservative approach\")),\n    \" requires J = \", schools, \" schools.\",\"\\n\",\n    ifelse(design == \"d.0\", \"\", \n           ifelse(design != \"d.0\" & delta &gt; 0, \n           paste0(\"This amounts to \", round(delta, 0), \n                  \"% more schools compared to the baseline design.\"),\n           ifelse(design != \"d.0\" & delta == 0, \n           \"The required number of schools does not change compared to the baseline design.\",\n           paste0(\"This amounts to \", round(delta, 0)*-1, \n                  \"% fewer schools compared to the baseline design.\")))),\n    sep = \"\"\n    ))) +\n  geom_bar(stat=\"identity\", width=0.9) + \n  scale_x_discrete(\"Design\") + \n  scale_y_continuous(\"Number of schools\") + \n  theme_minimal() + \n  theme(axis.ticks = element_blank(), \n        plot.title = element_text(hjust = 0.5)) + \n  ggtitle(\"Number of Schools Required for an MDES of .25 by Design\")\n\nggplotly(p, tooltip = \"text\")\n\n\n\n\n\n\n\n\n\nBuilt-in Functionality for Plotting in PowerUpR\nPowerUpR also comes with a built-in plotting function. We will quickly check out PowerUpR::plot() with the baseline design.\nIt is not possible to plot the required sample size. Instead, we can either plot the statistical power as a function of the sample size (which is the default)…\n\nplot(d.0, main = \"Power as a Function of the Number of Schools\")\n\n\n\n\n… or we can plot the MDES along with its (1-α)*100% CI as a function of the required number of schools.\n\n# include `ypar = \"mdes\"` to plot the MDES\n# include `locate=TRUE` to locate parameter values for the applied design\nplot(d.0, ypar = \"mdes\", \n     main = \"MDES as a Function of Number of Schools\", locate = TRUE)"
  },
  {
    "objectID": "covariates.html#scenario-2-how-many-schools-are-required-for-a-2l-crt",
    "href": "covariates.html#scenario-2-how-many-schools-are-required-for-a-2l-crt",
    "title": "Designs with Covariates",
    "section": "Scenario 2: How Many Schools are Required for a 2L-CRT?",
    "text": "Scenario 2: How Many Schools are Required for a 2L-CRT?\nResearch Team 1 would like to conduct a 2L-CRT on the effectiveness of a school-wide intervention to improve 4th graders’ mathematical achievement in Germany. Team 1 plans to sample 40 students from each school. A standardized treatment effect of d = .25 is considered meaningful, because it represents around one quarter of the expected annual growth in mathematics from Grade 3 to Grade 4 in the German student population (Brunner et al., 2023, Table 1). How many schools are required to detect MDES = .25?\n\nStep 1: Choose the Design Parameters\nWhich data frame contains the appropriate design parameters?\n\n\n# -- choose data frame B9 \ndp_s1 &lt;- multides1[[\"B9_General-2l\"]] |&gt; \n  # filter mathematics in grade 4\n  filter(domain == \"Mathematics\", grade == 4)\n\nLet’s have a look at the relevant design parameters.\ndp_s1 |&gt; \n  # select the ICC and its standard error\n  select(contains(\"icc\")) |&gt; \n  round(2) |&gt; \n  pivot_longer(everything(), names_to = \"Variable\", values_to = \"Value\") |&gt; \n  kable()\n\n\n\n\nVariable\nValue\n\n\n\n\nicc_l3.est\n0.12\n\n\nicc_l3.se\n0.01\n\n\n\n\n\n\nStep 2: Define the Assumptions\n\nDesign AssumptionsFormula\n\n\n\n\n\n\n\n\n\nParameter\nPowerUpR Conversion\n\n\n\n\nTarget output\n\n\n\nMinimum required sample size of a 2L-CRT: Number of schools J\nmrss.cra2()\n\n\nStatistical test\n\n\n\nPower 1-β = .80\npower=.80 (default)\n\n\nSignificance level α = .05\nalpha=.05 (default)\n\n\nTwo-tailed test\ntwo.tailed=TRUE (default)\n\n\nSample sizes\n\n\n\nHarmonic mean number of L1 units per L2 unit n = 40\nn=40\n\n\nProportion of sample assigned to treatment P = .50 (balanced)\np=.50 (default)\n\n\nDesign parameters\n\n\n\nICC at L2 ρL2 = .12\nrho2=dp_s1$icc_l3.est\n\n\nFurther parameters\n\n\n\nMinimum detectable effect size MDES = .25\nes=.25\n\n\n\n\n\nBased on the expression for the MDES of a 2L-CRT with randomization/treatment assignment at L2 as given in (dong_maynard2013?), the number of schools \\(J\\) is computed as \\[\nJ = \\left(\\frac{M_{J-2}}{MDES}\\right)^2\\left(\\frac{\\rho_{L2}}{P(1-P)}+\\frac{(1-\\rho_{L2})}{P(1-P)n} \\right)\n\\] with\n\n\\(n\\) = harmonic mean number of L1 units per L2 unit\n\\(J\\) = number of L2 units\n\\(P\\) = \\(J_{TG}/J\\) = proportion of sample assigned to treatment\n\\(MDES\\) = minimum detectable effect size\n\\(M_{J-2}\\) = \\(t_{\\alpha/2}+t_{1-\\beta}\\) = multiplier for two-tailed test with \\(J-2\\) degrees of freedom\n\\(\\rho_{L2}\\) = achievement differences at L2 (ICC at L2)\n\n\n\n\n\n\nStep 3: Power Analysis with PowerUpR\n\nSimple Design with Default Assumptions\n\nd.0 &lt;- mrss.cra2(power=.80, alpha=.05, two.tailed=TRUE,\n                 n=40, p=.50,\n                 rho2=dp_s1$icc_l3.est, \n                 es=.25)\n\nJ = 73 \n\n\nGiven this design, at least 73 schools are necessary to detect an MDES of .25.\nOf course, it is also possible to directly insert the numeric values for the design parameters, but using the variables instead is safer, more precise, and prevents typos. Note that the results can differ due to rounding.\n\n# Note: Here, we are omitting all default parameters...\nd.01 &lt;- mrss.cra2(n=40, rho2=.12, es=.25)\n\nJ = 73 \n\n\n\n\nChanging the Default Assumptions\nEverything else being equal, what happens, when…\n\n(a) … power increases from 80% to 90%?\n\n# adjust the `power` argument to .90\nd.a &lt;- mrss.cra2(power=.90, \n                 n=40, rho2=dp_s1$icc_l3.est, es=.25)\n\nJ = 97 \n\n\nIncreasing power requires a larger number of schools.\nTip: We could also update the respective parameter in the list $parms stored in the mrss object and then call the function again with the modified argument.\n\n# save design 0 as a new design\nd.a &lt;- d.0\n# update `power` argument to .90\nd.a$parms$power=.90\n# call the function\nd.a &lt;- exec(\"mrss.cra2\", !!!d.a$parms)\n\nJ = 97 \n\n\n\n\n(b) … Type I error rate is set to 1%?\n\n# adjust the `alpha` argument to .01\nd.b &lt;- mrss.cra2(alpha=.01, \n                 n=40, rho2=dp_s1$icc_l3.est, es=.25)\n\nJ = 109 \n\n\nDecreasing the Type I error rate requires a larger number of schools.\n\n\n(c) … applying a one-tailed test?\n\n# adjust the `two.tailed` argument to FALSE\nd.c &lt;- mrss.cra2(two.tailed=FALSE, \n                 n=40, rho2=dp_s1$icc_l3.est, es=.25)\n\nJ = 57 \n\n\nTesting one-tailed requires a smaller number of schools.\n\n\n(d) … sampling 20/40/60/80/100 students per school?\n\n# adjust the `n` argument to 20/40/60/80/100\nd.d1 &lt;- mrss.cra2(n=20, rho2=dp_s1$icc_l3.est, es=.25)\nd.d2 &lt;- mrss.cra2(n=40, rho2=dp_s1$icc_l3.est, es=.25)\nd.d3 &lt;- mrss.cra2(n=60, rho2=dp_s1$icc_l3.est, es=.25)\nd.d4 &lt;- mrss.cra2(n=80, rho2=dp_s1$icc_l3.est, es=.25)\nd.d5 &lt;- mrss.cra2(n=100, rho2=dp_s1$icc_l3.est, es=.25)\n\nTip: Performing power analysis over a range of possible input parameters can be more easily done via vectorization. To vectorize the functions of PowerUpR over a range of possible input parameters (here: n = 20/40/60/80/100), we need to write a custom function similar to what is suggested by the package authors in their vignette on vectorization).\n\ncustom_mrss.cra2 &lt;- function(n) {\n  parms &lt;- list(n=n, rho2 = dp_s1$icc_l3.est, es=.25)\n  design &lt;- exec(\"mrss.cra2\", !!!parms)\n  design$J\n}\n\nNow we simply have to map the function across the various sample sizes.\n\n# number of students per school n = 20/40/60/80/100 \nn &lt;- seq(20, 100, 20)\nd.d &lt;- map_dbl(n, custom_mrss.cra2)\n\nJ = 84 \nJ = 73 \nJ = 69 \nJ = 67 \nJ = 66 \n\n\nSampling fewer/more students per school requires a larger/smaller number of schools. However, it becomes clear that increasing the number of students per school quickly reaches a point of diminishing returns.\n\n\n(e) … using an unbalanced design with 75% of the sample assigned to the treatment condition?\n\n# adjust the `p` argument to .75\nd.e &lt;- mrss.cra2(n=20, p=.75, rho2=dp_s1$icc_l3.est, es=.25)\n\nJ = 111 \n\n\nThe more pronounced the imbalance between experimental conditions, the larger the required number of schools.\n\n\n(f) … larger achievement differences of \\(\\rho\\) = .20 are assumed?\n\n# adjust `rho2` to .20\nd.f &lt;-mrss.cra2(n=40, rho2=.20, es=.25)\n\nJ = 112 \n\n\nLarger ICCs increase the required number of schools.\n\n\n\nIncorporating Statistical Uncertainty\nThe design parameters are estimates of population quantities, and thus, associated with statistical uncertainty. The uncertainty can be incorporated by using the standard errors for each design parameter. Assuming large-sample properties, research Team 1 uses the standard normal distribution to compute the limits for 95% confidence intervals by means of the standard errors for the design parameters. This approach has been labeled the the “safeguard” approach (Perugini et al., 2014). A conservative approach for planning the sample size is to use the upper bound estimate of the 95% CI for \\(\\rho\\).\n\n# lower bound\nd.g_lb &lt;- mrss.cra2(n=40, \n                    rho2 = dp_s1$icc_l3.est-1.96*dp_s1$icc_l3.se, \n                    es=.25)\n\nJ = 61 \n\n# upper bound\nd.g_ub &lt;- mrss.cra2(n=40, \n                    rho2 = dp_s1$icc_l3.est+1.96*dp_s1$icc_l3.se, \n                    es=.25)\n\nJ = 85 \n\n\nTaking statistical uncertainty into account, the required number of schools likely ranges between 61 and 85.\nNote that there are also other approaches to tackle uncertainties and/or heterogeneities in the input parameters. For instance, (Bayesian) simulation-based approaches to power analysis have been proposed that implicitly take into account uncertainty(see e.g., Moerbeek & Teerenstra, 2015; Pek & Park, 2019; Spiegelhalter et al., 2003; Turner et al., 2004).\n\n\n\nStep 4: Plotting\nLet’s plot the results. Move your cursor across the bars to learn about the required number schools for each design and how large the difference in % is compared to the baseline design.\n\n\nshow code\n\n\npackages &lt;- c(\"plotly\", \"htmlwidgets\")\n\ninvisible(\n  lapply(packages,\n         function(x) {\n           if (!require(x, character.only = TRUE)) {\n             install.packages(x, dependencies = TRUE); require(x, character.only = TRUE)}\n         }\n  )\n)\n\n\ndesign &lt;- list(d.0, d.a, d.b, d.c, d.d1, d.d3, d.d5, d.e, d.f, d.g_lb, d.g_ub) |&gt; \n  set_names(\"d.0\", \"d.a\", \"d.b\", \"d.c\", \"d.d1\", \"d.d3\", \"d.d5\", \"d.e\", \"d.f\", \"d.g_lb\", \"d.g_ub\")\n\ndelta &lt;- function(design) (design[[\"J\"]]-d.0[[\"J\"]])/d.0[[\"J\"]]*100\n\n\np &lt;- data.frame(design = factor(names(design)), \n                schools = map_dbl(design, ~.[[\"J\"]]), \n                delta = map_dbl(design, delta)) |&gt; \n  ggplot(aes(design, schools, text = paste(\n    factor(design, \n           levels = c(\"d.0\", \"d.a\", \"d.b\", \"d.c\", \"d.d1\", \"d.d3\", \"d.d5\", \"d.e\", \"d.f\", \"d.g_lb\", \"d.g_ub\"), \n           labels = c(\"The baseline design\", \n                      \"... increasing power to 90%\", \n                      \" ... setting Type I error rate to 1%\", \n                      \" ... applying a one-tailed test\", \n                      \"... sampling 20 students per school\", \n                      \"... sampling 60 students per school\", \n                      \"... sampling 100 students per school\", \n                      \"... assigning 75% of the schools to the treatment condition\", \n                      \"... assuming increased achievement differences at L2 of 20%\", \n                      \"... applying a liberal approach\",\n                      \"... applying a conservative approach\")),\n    \" requires J = \", schools, \" schools.\",\"\\n\",\n    ifelse(design == \"d.0\", \"\", \n           ifelse(design != \"d.0\" & delta &gt; 0, \n           paste0(\"This amounts to \", round(delta, 0), \n                  \"% more schools compared to the baseline design.\"),\n           ifelse(design != \"d.0\" & delta == 0, \n           \"The required number of schools does not change compared to the baseline design.\",\n           paste0(\"This amounts to \", round(delta, 0)*-1, \n                  \"% fewer schools compared to the baseline design.\")))),\n    sep = \"\"\n    ))) +\n  geom_bar(stat=\"identity\", width=0.9) + \n  scale_x_discrete(\"Design\") + \n  scale_y_continuous(\"Number of schools\") + \n  theme_minimal() + \n  theme(axis.ticks = element_blank(), \n        plot.title = element_text(hjust = 0.5)) + \n  ggtitle(\"Number of Schools Required for an MDES of .25 by Design\")\n\nggplotly(p, tooltip = \"text\")\n\n\n\n\n\n\n\n\n\nBuilt-in Functionality for Plotting in PowerUpR\nPowerUpR also comes with a built-in plotting function. We will quickly check out PowerUpR::plot() with the baseline design.\nIt is not possible to plot the required sample size. Instead, we can either plot the statistical power as a function of the sample size (which is the default)…\n\nplot(d.0, main = \"Power as a Function of the Number of Schools\")\n\n\n\n\n… or we can plot the MDES along with its (1-α)*100% CI as a function of the required number of schools.\n\n# include `ypar = \"mdes\"` to plot the MDES\n# include `locate=TRUE` to locate parameter values for the applied design\nplot(d.0, ypar = \"mdes\", \n     main = \"MDES as a Function of Number of Schools\", locate = TRUE)"
  },
  {
    "objectID": "multilevel.html#your-turn",
    "href": "multilevel.html#your-turn",
    "title": "Multilevel Designs",
    "section": "Your turn!",
    "text": "Your turn!\n\nScenario 2: Finding the Minimum Required Sample Size for a 2L-CRT\nResearch Team 2 would like to conduct a 2L-CRT on the effectiveness of a curricular-based school reform targeted at improving 4th graders’ mathematics achievement in Germany. Team 2 plans to sample 40 students from each school. To improve statistical power and precision, the researchers administer a math pretest to each participating student.\n\nExercisesR Code Solutions\n\n\n\nWith the aid of the flow chart, choose the appropriate design parameters from the multides1 database.\nUse the mrss.cra2() function to compute how many schools are necessary to detect a standardized treatment effect of d = .15 with confidence (i.e., α = .05, two-tailed, 1-β = .80).\nAll else held constant, what happens when…\n\n\n\nincreasing power from 80% to 90%?\n\n\nadding sociodemographics as covariates (over and above the included math pretest) at the school level only, and both at the school and student level?\n\n\nno covariates are used?\n\n\nlarger between-school achievement differences of ρL3 = .20 are assumed?\n\n\ntaking statistical uncertainty into account to opt for a conservative or a liberal approach?\n\n\n\n\n\nWith the aid of the flow chart, choose the appropriate design parameters from the multides1 database.\n\n\n\n# -- choose data frame B9 \ndp_s2 &lt;- multides1[[\"B9_General-2l\"]] |&gt; \n  # filter mathematics in grade 4\n  filter(domain == \"Mathematics\", grade == 4)\n\n\nUse the mrss.cra2() function to compute how many schools are necessary to detect a standardized treatment effect of d = .15 with confidence (i.e., α = .05, two-tailed, 1-β = .80).\n\n\nBaseline design with a math pretest as covariate\n\nmrss.cra2(es = .15, n = 40, rho2 = dp_s2$icc_l3.est, \n          g2 = 1, r21 = dp_s2$r2_l1_pretest.est, r22 = dp_s2$r2_l3_pretest.est)\n\nJ = 80 \n\n\n\nAll else held constant, what happens when…\n\n\n\n(a) increasing power from 80% to 90%?\nAdjust the power argument to .90.\n\nmrss.cra2(power = .90, es = .15, n = 40, rho2 = dp_s2$icc_l3.est, \n          g2 = 1, r21 = dp_s2$r2_l1_pretest.est, r22 = dp_s2$r2_l3_pretest.est)\n\nJ = 107 \n\n\nOr, update the respective parameter in the list $parms stored in the mrss object and then call the function again with the modified argument.\n\n# save the baseline design as a new design\n# (if not saved into an object before, specify the design again)\nd2.0 &lt;- mrss.cra2(es = .15, n = 40, rho2 = dp_s2$icc_l3.est, \n        g2 = 1, r21 = dp_s2$r2_l1_pretest.est, r22 = dp_s2$r2_l3_pretest.est)\n\nJ = 80 \n\nd2.a &lt;- d2.0\n\n# update power argument to .90\nd2.a$parms$power = .90\n\n# call the function\nd2.a &lt;- exec(\"mrss.cra2\", !!!d2.a$parms)\n\nJ = 107 \n\n\n\n\n(b) adding sociodemographics as covariates (over and above the included math pretest) at the school level only, and both at the school and student level?\nLet’s have a look at the relevant design parameters first.\n\ndp_s2  |&gt;  \n  # select R-squared values for the combination of pretest and sociodemographics\n  select(contains(\"pretestses\")) |&gt; \n  round(2) %&gt;% \n  pivot_longer(everything(), names_to = \"Variable\", values_to = \"Value\") |&gt;  \n  kbl()\n\n\n\n\nVariable\nValue\n\n\n\n\nr2_l1_pretestses.est\n0.43\n\n\nr2_l1_pretestses.se\n0.01\n\n\nr2_l3_pretestses.est\n0.76\n\n\nr2_l3_pretestses.se\n0.03\n\n\n\n\n\n\n\nAdd 4 sociodemographics at L2 only – adjust only r22\n\nmrss.cra2(es = .15, n = 40, rho2 = dp_s2$icc_l3.est,\n          g2 = 4, r21 = dp_s2$r2_l3_pretest.est, r22 = dp_s2$r2_l1_pretestses.est)\n\nJ = 109 \n\n\nAdd 4 sociodemographics at both L1 and L2 – adjust both r21 and r22\n\nmrss.cra2(es = .15, n = 40, rho2 = dp_s2$icc_l3.est,\n          g2 = 4, r21 = dp_s2$r2_l3_pretestses.est, r22 = dp_s2$r2_l1_pretestses.est)\n\nJ = 105 \n\n\n\n\n(c) no covariates are used?\nSet all covariate-specific arguments to zero. Note that this can be achieved by not specifying the covariate-specific arguments (defaults: g2=0, r21=0, r22=0).\n\nmrss.cra2(es = .15, n = 40, rho2 = dp_s2$icc_l3.est)\n\nJ = 199 \n\n\n\n\n(e) larger between-school achievement differences of ρL3 = .20 are assumed?\nSet rho2 (denoting our ρL3 in the PowerUpR naming convention for two-level designs) to .20\n\nmrss.cra2(es = .15, n = 40, rho2 = .20, \n          g2 = 1, r21 = dp_s2$r2_l1_pretest.est, r22 = dp_s2$r2_l3_pretest.est)\n\nJ = 119 \n\n\n\n\n(f) taking statistical uncertainty into account to opt for a conservative or a liberal approach?\nUse the standard normal distribution to compute the limits for 95% confidence intervals by means of the standard errors of the design parameters.\n\nA conservative approach could be to rely on the upper bound estimate of the 95% CI for ρ, and the lower bound estimates for the R2 values.\n\nmrss.cra2(es = .15, n = 40,\n          rho2 = dp_s2$icc_l3.est+1.96*dp_s2$icc_l3.se,\n          g2 = 1,\n          r21 = dp_s2$r2_l1_pretest.est-1.96*dp_s2$r2_l1_pretest.se,\n          r22 = dp_s2$r2_l3_pretest.est-1.96*dp_s2$r2_l3_pretest.se)\n\nJ = 106 \n\n\nA liberal approach could be to rely on the lower bound estimate of the 95% CI for ρ, and the upper bound estimates for the R2 values.\n\nmrss.cra2(es = .15, n = 40,\n          rho2 = dp_s2$icc_l3.est-1.96*dp_s2$icc_l3.se,\n          g2 = 1,\n          r21 = dp_s2$r2_l1_pretest.est+1.96*dp_s2$r2_l1_pretest.se,\n          r22 = dp_s2$r2_l3_pretest.est+1.96*dp_s2$r2_l3_pretest.se)\n\nJ = 59 \n\n\n\n\n\n\n\n\nScenario 3: Computing the Minimum Detectable Effect Size for a 3L-CRT\nResearch Team 3 plans a 3L-CRT to study the impact of an intervention that is intended to affect students’ history achievement across Grades 5 to 12 in (non-academic track) comprehensive secondary schools. Due to budgetary constraints, a fixed maximum number of 40 schools (with 2 classrooms, and 20 students each) are at the researchers’ disposal. Given these limits, the primary concern of Team 3 is to ensure that the attainable MDES lies within the range of the effects on students’ achievement that is typically observed for this kind of intervention (i.e., 0.20 ≤ d ≤ 0.30, see Hill et al. (2008)). Team 3 considers two designs: (1) a design without covariates, and (2) a design that adjusts for a pretest and 4 sociodemographics (i.e., students’ gender and migration background, parents’ educational attainment, and families’ HISEI).\n\n\n\n\n\n\nTip\n\n\n\nIn this Scenario, you should use the normative distributions of the design parameters. Recall, these data frames are indexed by the suffix “_ND”.\n\n\n\nExercisesR Code Solutions\n\n\n\nWith the aid of the flow chart, choose the appropriate design parameters from the multides1 database.\nFor small (25th percentile), medium (50th percentile), and large values (75th percentile) of ρ, use the mdes.cra3() function to compute the MDES which can be detected with confidence (i.e., α = .05 in a two-tailed test, 1-β = .80), given…\n\n\n\na design without covariates.\n\n\na design with adjustment for the full battery of covariates (i.e., 1 pretest plus 4 sociodemographics), using large values (75th percentile) of R2.\n\n\n\nTry to visualize the results.\nAdditional task: Suppose that research Team 3 further wishes to analyze the intervention’s effects in the academic track and on other (possibly domain-general) skills. Choose two or three other target domains for which Stallasch et al. (2021) provide design parameters for the academic track and perform power analyses to find the design that is most parsimonious in terms of sample size and possibly included covariates.\n\n\n\n\nWith the aid of the flow chart, choose the appropriate design parameters from the multides1 database.\n\n Choose data frame B4.\n\ndp_s3 &lt;- multides1[[\"B4_Adjusted_ND\"]] |&gt;  \n  # filter P25, median, and P75 for design parameters that are summarized across domains and secondary school grades\n  filter(domain == \"All\", grade_range == \"5-12\", !grepl(\"Min|Max\", statistic)) |&gt;  \n  # select relevant design parameters\n  select(statistic, contains(c(\"icc\", \"pretestses\"))) |&gt;  \n  # simplify variable names\n  set_names(c(\"statistic\", \"rho2\", \"rho3\", \"r21\", \"r22\", \"r23\"))\n\n\nFor small (25th percentile), medium (50th percentile), and large values (75th percentile) of the design parameters, use the mdes.cra3() function to compute the MDES which can be detected with confidence (i.e., α = .05 in a two-tailed test, 1-β = .80), given…\n\n\n(a) a design without covariates.\nAgain, we can write a custom function to vectorize over a range of possible parameters (here: small, medium, and large ρ values).\n\ncustom_mdes.cra3 &lt;- function(rho2, rho3, g3 = 0, r21 = 0, r22 = 0, r23 = 0, ...) {\n  parms &lt;- list(rho2 = rho2, rho3 = rho3,\n                g3 = g3, \n                r21 = r21, r22 = r22, r23 = r23, \n                n = 20, J = 2, K = 40)\n  design &lt;- exec(\"mdes.cra3\", !!!parms)\n  mdes &lt;- design$mdes[1]  # MDES point estimate\n  ci.lb &lt;- design$mdes[2] # lower bound of 95% CI\n  ci.ub &lt;- design$mdes[3] # upper bound of 95% CI\n  return(data.frame(mdes = mdes, ci.lb = ci.lb, ci.ub = ci.ub))\n}\n\nApply the function to compute the MDES for small, medium, and large intraclass correlations using pmap()\n\nd3.a &lt;- pmap(dp_s3 %&gt;% select(contains(\"rho\")), custom_mdes.cra3) %&gt;% \n  set_names(dp_s3$statistic) %&gt;% \n  bind_rows(.id = \"statistic\")\n\n\nMinimum detectable effect size: \n--------------------------------------- \n 0.315 95% CI [0.093,0.536]\n---------------------------------------\nDegrees of freedom: 38\nStandardized standard error: 0.109\nType I error rate: 0.05\nType II error rate: 0.2\nTwo-tailed test: TRUE\n\nMinimum detectable effect size: \n--------------------------------------- \n 0.347 95% CI [0.103,0.592]\n---------------------------------------\nDegrees of freedom: 38\nStandardized standard error: 0.121\nType I error rate: 0.05\nType II error rate: 0.2\nTwo-tailed test: TRUE\n\nMinimum detectable effect size: \n--------------------------------------- \n 0.388 95% CI [0.115,0.661]\n---------------------------------------\nDegrees of freedom: 38\nStandardized standard error: 0.135\nType I error rate: 0.05\nType II error rate: 0.2\nTwo-tailed test: TRUE\n\n\n\n\n(b) a design with adjustment for the full battery of covariates (i.e., 1 pretest plus 4 sociodemographics), using large values (75th percentile) of R2.\nWhen adding covariates, Team 3 uses the large values for ρ (i.e., the 75th percentile) to apply a conservative approach.\n\n# use the 75th percentile of the ICCs and adjust for 5 covariates (1 pretest + 4 sociodemographics)\nd3.b &lt;- pmap(dp_s3 %&gt;% \n             mutate(rho2 = as.numeric(.[.$statistic == \"75th Percentile\", \"rho2\"]), \n                    rho3 = as.numeric(.[.$statistic == \"75th Percentile\", \"rho3\"]), \n                    g3 = 5), \n           custom_mdes.cra3) %&gt;% \n  set_names(unique(dp_s3$statistic))  %&gt;% \n  bind_rows(.id = \"statistic\")\n\n\nMinimum detectable effect size: \n--------------------------------------- \n 0.202 95% CI [0.06,0.344]\n---------------------------------------\nDegrees of freedom: 33\nStandardized standard error: 0.07\nType I error rate: 0.05\nType II error rate: 0.2\nTwo-tailed test: TRUE\n\nMinimum detectable effect size: \n--------------------------------------- \n 0.176 95% CI [0.052,0.3]\n---------------------------------------\nDegrees of freedom: 33\nStandardized standard error: 0.061\nType I error rate: 0.05\nType II error rate: 0.2\nTwo-tailed test: TRUE\n\nMinimum detectable effect size: \n--------------------------------------- \n 0.142 95% CI [0.042,0.242]\n---------------------------------------\nDegrees of freedom: 33\nStandardized standard error: 0.049\nType I error rate: 0.05\nType II error rate: 0.2\nTwo-tailed test: TRUE\n\n\n\nTry to visualize the results.\n\n\n\nPlotting\n\n\nshow code\n\n\np &lt;- ggplot(bind_rows(d3.a, d3.b, .id = \"design\") %&gt;% \n              mutate(statistic = factor(statistic, \n                                        levels = c(\"25th Percentile\", \n                                                   \"Median\", \n                                                   \"75th Percentile\"),\n                                        labels = c(\"Small\", \"Medium\", \"Large\")))) + \n  geom_pointrange(aes(x = statistic, y = mdes, ymin = ci.lb, ymax = ci.ub, col = design), \n                  position = position_dodge(width = 0.5)) + \n  geom_hline(yintercept = .3, lty = \"dotted\") + \n  scale_y_continuous(\"MDES\", breaks = seq(0, 0.7, 0.1))+\n  scale_color_manual(values = c(\"#2c3e50\", \"#18bc9c\"),\n                     labels = c(\"No covariates\", \n                                expression(\"Pretest + Sociodemographics (with large values of\"~rho*\")\"))) + \n  theme_minimal() + \n  theme(axis.title.x = element_blank(),\n        legend.title = element_blank(),\n        legend.position = \"bottom\", \n        plot.title = element_text(hjust = 0.5)) + \n  ggtitle(\"MDES (with 95% CI) for Normative Distributions of Design Parameters\") + \n  annotate(\"rect\", xmin = -Inf, xmax = Inf, ymin = 0.3, ymax = Inf,\n           alpha = .2)\np\n\n\n\n\n\n\n\n\n\n\n\n \n\nTeam 3 learns that the attainable MDES is 0.31/0.35/0.39 (point estimates) for small/medium/large values of ρL2 and ρL3. Including both a pretest and sociodemographics as covariates and using the 75th percentiles of the values for ρL2 and ρL3 (as more conservative upper bounds), the respective values for the MDES reduce to 0.2/0.18/0.14 for small/medium/large values of R2 at the various levels. Consequently, Team 3 can be quite confident that their CRT design offers sufficient sensitivity to detect a true intervention effect within the desired range when including both pretests and sociodemographics."
  },
  {
    "objectID": "dp.html#references",
    "href": "dp.html#references",
    "title": "Design Parameters",
    "section": "References",
    "text": "References\n\n\nStallasch, S. E., Lüdtke, O., Artelt, C., & Brunner, M. (2021). Multilevel Design Parameters to Plan Cluster-Randomized Intervention Studies on Student Achievement in Elementary and Secondary School. Journal of Research on Educational Effectiveness, 14(1), 172–206. https://doi.org/10.1080/19345747.2020.1823539\n\n\nStallasch, S. E., Lüdtke, O., Artelt, C., Hedges, L. V., & Brunner, M. (2023). Single- and multilevel perspectives on covariate selection in randomized intervention studies on student achievement. http://dx.doi.org/10.31234/osf.io/5ajmg\n\n\n\n \n\n© 2024 Sophie E. Stallasch (stallasch[at]uni-potsdam.de)"
  },
  {
    "objectID": "index.html#references",
    "href": "index.html#references",
    "title": "Workshop: Power Analysis for Experimental Designs in R with the ‘PowerUpR’ Package",
    "section": "References",
    "text": "References\n\n\nBulus, M., Dong, N., Kelcey, B., & Spybrook, J. (2021). PowerUpR: Power analysis tools for multilevel randomized experiments. https://CRAN.R-project.org/package=PowerUpR\n\n\nDong, N., & Maynard, R. (2013). PowerUp!: A Tool for Calculating Minimum Detectable Effect Sizes and Minimum Required Sample Sizes for Experimental and Quasi-Experimental Design Studies. Journal of Research on Educational Effectiveness, 6(1), 24–67. https://doi.org/10.1080/19345747.2012.673143\n\n\nWickham, H., Averick, M., Bryan, J., Chang, W., McGowan, L. D., François, R., Grolemund, G., Hayes, A., Henry, L., Hester, J., Kuhn, M., Pedersen, T. L., Miller, E., Bache, S. M., Müller, K., Ooms, J., Robinson, D., Seidel, D. P., Spinu, V., … Yutani, H. (2019). Welcome to the tidyverse. 4, 1686. https://doi.org/10.21105/joss.01686\n\n\nZhu, H. (2024). kableExtra: Construct complex table with ’kable’ and pipe syntax. https://CRAN.R-project.org/package=kableExtra\n\n\n\n \n\n© 2024 Sophie E. Stallasch (stallasch[at]uni-potsdam.de)"
  },
  {
    "objectID": "single-level.html#footnotes",
    "href": "single-level.html#footnotes",
    "title": "Single-Level Designs",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nIn PowerUpR, the standardized standard error is calculated as \\(SSE=\\sqrt{\\frac{1-R^2}{P(1-P)n}}\\), and is as such expressed as the ratio of the effect size (i.e., the MDES) to the noncentrality parameter \\(\\lambda\\): \\(SSE=\\frac{MDES}{\\lambda}\\). Therefore, in PowerUpR, the noncentrality parameter \\(\\lambda\\) is equated with the multiplier \\(M_{n-g^*-2}\\) (see e.g., Stallasch et al., 2023).↩︎"
  }
]